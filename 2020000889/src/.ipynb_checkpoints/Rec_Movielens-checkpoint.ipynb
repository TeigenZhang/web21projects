{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import tqdm\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Module\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import BCELoss,BCEWithLogitsLoss\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam,Adadelta,RMSprop\n",
    "\n",
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda._initialized = True\n",
    "\n",
    "#from src.Dataset import ACM_Dataset,Amazon_Dataset,Movielens_Dataset\n",
    "from src.models import MF,NeuMF,GCF\n",
    "from src.Utils import BPRLoss,Wrap_Dataset,EarlyStopping\n",
    "#from src.Evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    return len(truth_in_top_k) * 1.0 / (df_static['len'].sum())\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return full['ndcg'].sum() * 1.0 / df_eval['uid'].nunique()\n",
    "\n",
    "def evaluate(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio(df_eval,df_static,top_k),call_ndcg(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    stat = full[['uid','len','rating']].groupby('uid')['rating'].apply(sum).reset_index().rename(columns={'rating': 'recall_num'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    stat2['hr_perU'] = stat2.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    #stat['hr'] = stat.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    return stat2[['uid','len','recall_num','hr_perU']]\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    \n",
    "    stat = full[['uid','len','ndcg']].groupby('uid')['ndcg'].apply(sum).reset_index().rename(columns={'ndcg': 'ndcg_perU'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return stat2[['uid','len','ndcg_perU']]\n",
    "\n",
    "def evaluate2(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio2(df_eval,df_static,top_k),call_ndcg2(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movielens_Dataset(object):\n",
    "    def __init__(self,config_dat):\n",
    "        self.dataset_name = config_dat['dataset_name']\n",
    "        #self.model_name = model_name\n",
    "        self.Load_flag = config_dat['isLoad']\n",
    "        self.Store_flag =config_dat['store']\n",
    "        self.filepaths = config_dat['filepaths']\n",
    "        self.uNum,self.iNum = self.Movielens_get_nums()\n",
    "        self.train,self.dev,self.test = self.data_split(config_dat['neg_num4train'])\n",
    "        self.train['rating'] = [1 for i in range(len(self.train))]\n",
    "        print(self.uNum)\n",
    "        print(self.iNum)\n",
    "        self.input_train = self.Movielens_build_input_data(1)\n",
    "        self.input_dev = self.Movielens_build_input_data(2)\n",
    "        self.input_test = self.Movielens_build_input_data(3)\n",
    "        self.eval_dev,self.eval_test = self.Movielens_build_eval_data()\n",
    "        \n",
    "        self.i2g = pd.read_csv(self.filepaths[0]+'i2g.csv')\n",
    "        self.i2i = pd.read_csv(self.filepaths[0]+'i2i.csv')\n",
    "        self.u2a = pd.read_csv(self.filepaths[0]+'u2a.csv')\n",
    "        self.u2o = pd.read_csv(self.filepaths[0]+'u2o.csv')\n",
    "        self.u2u = pd.read_csv(self.filepaths[0]+'u2u.csv')\n",
    "        self.i2g['link'] = [1 for _ in range(len(self.i2g))]\n",
    "        self.i2i['link'] = [1 for _ in range(len(self.i2i))]\n",
    "        self.u2a['link'] = [1 for _ in range(len(self.u2a))]\n",
    "        self.u2o['link'] = [1 for _ in range(len(self.u2o))]\n",
    "        self.u2u['link'] = [1 for _ in range(len(self.u2u))]\n",
    "        self.gNum = self.i2g['gid'].max()+1\n",
    "        self.aNum = self.u2a['aid'].max()+1\n",
    "        self.oNum = self.u2o['oid'].max()+1\n",
    "        # L_u2i,L_u2es,L_i2es,nNum_u2i,nNum_u2es,nNum_i2es\n",
    "        self.mp_graphs = self.Movielens_create_mp_neighbor_graph()\n",
    "        \n",
    "        L_u2i,L_u2i_hat = self.Movielens_buildLaplacianMat_u2i()\n",
    "        self.u2i = [(L_u2i, L_u2i_hat),[self.uNum,self.iNum]]\n",
    "        \n",
    "        L_u2u,L_u2u_hat = self.Movielens_buildLaplacianMat_u2u()\n",
    "        L_u2a_u, L_u2a_u_hat, L_u2a_a, L_u2a_a_hat = self.Movielens_buildLaplacianMat_u2a()\n",
    "        L_u2o_u, L_u2o_u_hat, L_u2o_o, L_u2o_o_hat = self.Movielens_buildLaplacianMat_u2o()\n",
    "        self.u2es = [\n",
    "            [(L_u2u, L_u2u_hat,None),0,True],\n",
    "            [(L_u2a_u, L_u2a_u_hat, L_u2a_a_hat),self.aNum,False],\n",
    "            [(L_u2o_u, L_u2o_u_hat, L_u2o_o_hat),self.oNum,False]\n",
    "        ]\n",
    "        \n",
    "        self.u2es2 = [\n",
    "            [(L_u2u, L_u2u_hat,None,None),0,True],\n",
    "            [(L_u2a_u, L_u2a_u_hat, L_u2a_a, L_u2a_a_hat),self.aNum,False],\n",
    "            [(L_u2o_u, L_u2o_u_hat, L_u2o_o, L_u2o_o_hat),self.oNum,False]\n",
    "        ]\n",
    "        \n",
    "        L_i2i, L_i2i_hat = self.Movielens_buildLaplacianMat_i2i()\n",
    "        L_i2g_i, L_i2g_i_hat, L_i2g_g, L_i2g_g_hat = self.Movielens_buildLaplacianMat_i2g()\n",
    "        self.i2es = [\n",
    "            [(L_i2i, L_i2i_hat,None),0,True],\n",
    "            [(L_i2g_i, L_i2g_i_hat, L_i2g_g_hat),self.gNum,False]\n",
    "        ]\n",
    "        \n",
    "        self.i2es2 = [\n",
    "            [(L_i2i, L_i2i_hat,None,None),0,True],\n",
    "            [(L_i2g_i, L_i2g_i_hat, L_i2g_g, L_i2g_g_hat),self.gNum,False]\n",
    "        ]\n",
    "        self.full,self.full_hat = self.Movielens_buildLaplacianMat_full()\n",
    "        self.num_list = [self.uNum,self.iNum,self.aNum,self.oNum,self.gNum]\n",
    "    \n",
    "    def Movielens_get_nums(self):\n",
    "        df_u2i = pd.read_csv(self.filepaths[1])\n",
    "        return df_u2i['uid'].max()+1,df_u2i['iid'].max()+1\n",
    "    \n",
    "    def Movielens_split(self,df_u2i):\n",
    "        \"\"\" \n",
    "        interact>20 ---> [n-20:10:10]\n",
    "        20>=interact>10 ---> [n-10:0:10]\n",
    "        10>=interact ---> [n:0:0]\n",
    "        \n",
    "        \"\"\"\n",
    "        rd_val = []\n",
    "        for i in range(len(df_u2i)):\n",
    "            rd_val.append(random.random())\n",
    "        df_u2i['random_val']=rd_val\n",
    "        df_u2i['rank'] = df_u2i.groupby(['uid'])['random_val'].rank(method='first', ascending=False)\n",
    "\n",
    "        grouped = df_u2i.groupby(['uid'])\n",
    "        test1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        dev1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        train1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        for name,group in tqdm.tqdm(grouped):\n",
    "            split_list = np.array_split(list(range(1,len(group)+1)),3)\n",
    "            train1 = train1.append(group[group['rank'].isin(split_list[0])])\n",
    "            test1 = test1.append(group[group['rank'].isin(split_list[1])])\n",
    "            dev1 = dev1.append(group[group['rank'].isin(split_list[2])])\n",
    "            \n",
    "        return train1[['uid', 'iid','negatives']],dev1[['uid', 'iid','negatives']], test1[['uid', 'iid','negatives']]\n",
    "    \n",
    "    def get_prob(self,neg_items,counter_dict):\n",
    "        \"\"\" get the prob of each neg_items\"\"\"\n",
    "        neg_occurance = [counter_dict[i] for i in neg_items] \n",
    "        neg_num = sum(neg_occurance)\n",
    "        neg_prob = [i/neg_num for i in neg_occurance]\n",
    "        return neg_prob\n",
    "    \n",
    "    def negative_sample(self,row_item,row_prob,row_len,neg_ratio,max_num):\n",
    "        if row_len * neg_ratio> max_num:\n",
    "            return np.random.choice(list(row_item),row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        else:\n",
    "            return np.random.choice(list(row_item),neg_ratio*row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        \n",
    "    def Movielens_get_negative_items(self,df_u2i,neg_ratio):\n",
    "        paper_pool = set(df_u2i['iid'].unique())\n",
    "        #max_num = len(paper_pool)\n",
    "        counter_dict = Counter(df_u2i['iid'])\n",
    "        interact_status = df_u2i.groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        interact_status['len'] = interact_status['interacted_items'].apply(lambda x:len(x))\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: paper_pool - x)\n",
    "        interact_status['negative_probs'] = interact_status['negative_items'].apply(lambda x:self.get_prob(x,counter_dict))\n",
    "        interact_status['len_neg'] = interact_status['negative_items'].apply(lambda x:len(x))\n",
    "        interact_status['negatives'] = interact_status.apply(lambda row:self.negative_sample(row['negative_items'],\n",
    "                                                                                            row['negative_probs'],\n",
    "                                                                                            row['len'],\n",
    "                                                                                            neg_ratio,\n",
    "                                                                                            row['len_neg']),axis=1)\n",
    "        return interact_status[['uid','interacted_items','negatives','len']]\n",
    "    \n",
    "    def Movielens_negative_allocation(self,neg):\n",
    "        neg['iids'] = neg['interacted_items'].apply(list)\n",
    "        neg['split_negtives'] = neg.apply(lambda row: list(np.array_split(row['negatives'], row['len'])),axis=1)\n",
    "        uids,iids,neg_items = [],[],[]\n",
    "        for row in neg.itertuples():\n",
    "            for i,n in zip(row.iids,row.split_negtives):\n",
    "                uids.append(row.uid)\n",
    "                iids.append(i)\n",
    "                neg_items.append(n)\n",
    "        full = pd.DataFrame()\n",
    "        full['uid']=uids\n",
    "        full['iid']=iids\n",
    "        full['negatives']=neg_items\n",
    "\n",
    "        return full[['uid','iid','negatives']] \n",
    "    \n",
    "    def Movielens_split_and_sample(self, neg_ratio):\n",
    "        df_u2i = pd.read_csv(self.filepaths[1]) \n",
    "        \n",
    "        neg = self.Movielens_get_negative_items(df_u2i,neg_ratio)\n",
    "        full = self.Movielens_negative_allocation(neg)\n",
    "        train,dev,test = self.Movielens_split(full)\n",
    "        if self.Store_flag:\n",
    "            train.to_csv(self.filepaths[0]+'train.csv')\n",
    "            dev.to_csv(self.filepaths[0]+'dev.csv')\n",
    "            test.to_csv(self.filepaths[0]+'test.csv')\n",
    "        return train,dev,test\n",
    "    \n",
    "    def data_split(self, neg_ratio):\n",
    "        if self.Load_flag==True:\n",
    "            #raise Exception(\"Dataset has been loaded.\")\n",
    "            train = pd.read_csv(self.filepaths[0]+'train.csv')\n",
    "            dev = pd.read_csv(self.filepaths[0]+'dev.csv')\n",
    "            test = pd.read_csv(self.filepaths[0]+'test.csv')\n",
    "        else:\n",
    "            train,dev,test = self.Movielens_split_and_sample(neg_ratio)\n",
    "        print('Dataset has been splited!')\n",
    "        return train,dev,test\n",
    "    ###############################################################################################################################\n",
    "    \n",
    "    def Movielens_build_input_data(self,dat_type):\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        input_dat= pd.DataFrame()\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "        else:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "                        \n",
    "        input_dat['uid']=users\n",
    "        input_dat['pos_iid']=pos_items\n",
    "        input_dat['neg_iid']=neg_items\n",
    "        return input_dat\n",
    "    \n",
    "    def Movielens_build_eval_data(self):\n",
    "        users,items,ratings = [],[],[]\n",
    "        eval_dev=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        eval_dev['uid']=users\n",
    "        eval_dev['iid']=items\n",
    "        eval_dev['rating']=ratings\n",
    "        \n",
    "        users,items,ratings = [],[],[]\n",
    "        eval_test=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        eval_test['uid']=users\n",
    "        eval_test['iid']=items\n",
    "        eval_test['rating']=ratings\n",
    "        \n",
    "        return eval_dev,eval_test\n",
    "    ###############################################################################################################################\n",
    "    def Movielens_sample_mp_neighbor(self,df):\n",
    "        sample_df = pd.DataFrame([],columns = ['uid','iid'])\n",
    "        grouped_df = df.groupby('uid')\n",
    "        for name,group in tqdm.tqdm(grouped_df):\n",
    "            if len(group)> 100:\n",
    "                    sample_df = sample_df.append(group.sample(n=50, replace=False))\n",
    "            if 100>=len(group)>10:\n",
    "                    sample_df = sample_df.append(group.sample(frac=0.2, replace=False))\n",
    "            if len(group)<=10:\n",
    "                    sample_df = sample_df.append(group)\n",
    "        return sample_df\n",
    "                    \n",
    "    def Movielens_create_mp_neighbor_graph(self):\n",
    "        \"\"\"\n",
    "        creat metapath neighbor: UI, UIBI,UIVI,UICI\n",
    "        and transform to DGL Graph\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            df_uigi = pd.read_csv(self.filepaths[0]+'uigi.csv')\n",
    "            df_uii = pd.read_csv(self.filepaths[0]+'uii.csv')\n",
    "            df_uaui = pd.read_csv(self.filepaths[0]+'uaui.csv')\n",
    "            df_uoui = pd.read_csv(self.filepaths[0]+'uoui.csv')\n",
    "            df_uui = pd.read_csv(self.filepaths[0]+'uui.csv')\n",
    "        else:\n",
    "            temp = pd.merge(self.train[['uid','iid']], self.i2g[['iid','gid']], on=['iid'])\n",
    "            temp = temp.drop(columns=['iid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uigi = pd.merge(temp,self.i2g[['iid','gid']],on=['gid'])\n",
    "            df_uigi = df_uigi[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            \n",
    "            df_uii = pd.merge(self.train[['uid','iid']],self.i2i[['iid','iid_2']],on=['iid'])\n",
    "            df_uii = df_uii[['uid','iid_2']].drop_duplicates().reset_index(drop=True)\n",
    "            df_uii = df_uii.rename(columns={'iid_2': 'iid'})\n",
    "            \n",
    "            temp = pd.merge(self.train[['uid','iid']], self.u2a[['uid','aid']], on=['uid'])\n",
    "            temp = temp.drop(columns=['uid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uaui = pd.merge(temp,self.u2a[['uid','aid']],on=['aid'])\n",
    "            df_uaui = df_uaui[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            \n",
    "            temp = pd.merge(self.train[['uid','iid']], self.u2o[['uid','oid']], on=['uid'])\n",
    "            temp = temp.drop(columns=['uid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uoui = pd.merge(temp,self.u2o[['uid','oid']],on=['oid'])\n",
    "            df_uoui = df_uoui[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            \n",
    "            df_uui = pd.merge(self.train[['uid','iid']],self.u2u[['uid','uid_2']],on=['uid'])\n",
    "            df_uui = df_uui[['uid_2','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            df_uui = df_uui.rename(columns={'uid_2': 'uid'})\n",
    "            #sample (sample standard? sample strategy?)\n",
    "            \n",
    "            if len(df_uigi)>200000:\n",
    "                print('length of df_uigi:',len(df_uigi),'start sampling...') \n",
    "                df_uigi = self.Movielens_sample_mp_neighbor(df_uigi)\n",
    "\n",
    "            if len(df_uii)>200000:\n",
    "                print('length of df_uii:',len(df_uii),'start sampling...') \n",
    "                df_uii = self.Movielens_sample_mp_neighbor(df_uii)\n",
    "                \n",
    "            if len(df_uaui)>200000:\n",
    "                print('length of df_uaui:',len(df_uaui),'start sampling...') \n",
    "                df_uaui = self.Movielens_sample_mp_neighbor(df_uaui)\n",
    "                \n",
    "            if len(df_uoui)>200000:\n",
    "                print('length of df_uoui:',len(df_uoui),'start sampling...') \n",
    "                df_uoui = self.Movielens_sample_mp_neighbor(df_uoui)\n",
    "                \n",
    "            if len(df_uui)>200000:\n",
    "                print('length of df_uui:',len(df_uui),'start sampling...') \n",
    "                df_uui = self.Movielens_sample_mp_neighbor(df_uui)\n",
    "                \n",
    "            if self.Store_flag==True:\n",
    "                df_uigi.to_csv('Movielens/uigi.csv')\n",
    "                df_uii.to_csv('Movielens/uii.csv')\n",
    "                df_uaui.to_csv('Movielens/uaui.csv')\n",
    "                df_uoui.to_csv('Movielens/uoui.csv')\n",
    "                df_uui.to_csv('Movielens/uui.csv')\n",
    "\n",
    "        df_uigi['n_iid'] = df_uigi['iid'].apply(lambda x: x+self.uNum)        \n",
    "        df_uii['n_iid'] = df_uii['iid'].apply(lambda x: x+self.uNum)\n",
    "        df_uaui['n_iid'] = df_uaui['iid'].apply(lambda x: x+self.uNum)\n",
    "        df_uoui['n_iid'] = df_uoui['iid'].apply(lambda x: x+self.uNum)\n",
    "        df_uui['n_iid'] = df_uui['iid'].apply(lambda x: x+self.uNum)\n",
    "        self.train['n_iid'] = self.train['iid'].apply(lambda x: x+self.uNum)\n",
    "        \n",
    "        g_ui = dgl.DGLGraph()\n",
    "        g_ui.add_nodes(self.uNum+self.iNum)\n",
    "        g_ui.add_edges(self.train['uid'].tolist(),self.train['n_iid'].tolist())\n",
    "        g_ui.add_edges(self.train['n_iid'].tolist(),self.train['uid'].tolist())\n",
    "        \n",
    "        g_uigi = dgl.DGLGraph()\n",
    "        g_uigi.add_nodes(self.uNum+self.iNum)\n",
    "        g_uigi.add_edges(df_uigi['uid'].tolist(),df_uigi['n_iid'].tolist())\n",
    "        g_uigi.add_edges(df_uigi['n_iid'].tolist(),df_uigi['uid'].tolist())\n",
    "        \n",
    "        g_uii = dgl.DGLGraph()\n",
    "        g_uii.add_nodes(self.uNum+self.iNum)\n",
    "        g_uii.add_edges(df_uii['uid'].tolist(),df_uii['n_iid'].tolist())\n",
    "        g_uii.add_edges(df_uii['n_iid'].tolist(),df_uii['uid'].tolist())\n",
    "        \n",
    "        g_uaui = dgl.DGLGraph()\n",
    "        g_uaui.add_nodes(self.uNum+self.iNum)\n",
    "        g_uaui.add_edges(df_uaui['uid'].tolist(),df_uaui['n_iid'].tolist())\n",
    "        g_uaui.add_edges(df_uaui['n_iid'].tolist(),df_uaui['uid'].tolist())\n",
    "        \n",
    "        g_uoui = dgl.DGLGraph()\n",
    "        g_uoui.add_nodes(self.uNum+self.iNum)\n",
    "        g_uoui.add_edges(df_uoui['uid'].tolist(),df_uoui['n_iid'].tolist())\n",
    "        g_uoui.add_edges(df_uoui['n_iid'].tolist(),df_uoui['uid'].tolist())\n",
    "        \n",
    "        g_uui = dgl.DGLGraph()\n",
    "        g_uui.add_nodes(self.uNum+self.iNum)\n",
    "        g_uui.add_edges(df_uui['uid'].tolist(),df_uui['n_iid'].tolist())\n",
    "        g_uui.add_edges(df_uui['n_iid'].tolist(),df_uui['uid'].tolist())\n",
    "        \n",
    "        return [g_ui,g_uigi,g_uii,g_uaui,g_uoui,g_uui]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################################################################################\n",
    "    def getSparseEye(self,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(0,num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    def getSparseEye_down(self,num_span,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(num_span,num_span+num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    def getSparseEye_upper(self,num_span,num):\n",
    "        row = [k for k in range(0,num_span)]\n",
    "        row.append(num_span-1)\n",
    "        col = [j for j in range(0,num_span)]\n",
    "        col.append(num_span+num-1)\n",
    "        i = torch.LongTensor([row,col])\n",
    "        val = torch.FloatTensor([1]*num_span)\n",
    "        val = torch.cat([val,torch.FloatTensor([0])])\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    \n",
    "    def Movielens_buildLaplacianMat_u2u(self):\n",
    "        uuMat = coo_matrix((self.u2u['link'], (self.u2u['uid'], self.u2u['uid_2'])))\n",
    "        A = uuMat\n",
    "        selfLoop = sparse.eye(self.uNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    def Movielens_buildLaplacianMat_i2i(self):\n",
    "        iiMat = coo_matrix((self.i2i['link'], (self.i2i['iid'], self.i2i['iid_2'])))\n",
    "        A = iiMat\n",
    "        selfLoop = sparse.eye(self.iNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.iNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    \n",
    "    def Movielens_buildLaplacianMat_u2i(self):\n",
    "        rt_item = self.train['iid'] + self.uNum\n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['uid'], self.train['iid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.train['rating'], (self.train['uid'], rt_item)))\n",
    "        uiMat_upperPart.resize((self.uNum, self.uNum + self.iNum))\n",
    "        \n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.iNum, self.uNum + self.iNum))\n",
    "        #print(uiMat_upperPart.shape,uiMat.shape)\n",
    "        \n",
    "        print(uiMat_upperPart.shape,uiMat.shape)\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.uNum+self.iNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        #print(L.shape)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row =np.append(row,self.uNum + self.iNum-1)\n",
    "        col =np.append(col,self.uNum + self.iNum-1)\n",
    "        data =np.append(data,0)\n",
    "        \n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum)\n",
    "        return SparseL,SparseL+SL\n",
    "    \n",
    "    def Movielens_buildLaplacianMat_i2g(self):\n",
    "        rt_item = self.i2g['gid'] + self.iNum\n",
    "        uiMat = coo_matrix((self.i2g['link'], (self.i2g['iid'], self.i2g['gid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.i2g['link'], (self.i2g['iid'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.gNum, self.iNum + self.gNum))\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.iNum + self.gNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.iNum)\n",
    "        row_index_down = np.where(row>=self.iNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.iNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.iNum+self.gNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.iNum,self.gNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.iNum),self.gNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.iNum+self.gNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.iNum,self.gNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Movielens_buildLaplacianMat_u2a(self):\n",
    "        rt_item = self.u2a['aid'] + self.uNum\n",
    "        uiMat = coo_matrix((self.u2a['link'], (self.u2a['uid'], self.u2a['aid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.u2a['link'], (self.u2a['uid'], rt_item)))\n",
    "        #uiMat_upperPart.resize((self.uNum, self.uNum + self.iNum))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.aNum, self.uNum + self.aNum))\n",
    "        \n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.uNum+self.aNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.uNum)\n",
    "        row_index_down = np.where(row>=self.uNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.uNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.uNum+self.aNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.uNum,self.aNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.uNum),self.aNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.uNum+self.aNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.uNum,self.aNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Movielens_buildLaplacianMat_u2o(self):\n",
    "        rt_item = self.u2o['oid'] + self.uNum\n",
    "        uiMat = coo_matrix((self.u2o['link'], (self.u2o['uid'], self.u2o['oid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.u2o['link'], (self.u2o['uid'], rt_item)))\n",
    "        #uiMat_upperPart.resize((self.uNum, self.uNum + self.iNum))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.oNum, self.uNum + self.oNum))\n",
    "        \n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.uNum+self.oNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.uNum)\n",
    "        row_index_down = np.where(row>=self.uNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.uNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.uNum+self.oNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.uNum,self.oNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.uNum),self.oNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.uNum+self.oNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.uNum,self.oNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Movielens_buildLaplacianMat_full(self):\n",
    "        \"\"\"  \n",
    "        u - i - a - o - g\n",
    "        \"\"\"\n",
    "        uuMat = coo_matrix((self.u2u['link'], (self.u2u['uid'], self.u2u['uid_2'])))\n",
    "        uuMat.resize((self.uNum,self.uNum))\n",
    "\n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['uid'], self.train['iid'])))\n",
    "        uiMat.resize((self.uNum,self.iNum))\n",
    "\n",
    "        uaMat = coo_matrix((self.u2a['link'], (self.u2a['uid'], self.u2a['aid'])))\n",
    "        uaMat.resize((self.uNum,self.aNum))\n",
    "\n",
    "        uoMat = coo_matrix((self.u2o['link'], (self.u2o['uid'], self.u2o['oid'])))\n",
    "        uoMat.resize((self.uNum,self.oNum+self.gNum))\n",
    "\n",
    "        uMat = sparse.hstack([uuMat,uiMat,uaMat,uoMat])\n",
    "        ###################################################    \n",
    "        iuMat = uiMat.transpose()\n",
    "\n",
    "        iiMat = coo_matrix((self.i2i['link'], (self.i2i['iid'], self.i2i['iid_2'])))\n",
    "        iiMat.resize(self.iNum,self.iNum+self.aNum+self.oNum)\n",
    "\n",
    "        igMat = coo_matrix((self.i2g['link'], (self.i2g['iid'], self.i2g['gid'])))\n",
    "        igMat.resize((self.iNum,self.gNum))\n",
    "\n",
    "        iMat = sparse.hstack([iuMat,iiMat,igMat])\n",
    "        ###################################################   \n",
    "        auMat = uaMat.transpose()\n",
    "        auMat.resize((self.aNum,self.uNum+self.iNum+self.aNum+self.oNum+self.gNum))\n",
    "\n",
    "        ouMat = uoMat.transpose()\n",
    "        ouMat.resize((self.oNum,self.uNum+self.iNum+self.aNum+self.oNum+self.gNum))\n",
    "\n",
    "        giMat = coo_matrix((self.i2g['link'], (self.i2g['gid'], self.i2g['iid']+self.uNum)))\n",
    "        giMat.resize((self.gNum,self.uNum+self.iNum+self.aNum+self.oNum+self.gNum))\n",
    "\n",
    "        full = sparse.vstack([uMat,iMat,auMat,ouMat,giMat])\n",
    "        A = full\n",
    "        #selfLoop = sparse.eye(self.uNum+self.iNum+self.aNum+self.oNum+self.gNumm)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum+self.aNum+self.oNum+self.gNum)\n",
    "\n",
    "        return SparseL, SparseL+SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2672, 2672), torch.Size([2672, 2672]), torch.Size([2672, 2672]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dat.uNum+dat.iNum+dat.aNum+dat.oNum+dat.gNum\n",
    "full.shape,SparseL.shape,SL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been splited!\n",
      "943\n",
      "1682\n",
      "(943, 2625) (1682, 2625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:465: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:432: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:497: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:661: RuntimeWarning: divide by zero encountered in power\n"
     ]
    }
   ],
   "source": [
    "filepaths_ACM = [\n",
    "    'ACM/',\n",
    "    'ACM/a2p.csv',\n",
    "    'ACM/p2p.csv',\n",
    "    'ACM/a2a.csv'\n",
    "]\n",
    "\n",
    "filepaths_Movielens = [\n",
    "    'Movielens/',\n",
    "    'Movielens/u2i.csv',\n",
    "    'Movielens/i2g.csv',\n",
    "    'Movielens/i2i.csv',\n",
    "    'Movielens/u2g.csv',\n",
    "    'Movielens/u2o.csv',\n",
    "    'Movielens/u2u.csv'\n",
    "]\n",
    "\n",
    "filepaths_Amazon = [\n",
    "    'Amazon/',\n",
    "    'Amazon/u2i.csv',\n",
    "    'Amazon/i2b.csv',\n",
    "    'Amazon/i2c.csv',\n",
    "    'Amazon/i2v.csv'\n",
    "]\n",
    "\n",
    "config_dat = {\n",
    "    'filepaths':filepaths_Movielens,\n",
    "    'dataset_name':'ACM',\n",
    "    'isLoad':True,\n",
    "    'store':False,\n",
    "    'neg_num4train':5,\n",
    "    'neg_num4eval':5\n",
    "}\n",
    "\n",
    "dat = Movielens_Dataset(config_dat)\n",
    "\n",
    "userNum = dat.uNum\n",
    "itemNum = dat.iNum\n",
    "\n",
    "para = {\n",
    "    'dropout':0,\n",
    "    'num_heads':[4],\n",
    "    'num_meta_paths':3,\n",
    "    'epoch_strat':-1,\n",
    "    'continue':False,\n",
    "    'is_load':True,\n",
    "    'device_id':1,\n",
    "    'num_users':userNum,\n",
    "    'num_items':itemNum,\n",
    "    #'layers':[128,32,16,8],\n",
    "    'layers':[64,64,64,64],\n",
    "    'proj_dim':32,\n",
    "    'embed_dim':64,\n",
    "    'hidden_dim':32,\n",
    "    'latent_dim_mf':16,\n",
    "    'latent_dim_mlp':64,\n",
    "    'cuda':True,\n",
    "    'epoch':500,\n",
    "    'loss_type':'BPR',\n",
    "    'lr':1e-3,\n",
    "    'weight_decay':0.01,\n",
    "    'batch_size':128,\n",
    "    'train':0.8,\n",
    "    'patience':10# 当验证集损失在连续20次训练周期中都没有得到降低时，停止模型训练，以防止模型过拟合\n",
    "}\n",
    "\n",
    "input_train = Wrap_Dataset(user_tensor=torch.LongTensor(dat.input_train['uid']),\n",
    "                            pos_item_tensor=torch.LongTensor(dat.input_train['pos_iid']),\n",
    "                            neg_item_tensor=torch.LongTensor(dat.input_train['neg_iid']))\n",
    "input_train_loader = DataLoader(input_train, batch_size=para['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric Increased (inf --> -0.466594).  Saving model ...\n",
      "Epoch 00000 | Time(s) nan | Train_Loss 56.1005 | Val_Loss 18633.4219 | Val_HR@5 0.2116 | Val_NDCG@5 0.4666\n",
      "Validation metric Increased (-0.466594 --> -0.488960).  Saving model ...\n",
      "Epoch 00001 | Time(s) nan | Train_Loss 41.3668 | Val_Loss 18438.3867 | Val_HR@5 0.2201 | Val_NDCG@5 0.4890\n",
      "Validation metric Increased (-0.488960 --> -0.496297).  Saving model ...\n",
      "Epoch 00002 | Time(s) nan | Train_Loss 37.1790 | Val_Loss 18296.6133 | Val_HR@5 0.2234 | Val_NDCG@5 0.4963\n",
      "Validation metric Increased (-0.496297 --> -0.502886).  Saving model ...\n",
      "Epoch 00003 | Time(s) 17.9914 | Train_Loss 35.0571 | Val_Loss 18245.7891 | Val_HR@5 0.2278 | Val_NDCG@5 0.5029\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 00004 | Time(s) 18.1727 | Train_Loss 33.6074 | Val_Loss 18153.9336 | Val_HR@5 0.2280 | Val_NDCG@5 0.5024\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 00005 | Time(s) 18.2575 | Train_Loss 32.3191 | Val_Loss 18204.8711 | Val_HR@5 0.2287 | Val_NDCG@5 0.5005\n",
      "Validation metric Increased (-0.502886 --> -0.507234).  Saving model ...\n",
      "Epoch 00006 | Time(s) 18.3169 | Train_Loss 31.1020 | Val_Loss 18193.8086 | Val_HR@5 0.2299 | Val_NDCG@5 0.5072\n",
      "Validation metric Increased (-0.507234 --> -0.511779).  Saving model ...\n",
      "Epoch 00007 | Time(s) 18.4049 | Train_Loss 29.9606 | Val_Loss 18140.9062 | Val_HR@5 0.2324 | Val_NDCG@5 0.5118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 00008 | Time(s) 18.3423 | Train_Loss 28.8118 | Val_Loss 18083.1484 | Val_HR@5 0.2315 | Val_NDCG@5 0.5106\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 00009 | Time(s) 18.3101 | Train_Loss 27.5873 | Val_Loss 18108.4844 | Val_HR@5 0.2289 | Val_NDCG@5 0.5059\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 00010 | Time(s) 18.2517 | Train_Loss 26.2775 | Val_Loss 18188.3691 | Val_HR@5 0.2299 | Val_NDCG@5 0.5081\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 00011 | Time(s) 18.3122 | Train_Loss 24.9172 | Val_Loss 18155.4863 | Val_HR@5 0.2302 | Val_NDCG@5 0.5096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 00012 | Time(s) 18.3515 | Train_Loss 23.5300 | Val_Loss 18150.4277 | Val_HR@5 0.2305 | Val_NDCG@5 0.5097\n",
      "Validation metric Increased (-0.511779 --> -0.514419).  Saving model ...\n",
      "Epoch 00013 | Time(s) 18.3219 | Train_Loss 22.1646 | Val_Loss 18086.6133 | Val_HR@5 0.2306 | Val_NDCG@5 0.5144\n",
      "Validation metric Increased (-0.514419 --> -0.518158).  Saving model ...\n",
      "Epoch 00014 | Time(s) 18.3348 | Train_Loss 20.8857 | Val_Loss 18236.2500 | Val_HR@5 0.2333 | Val_NDCG@5 0.5182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 00015 | Time(s) 18.3831 | Train_Loss 19.6220 | Val_Loss 18234.6836 | Val_HR@5 0.2326 | Val_NDCG@5 0.5171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 00016 | Time(s) 18.4560 | Train_Loss 18.4418 | Val_Loss 18290.1777 | Val_HR@5 0.2332 | Val_NDCG@5 0.5155\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 00017 | Time(s) 18.4208 | Train_Loss 17.3494 | Val_Loss 18431.9707 | Val_HR@5 0.2314 | Val_NDCG@5 0.5131\n",
      "Validation metric Increased (-0.518158 --> -0.519287).  Saving model ...\n",
      "Epoch 00018 | Time(s) 18.3989 | Train_Loss 16.3583 | Val_Loss 18447.0762 | Val_HR@5 0.2330 | Val_NDCG@5 0.5193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 00019 | Time(s) 18.3849 | Train_Loss 15.5330 | Val_Loss 18601.5781 | Val_HR@5 0.2308 | Val_NDCG@5 0.5158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 00020 | Time(s) 18.3781 | Train_Loss 14.7880 | Val_Loss 18646.9180 | Val_HR@5 0.2289 | Val_NDCG@5 0.5146\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 00021 | Time(s) 18.3645 | Train_Loss 14.1578 | Val_Loss 18621.2344 | Val_HR@5 0.2312 | Val_NDCG@5 0.5176\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 00022 | Time(s) 18.3552 | Train_Loss 13.6325 | Val_Loss 18677.9805 | Val_HR@5 0.2323 | Val_NDCG@5 0.5141\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 00023 | Time(s) 18.3571 | Train_Loss 13.2416 | Val_Loss 18727.3320 | Val_HR@5 0.2289 | Val_NDCG@5 0.5068\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 00024 | Time(s) 18.3656 | Train_Loss 12.8250 | Val_Loss 18620.3887 | Val_HR@5 0.2290 | Val_NDCG@5 0.5136\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 00025 | Time(s) 18.3780 | Train_Loss 12.4649 | Val_Loss 18785.0469 | Val_HR@5 0.2294 | Val_NDCG@5 0.5119\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 00026 | Time(s) 18.3606 | Train_Loss 12.2326 | Val_Loss 18852.5508 | Val_HR@5 0.2303 | Val_NDCG@5 0.5139\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 00027 | Time(s) 18.3652 | Train_Loss 11.9513 | Val_Loss 18915.7852 | Val_HR@5 0.2297 | Val_NDCG@5 0.5129\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "#model = NHGCF2(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "#model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "#model = NHGCF3_noattn(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "#model = NHGCF_norelation(para,dat.full,dat.full_hat,dat.num_list)\n",
    "#model = NHGCF3_share_proj(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "model = NHGCF3_smooth(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "#model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#model.module.weight_init()\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "    \n",
    "if para['continue'] == True:\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "BCE_lossfunc = BCEWithLogitsLoss()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "patience = para['patience'] \n",
    "early_stopping = EarlyStopping(patience, verbose=True) \n",
    "dur = []\n",
    "loss_record=[]\n",
    "hr_record=[]\n",
    "ndcg_record=[]\n",
    "for epoch in range(para['epoch']):\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    loss_log = []\n",
    "    model.train() # 设置模型为训练模式\n",
    "    for _id,batch in enumerate(input_train_loader):\n",
    "        optim.zero_grad()\n",
    "        if para['cuda']:\n",
    "            train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "        else:\n",
    "            train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "        #print(train_loss)\n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "        loss_log.append(train_loss.item())\n",
    "        \n",
    "    val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    \n",
    "    loss_record.append(np.mean(loss_log))\n",
    "    hr_record.append(hr)\n",
    "    ndcg_record.append(ndcg)\n",
    "    \n",
    "    if epoch > para['epoch_strat']:\n",
    "        early_stopping(ndcg*(-1), model)   \n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break # 结束模型训练   \n",
    "        \n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "    \n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "            \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "                                             hr, ndcg))\n",
    "x=list(range(epoch+1))   \n",
    "#plt.plot(x,loss_record,label=\"loss\")\n",
    "plt.plot(x,hr_record,label=\"HR@5\")\n",
    "plt.plot(x,ndcg_record,label=\"NDCG@5\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric Increased (inf --> -0.360141).  Saving model ...\n",
      "Validation metric Increased (-0.360141 --> -0.384132).  Saving model ...\n",
      "Validation metric Increased (-0.384132 --> -0.398624).  Saving model ...\n",
      "Validation metric Increased (-0.398624 --> -0.404441).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.404441 --> -0.405206).  Saving model ...\n",
      "Validation metric Increased (-0.405206 --> -0.405450).  Saving model ...\n",
      "Validation metric Increased (-0.405450 --> -0.406099).  Saving model ...\n",
      "Validation metric Increased (-0.406099 --> -0.407265).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.407265 --> -0.410072).  Saving model ...\n",
      "Validation metric Increased (-0.410072 --> -0.417778).  Saving model ...\n",
      "Validation metric Increased (-0.417778 --> -0.418449).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.418449 --> -0.426855).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.426855 --> -0.428081).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.428081 --> -0.430962).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.430962 --> -0.435076).  Saving model ...\n",
      "Validation metric Increased (-0.435076 --> -0.440996).  Saving model ...\n",
      "Validation metric Increased (-0.440996 --> -0.441253).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.441253 --> -0.441912).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Validation metric Increased (-0.441912 --> -0.444148).  Saving model ...\n",
      "Validation metric Increased (-0.444148 --> -0.449147).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.449147 --> -0.451514).  Saving model ...\n",
      "Validation metric Increased (-0.451514 --> -0.452766).  Saving model ...\n",
      "Validation metric Increased (-0.452766 --> -0.452932).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.452932 --> -0.456229).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.456229 --> -0.461024).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.461024 --> -0.466115).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.466115 --> -0.467984).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.467984 --> -0.468876).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Validation metric Increased (-0.468876 --> -0.472498).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.472498 --> -0.479283).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Validation metric Increased (-0.479283 --> -0.479666).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Validation metric Increased (-0.479666 --> -0.480753).  Saving model ...\n",
      "Validation metric Increased (-0.480753 --> -0.482719).  Saving model ...\n",
      "Validation metric Increased (-0.482719 --> -0.483055).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.483055 --> -0.483209).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.483209 --> -0.483845).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.483845 --> -0.484644).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Validation metric Increased (-0.484644 --> -0.488613).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 8 hr: 0.2121813031161473 ndcg: 0.47233380752694154\n",
      "Validation metric Increased (inf --> -0.376733).  Saving model ...\n",
      "Validation metric Increased (-0.376733 --> -0.413534).  Saving model ...\n",
      "Validation metric Increased (-0.413534 --> -0.439623).  Saving model ...\n",
      "Validation metric Increased (-0.439623 --> -0.446384).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.446384 --> -0.451554).  Saving model ...\n",
      "Validation metric Increased (-0.451554 --> -0.459062).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.459062 --> -0.459337).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.459337 --> -0.463380).  Saving model ...\n",
      "Validation metric Increased (-0.463380 --> -0.465574).  Saving model ...\n",
      "Validation metric Increased (-0.465574 --> -0.468805).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.468805 --> -0.469648).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.469648 --> -0.474342).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.474342 --> -0.477915).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.477915 --> -0.478691).  Saving model ...\n",
      "Validation metric Increased (-0.478691 --> -0.479346).  Saving model ...\n",
      "Validation metric Increased (-0.479346 --> -0.481117).  Saving model ...\n",
      "Validation metric Increased (-0.481117 --> -0.487704).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.487704 --> -0.488564).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.488564 --> -0.490463).  Saving model ...\n",
      "Validation metric Increased (-0.490463 --> -0.490509).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.490509 --> -0.493605).  Saving model ...\n",
      "Validation metric Increased (-0.493605 --> -0.498193).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.498193 --> -0.500319).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Validation metric Increased (-0.500319 --> -0.501864).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Validation metric Increased (-0.501864 --> -0.504310).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.504310 --> -0.506905).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 16 hr: 0.21600566572237961 ndcg: 0.47803939903469705\n",
      "Validation metric Increased (inf --> -0.440050).  Saving model ...\n",
      "Validation metric Increased (-0.440050 --> -0.460106).  Saving model ...\n",
      "Validation metric Increased (-0.460106 --> -0.472944).  Saving model ...\n",
      "Validation metric Increased (-0.472944 --> -0.479103).  Saving model ...\n",
      "Validation metric Increased (-0.479103 --> -0.482936).  Saving model ...\n",
      "Validation metric Increased (-0.482936 --> -0.488861).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.488861 --> -0.492585).  Saving model ...\n",
      "Validation metric Increased (-0.492585 --> -0.492684).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.492684 --> -0.504153).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Validation metric Increased (-0.504153 --> -0.514147).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.514147 --> -0.517521).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 32 hr: 0.22705382436260624 ndcg: 0.4987852892965452\n",
      "Validation metric Increased (inf --> -0.478460).  Saving model ...\n",
      "Validation metric Increased (-0.478460 --> -0.495082).  Saving model ...\n",
      "Validation metric Increased (-0.495082 --> -0.501717).  Saving model ...\n",
      "Validation metric Increased (-0.501717 --> -0.508431).  Saving model ...\n",
      "Validation metric Increased (-0.508431 --> -0.513066).  Saving model ...\n",
      "Validation metric Increased (-0.513066 --> -0.514383).  Saving model ...\n",
      "Validation metric Increased (-0.514383 --> -0.514565).  Saving model ...\n",
      "Validation metric Increased (-0.514565 --> -0.514621).  Saving model ...\n",
      "Validation metric Increased (-0.514621 --> -0.516452).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.516452 --> -0.517666).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 128 hr: 0.2273371104815864 ndcg: 0.5046573126740095\n",
      "Validation metric Increased (inf --> -0.459049).  Saving model ...\n",
      "Validation metric Increased (-0.459049 --> -0.478405).  Saving model ...\n",
      "Validation metric Increased (-0.478405 --> -0.479498).  Saving model ...\n",
      "Validation metric Increased (-0.479498 --> -0.485140).  Saving model ...\n",
      "Validation metric Increased (-0.485140 --> -0.489742).  Saving model ...\n",
      "Validation metric Increased (-0.489742 --> -0.496227).  Saving model ...\n",
      "Validation metric Increased (-0.496227 --> -0.502022).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.502022 --> -0.504910).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.504910 --> -0.510344).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 8 hr: 0.230028328611898 ndcg: 0.5028757750762439\n",
      "Validation metric Increased (inf --> -0.449921).  Saving model ...\n",
      "Validation metric Increased (-0.449921 --> -0.476999).  Saving model ...\n",
      "Validation metric Increased (-0.476999 --> -0.487674).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.487674 --> -0.492203).  Saving model ...\n",
      "Validation metric Increased (-0.492203 --> -0.498097).  Saving model ...\n",
      "Validation metric Increased (-0.498097 --> -0.499282).  Saving model ...\n",
      "Validation metric Increased (-0.499282 --> -0.503833).  Saving model ...\n",
      "Validation metric Increased (-0.503833 --> -0.508083).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.508083 --> -0.510100).  Saving model ...\n",
      "Validation metric Increased (-0.510100 --> -0.512702).  Saving model ...\n",
      "Validation metric Increased (-0.512702 --> -0.513962).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.513962 --> -0.517852).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Validation metric Increased (-0.517852 --> -0.518177).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 16 hr: 0.2254957507082153 ndcg: 0.4927604330372059\n",
      "Validation metric Increased (inf --> -0.476320).  Saving model ...\n",
      "Validation metric Increased (-0.476320 --> -0.488107).  Saving model ...\n",
      "Validation metric Increased (-0.488107 --> -0.492569).  Saving model ...\n",
      "Validation metric Increased (-0.492569 --> -0.505474).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.505474 --> -0.507616).  Saving model ...\n",
      "Validation metric Increased (-0.507616 --> -0.509919).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.509919 --> -0.510983).  Saving model ...\n",
      "Validation metric Increased (-0.510983 --> -0.515104).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.515104 --> -0.515580).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 64 hr: 0.22577903682719547 ndcg: 0.5004616802691683\n",
      "Validation metric Increased (inf --> -0.472559).  Saving model ...\n",
      "Validation metric Increased (-0.472559 --> -0.490394).  Saving model ...\n",
      "Validation metric Increased (-0.490394 --> -0.497119).  Saving model ...\n",
      "Validation metric Increased (-0.497119 --> -0.497200).  Saving model ...\n",
      "Validation metric Increased (-0.497200 --> -0.502947).  Saving model ...\n",
      "Validation metric Increased (-0.502947 --> -0.503355).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric Increased (-0.503355 --> -0.507405).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.507405 --> -0.510513).  Saving model ...\n",
      "Validation metric Increased (-0.510513 --> -0.510748).  Saving model ...\n",
      "Validation metric Increased (-0.510748 --> -0.513754).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.513754 --> -0.516508).  Saving model ...\n",
      "Validation metric Increased (-0.516508 --> -0.517760).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 128 hr: 0.2245042492917847 ndcg: 0.49541900852548054\n"
     ]
    }
   ],
   "source": [
    "para['proj_dim'] = 32\n",
    "\n",
    "for dim in [8,16,32,128]:\n",
    "    para['embed_dim'] = dim\n",
    "    para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('embed dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)\n",
    "\n",
    "    \n",
    "para['embed_dim'] = 64\n",
    "para['layers'] = [64,64,64,64]    \n",
    "\n",
    "for dim in [8,16,64,128]:\n",
    "    para['proj_dim'] = dim\n",
    "    #para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('proj dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19292.3203125, 0.2281869688385269, 0.4986662326927002)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19257.76171875, 0.22322946175637393, 0.49072961698769446)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19542.7734375, 0.22861189801699716, 0.5079282621118746)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19260.427734375, 0.2177053824362606, 0.48081297191623146)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19064.94140625, 0.22691218130311613, 0.49517304028056475)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19661.974609375, 0.22337110481586403, 0.4937934733109644)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19336.13671875, 0.22492917847025495, 0.4938609294133564)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17141.859375, 0.24801699716713882, 0.5607515040090102)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置切分区域\n",
    "listBins = [0, 5, 10, 20,210]\n",
    "#设置切分后对应标签\n",
    "listLabels = ['0 - 5','6 - 10','11 - 20','>20']\n",
    "\n",
    "df_at = dat.test\n",
    "df_test = df_at.groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "df_test['len'] = df_test['interacted_items'].apply(lambda x:len(x))\n",
    "df_test = df_test[['uid','len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('MF327.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_MF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_MF['num'] = num_list\n",
    "\n",
    "df_MF['fenzu'] = pd.cut(df_MF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_MF_stat = df_MF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_MF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_MF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['layers']=[64,64,64,64]\n",
    "\n",
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NGCF327_2.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_NGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NGCF['num'] = num_list\n",
    "\n",
    "df_NGCF['fenzu'] = pd.cut(df_NGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NGCF_stat = df_NGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NGCF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "#model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('HAN327_2.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_HAN = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_HAN['num'] = num_list\n",
    "\n",
    "df_HAN['fenzu'] = pd.cut(df_HAN['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_HAN_stat = df_HAN.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_HAN.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_HAN_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['layers']=[64,64]\n",
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "#model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NHGCF328_m.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_NHGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NHGCF['num'] = num_list\n",
    "\n",
    "df_NHGCF['fenzu'] = pd.cut(df_NHGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NHGCF_stat = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NHGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NHGCF_stat['num'] = num_list\n",
    "#df_NHGCF_stat['num'] = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.577827</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.449457</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 20</td>\n",
       "      <td>0.502533</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.573044</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg  num\n",
       "0    0 - 5  0.577827  446\n",
       "1   6 - 10  0.449457  178\n",
       "2  11 - 20  0.502533  142\n",
       "3      >20  0.573044   66"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NHGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.586918</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.426449</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 20</td>\n",
       "      <td>0.461246</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.553049</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg  num\n",
       "0    0 - 5  0.586918  437\n",
       "1   6 - 10  0.426449  183\n",
       "2  11 - 20  0.461246  137\n",
       "3      >20  0.553049   63"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HAN_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.568980</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.456352</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 20</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.526166</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg  num\n",
       "0    0 - 5  0.568980  435\n",
       "1   6 - 10  0.456352  181\n",
       "2  11 - 20  0.478981  136\n",
       "3      >20  0.526166   65"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.556940</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.408952</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 20</td>\n",
       "      <td>0.440290</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.472178</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg  num\n",
       "0    0 - 5  0.556940  435\n",
       "1   6 - 10  0.408952  177\n",
       "2  11 - 20  0.440290  135\n",
       "3      >20  0.472178   58"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=500)\n",
    "#plt.figure(figsize=(10,5))\n",
    "fig, ax1 = plt.subplots(figsize = (6, 5))\n",
    "\n",
    "width = 0.5\n",
    "#index = np.arange(len(listLabels))\n",
    "#tick_label = listLabels\n",
    "#ax1.bar(index,df_MF_stat['num'],width =width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width,df_HAN_stat['num'],width =width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width,df_NGCF_stat['num'],width =width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width+width,df_NHGCF_stat['num'],width =width,color='lightgray',label=\"NHGCF_recall\",align=\"center\")\n",
    "#ax1.set_ylabel('Recall Num')\n",
    "#ax1.set_xticks(index+width*1.5, tick_label)\n",
    "#ax1.legend(loc='upper center')\n",
    "\n",
    "ax1.bar(listLabels,df_MF_stat['num'],width = width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NGCF_stat['num'],width = width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_HAN_stat['num'],width = width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NHGCF_stat['num'],width = width,color='lightgray',label=\"Ours_recall\",align=\"center\")\n",
    "ax1.set_ylabel(' Num',fontsize=12)\n",
    "ax1.set_xlabel('User Group\\n(divided by interaction num)',fontsize=15)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(listLabels,df_MF_stat['ave_ndcg'],label=\"MF\",marker='o')\n",
    "ax2.plot(listLabels,df_NGCF_stat['ave_ndcg'],label=\"NGCF\",marker='v')\n",
    "ax2.plot(listLabels,df_HAN_stat['ave_ndcg'],label=\"HAN\",marker='*')\n",
    "ax2.plot(listLabels,df_NHGCF_stat['ave_ndcg'],label=\"Ours\",marker='s')\n",
    "#ax2.hlines(0.70, -1, 8, linestyles = \"dashed\")\n",
    "#ax2.plot(listLabels,df_NeuMF_stat['ave_ndcg'],label=\"NeuMF\",marker='o')\n",
    "#ax2.set_ylim(.65,.90)\n",
    "ax2.set_ylabel('NDCG@5',fontsize=12)\n",
    "ax2.yaxis.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)\n",
    "\n",
    "#ax1.legend(loc='lower left')\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[3].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[3].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[3].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            #nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=128):\n",
    "        super(SemanticAttention, self).__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "\n",
    "        return (beta * z).sum(1)\n",
    "\n",
    "class HANLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    HAN layer.\n",
    "    Arguments\n",
    "    ---------\n",
    "    num_meta_paths : number of homogeneous graphs generated from the metapaths.\n",
    "    in_size : input feature dimension\n",
    "    out_size : output feature dimension\n",
    "    layer_num_heads : number of attention heads\n",
    "    dropout : Dropout probability\n",
    "    Inputs\n",
    "    ------\n",
    "    g : list[DGLGraph]\n",
    "        List of graphs\n",
    "    h : tensor\n",
    "        Input features\n",
    "    Outputs\n",
    "    -------\n",
    "    tensor\n",
    "        The output feature\n",
    "    \"\"\"\n",
    "    def __init__(self, num_meta_paths, in_size, out_size, layer_num_heads, dropout):\n",
    "        super(HANLayer, self).__init__()\n",
    "\n",
    "        # One GAT layer for each meta path based adjacency matrix\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        for i in range(num_meta_paths):\n",
    "            self.gat_layers.append(GATConv(in_size, out_size, layer_num_heads,\n",
    "                                           dropout, dropout, activation=F.elu))\n",
    "        self.semantic_attention = SemanticAttention(in_size=out_size * layer_num_heads)\n",
    "        self.num_meta_paths = num_meta_paths\n",
    "\n",
    "    def forward(self, gs, h):\n",
    "        semantic_embeddings = []\n",
    "\n",
    "        for i, g in enumerate(gs):\n",
    "            semantic_embeddings.append(self.gat_layers[i](g, h).flatten(1))\n",
    "        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)                  # (N, M, D * K)\n",
    "\n",
    "        return self.semantic_attention(semantic_embeddings)                            # (N, D * K)\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self,config, gs):\n",
    "        super(HAN, self).__init__()\n",
    "        self.gs = gs\n",
    "        self.usecuda = config['cuda']\n",
    "        self.dropout = config['dropout']\n",
    "        self.num_heads = config['num_heads']\n",
    "        self.num_meta_paths = len(gs)\n",
    "        self.userNum = config['num_users']\n",
    "        self.itemNum = config['num_items']\n",
    "        self.uEmbd = nn.Embedding(config['num_users'],config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(config['num_items'],config['embed_dim'])\n",
    "        self.in_size = config['embed_dim']\n",
    "        self.hidden_size = config['hidden_dim']\n",
    "        #self.h = torch.cat((self.uEmbd,self.iEmbd),dim=0)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(HANLayer(self.num_meta_paths, self.in_size, self.hidden_size, self.num_heads[0], self.dropout))\n",
    "        for l in range(1, len(self.num_heads)):\n",
    "            self.layers.append(HANLayer(self.num_meta_paths, self.hidden_size * self.num_heads[l-1],\n",
    "                                        self.hidden_size,  self.num_heads[l],  self.dropout))\n",
    "        #self.predict = nn.Linear(hidden_size * num_heads[-1], 1)\n",
    "    \n",
    "    def weight_init(self):\n",
    "        wts = [\n",
    "            self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.layers[0].gat_layers[0].fc.weight,\n",
    "            self.layers[0].gat_layers[1].fc.weight,\n",
    "            self.layers[0].gat_layers[2].fc.weight,\n",
    "            self.layers[0].gat_layers[3].fc.weight,\n",
    "           # self.layers[0].gat_layers[3].fc.weight,\n",
    "            self.layers[0].gat_layers[4].fc.weight,\n",
    "            self.layers[0].gat_layers[5].fc.weight,\n",
    "            self.layers[0].semantic_attention.project[0].weight,\n",
    "            self.layers[0].semantic_attention.project[2].weight\n",
    "            #self.layers[1].gat_layers[0].fc.weight,\n",
    "            #self.layers[1].gat_layers[1].fc.weight,\n",
    "            #self.layers[1].gat_layers[2].fc.weight,\n",
    "            #self.layers[1].semantic_attention.project[0].weight,\n",
    "            #self.layers[1].semantic_attention.project[2].weight\n",
    "            #self.layers[2].gat_layers[0].fc.weight,\n",
    "            #self.layers[2].gat_layers[1].fc.weight,\n",
    "            #self.layers[2].gat_layers[2].fc.weight,\n",
    "            #self.layers[2].semantic_attention.project[0].weight,\n",
    "            #self.layers[2].semantic_attention.project[2].weight\n",
    "        ]\n",
    "        \n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)  \n",
    "    \n",
    "    def getFeatureMat(self):\n",
    "        uidx = torch.LongTensor([i for i in range(self.userNum)])\n",
    "        iidx = torch.LongTensor([i for i in range(self.itemNum)])\n",
    "        if self.usecuda  == True:\n",
    "            uidx = uidx.cuda()\n",
    "            iidx = iidx.cuda()\n",
    "        #print(type(uidx))\n",
    "        userEmbd = self.uEmbd(uidx)\n",
    "        itemEmbd = self.iEmbd(iidx)\n",
    "\n",
    "        features = torch.cat([userEmbd,itemEmbd],dim=0)\n",
    "        return features\n",
    "    \n",
    "    def forward(self, userIdx,itemIdx):\n",
    "        itemIdx = itemIdx + self.userNum\n",
    "        features = self.getFeatureMat()\n",
    "        #finalEmbd = features.clone()\n",
    "        for gnn in self.layers:\n",
    "            features = gnn(self.gs, features)\n",
    "            features = normalize(features, 2, 1) # L2 Norm\n",
    "          \n",
    "        userEmbd = features[userIdx]\n",
    "        itemEmbd = features[itemIdx]    \n",
    "        #print(userEmbd.size()) \n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "           \n",
    "\n",
    "class NHGCF2(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF2,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "        \n",
    "        \n",
    "        self.u_relation_attention = RelationAttention(in_size=config['embed_dim'])\n",
    "        self.i_relation_attention = RelationAttention(in_size=config['embed_dim'])\n",
    "        self.u2i_Cell = Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self.self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda),\n",
    "                                                           Message_Storage(self.useCuda)]))\n",
    "        \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self.self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda),\n",
    "                                                           Message_Storage(self.useCuda)]))\n",
    "        \n",
    "        self.layers = config['layers']\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    " \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.u_relation_attention.project[0].weight,\n",
    "            self.u_relation_attention.project[2].weight,\n",
    "            self.i_relation_attention.project[0].weight,\n",
    "            self.i_relation_attention.project[2].weight,\n",
    "            self.u2i_Cell.Transform.weight,\n",
    "            self.u2i_Cell.InterAct.weight,\n",
    "            self.u2e_Cells[0].Transform.weight,\n",
    "            self.u2e_Cells[0].InterAct.weight,\n",
    "            self.u2e_Cells[1][0].Transform.weight,\n",
    "            self.u2e_Cells[1][0].InterAct.weight,\n",
    "            self.u2e_Cells[2][0].Transform.weight,\n",
    "            self.u2e_Cells[2][0].InterAct.weight,\n",
    "            self.i2e_Cells[0].Transform.weight,\n",
    "            self.i2e_Cells[0].InterAct.weight,\n",
    "            self.i2e_Cells[1][0].Transform.weight,\n",
    "            self.i2e_Cells[1][0].InterAct.weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            #nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        \n",
    "        for _ in self.layers[:-1]:\n",
    "            u_embeddings = []\n",
    "            i_embeddings = []\n",
    "            u2e_embeddings =[]\n",
    "            i2e_embeddings =[]\n",
    "            for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(self.u2e_pack,u2e_features,self.u2e_Cells):\n",
    "                if self_tag is True:\n",
    "                    # self interact\n",
    "                    u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "                else:\n",
    "                    u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                    u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "            for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(self.i2e_pack,i2e_features,self.i2e_Cells):\n",
    "                if self_tag is True:\n",
    "                    # self interact\n",
    "                    i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "                else:\n",
    "                    i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                    i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "            temp = self.u2i_Cell(self.u2i_pack[0][0],self.u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "            i_embeddings.append(temp[self.userNum:]) \n",
    "            u_embeddings.append(temp[:self.userNum])\n",
    "\n",
    "            i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "            u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "            \n",
    "            u_feature = self.leakyRelu(self.u_relation_attention(u_embeddings))\n",
    "            i_feature = self.leakyRelu(self.i_relation_attention(i_embeddings))\n",
    "            \n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_embeddings]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_embeddings]\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell(L_down,L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell(L_down,L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHGCF3_noattn(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#model.module.weight_init()\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uEmbd.weight\n",
      "iEmbd.weight\n",
      "u2eEmbds.1.weight\n",
      "u2eEmbds.2.weight\n",
      "i2eEmbds.1.weight\n",
      "NHGCFLayers.0.u2i_Cell.Transform.weight\n",
      "NHGCFLayers.0.u2i_Cell.Transform.bias\n",
      "NHGCFLayers.0.u2i_Cell.InterAct.weight\n",
      "NHGCFLayers.0.u2i_Cell.InterAct.bias\n",
      "NHGCFLayers.0.u2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.0.u2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.0.u2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.0.u2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.0.u2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.0.u2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.0.u2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.0.u2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.0.u2e_Cells.2.Transform.weight\n",
      "NHGCFLayers.0.u2e_Cells.2.Transform.bias\n",
      "NHGCFLayers.0.u2e_Cells.2.InterAct.weight\n",
      "NHGCFLayers.0.u2e_Cells.2.InterAct.bias\n",
      "NHGCFLayers.0.i2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.0.i2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.0.i2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.0.i2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.0.i2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.0.i2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.0.i2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.0.i2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.0.u_relation_attention.project.0.weight\n",
      "NHGCFLayers.0.u_relation_attention.project.0.bias\n",
      "NHGCFLayers.0.u_relation_attention.project.2.weight\n",
      "NHGCFLayers.0.i_relation_attention.project.0.weight\n",
      "NHGCFLayers.0.i_relation_attention.project.0.bias\n",
      "NHGCFLayers.0.i_relation_attention.project.2.weight\n",
      "NHGCFLayers.1.u2i_Cell.Transform.weight\n",
      "NHGCFLayers.1.u2i_Cell.Transform.bias\n",
      "NHGCFLayers.1.u2i_Cell.InterAct.weight\n",
      "NHGCFLayers.1.u2i_Cell.InterAct.bias\n",
      "NHGCFLayers.1.u2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.1.u2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.1.u2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.1.u2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.1.u2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.1.u2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.1.u2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.1.u2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.1.u2e_Cells.2.Transform.weight\n",
      "NHGCFLayers.1.u2e_Cells.2.Transform.bias\n",
      "NHGCFLayers.1.u2e_Cells.2.InterAct.weight\n",
      "NHGCFLayers.1.u2e_Cells.2.InterAct.bias\n",
      "NHGCFLayers.1.i2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.1.i2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.1.i2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.1.i2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.1.i2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.1.i2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.1.i2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.1.i2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.1.u_relation_attention.project.0.weight\n",
      "NHGCFLayers.1.u_relation_attention.project.0.bias\n",
      "NHGCFLayers.1.u_relation_attention.project.2.weight\n",
      "NHGCFLayers.1.i_relation_attention.project.0.weight\n",
      "NHGCFLayers.1.i_relation_attention.project.0.bias\n",
      "NHGCFLayers.1.i_relation_attention.project.2.weight\n",
      "NHGCFLayers.2.u2i_Cell.Transform.weight\n",
      "NHGCFLayers.2.u2i_Cell.Transform.bias\n",
      "NHGCFLayers.2.u2i_Cell.InterAct.weight\n",
      "NHGCFLayers.2.u2i_Cell.InterAct.bias\n",
      "NHGCFLayers.2.u2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.2.u2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.2.u2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.2.u2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.2.u2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.2.u2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.2.u2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.2.u2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.2.u2e_Cells.2.Transform.weight\n",
      "NHGCFLayers.2.u2e_Cells.2.Transform.bias\n",
      "NHGCFLayers.2.u2e_Cells.2.InterAct.weight\n",
      "NHGCFLayers.2.u2e_Cells.2.InterAct.bias\n",
      "NHGCFLayers.2.i2e_Cells.0.Transform.weight\n",
      "NHGCFLayers.2.i2e_Cells.0.Transform.bias\n",
      "NHGCFLayers.2.i2e_Cells.0.InterAct.weight\n",
      "NHGCFLayers.2.i2e_Cells.0.InterAct.bias\n",
      "NHGCFLayers.2.i2e_Cells.1.Transform.weight\n",
      "NHGCFLayers.2.i2e_Cells.1.Transform.bias\n",
      "NHGCFLayers.2.i2e_Cells.1.InterAct.weight\n",
      "NHGCFLayers.2.i2e_Cells.1.InterAct.bias\n",
      "NHGCFLayers.2.u_relation_attention.project.0.weight\n",
      "NHGCFLayers.2.u_relation_attention.project.0.bias\n",
      "NHGCFLayers.2.u_relation_attention.project.2.weight\n",
      "NHGCFLayers.2.i_relation_attention.project.0.weight\n",
      "NHGCFLayers.2.i_relation_attention.project.0.bias\n",
      "NHGCFLayers.2.i_relation_attention.project.2.weight\n",
      "torch.Size([943, 64])\n",
      "torch.Size([943, 64])\n",
      "torch.Size([943, 64])\n",
      "torch.Size([943, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.6567, 2.6567, 2.6567, 2.6567, 2.6567, 2.6937, 2.6937, 2.6937, 2.6937,\n",
       "        2.6937, 2.5666, 2.5666, 2.5666, 2.5666, 2.5666, 2.6206, 2.6206, 2.6206,\n",
       "        2.6206, 2.6206], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #pass\n",
    "        \n",
    "model(torch.tensor(dat.input_dev[:20]['uid']).cuda(),torch.tensor(dat.input_dev[:20]['pos_iid']).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -1, -1],\n",
       "        [ 6,  6,  6]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.tensor([[1,1,1],[2,2,2]]),torch.tensor([[-1,-1,-1],[2,2,2]]),torch.tensor([[-1,-1,-1],[2,2,2]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell(L_down,L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell(L_down,L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        \n",
    "        return torch.sum(u_embeddings, dim=1),torch.sum(i_embeddings, dim=1),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3_noattn(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3_noattn,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,num_list,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        \n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "        self.aNum = num_list[2]\n",
    "        self.oNum = num_list[3]\n",
    "        self.gNum = num_list[4]\n",
    "        \n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        full =  inter_part1+inter_part2\n",
    "        u_feature = full[:self.uNum]\n",
    "        i_feature = full[self.uNum:self.iNum+self.uNum]\n",
    "        a_feature = full[self.iNum+self.uNum:self.iNum+self.uNum+self.aNum]\n",
    "        o_feature = full[self.iNum+self.uNum+self.aNum:self.iNum+self.uNum+self.aNum+self.oNum]\n",
    "        g_feature = full[self.iNum+self.uNum+self.aNum+self.oNum:]\n",
    "        return u_feature,i_feature,a_feature,o_feature,g_feature\n",
    "\n",
    "class NHGCF_norelation(Module):\n",
    "\n",
    "    def __init__(self,config,L,L_hat,num_list):\n",
    "\n",
    "        super(NHGCF_norelation,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "        self.aNum = num_list[2]\n",
    "        self.oNum = num_list[3]\n",
    "        self.gNum = num_list[4]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.uNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.iNum,config['embed_dim'])\n",
    "        self.aEmbd = nn.Embedding(self.aNum,config['embed_dim'])\n",
    "        self.oEmbd = nn.Embedding(self.oNum,config['embed_dim'])\n",
    "        self.gEmbd = nn.Embedding(self.gNum,config['embed_dim'])\n",
    "        \n",
    "        self.layers = config['layers']\n",
    "        self.GNNlayers = torch.nn.ModuleList()\n",
    "        self.L = L # sparse format\n",
    "        self.L_hat = L_hat\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "        \n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.GNNlayers.append(Message_Passing(From,To,num_list,self.useCuda))\n",
    "    \n",
    "     # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "              self.iEmbd.weight,\n",
    "              self.aEmbd.weight,\n",
    "              self.oEmbd.weight,\n",
    "              self.gEmbd.weight,        \n",
    "              self.GNNlayers[0].Transform.weight,\n",
    "              self.GNNlayers[0].InterAct.weight,\n",
    "              self.GNNlayers[1].Transform.weight,\n",
    "              self.GNNlayers[1].InterAct.weight,\n",
    "              self.GNNlayers[2].Transform.weight,\n",
    "              self.GNNlayers[2].InterAct.weight\n",
    "              #self.transForm1.weight,\n",
    "              #self.transForm2.weight,\n",
    "              #self.transForm3.weight,\n",
    "              ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)      \n",
    "\n",
    "\n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "        \n",
    "        u_feature = self.getFeatureMat(self.uNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.iNum,self.iEmbd)\n",
    "        a_feature = self.getFeatureMat(self.aNum,self.aEmbd)\n",
    "        o_feature = self.getFeatureMat(self.oNum,self.oEmbd)\n",
    "        g_feature = self.getFeatureMat(self.gNum,self.gEmbd)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.GNNlayers:\n",
    "            u_feature,i_feature,a_feature,o_feature,g_feature = gnn(self.L,self.L_hat,torch.cat([u_feature,i_feature,\n",
    "                                                                                                 a_feature,o_feature,g_feature]))\n",
    "            u_feature = normalize(self.leakyRelu(u_feature), 2, 1)\n",
    "            i_feature = normalize(self.leakyRelu(i_feature), 2, 1)\n",
    "            a_feature = normalize(self.leakyRelu(a_feature), 2, 1)\n",
    "            o_feature = normalize(self.leakyRelu(o_feature), 2, 1)\n",
    "            g_feature = normalize(self.leakyRelu(g_feature), 2, 1)\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "            \n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHGCF_norelation(para,dat.full,dat.full_hat,dat.num_list)\n",
    "\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#model.module.weight_init()\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uEmbd.weight\n",
      "iEmbd.weight\n",
      "aEmbd.weight\n",
      "oEmbd.weight\n",
      "gEmbd.weight\n",
      "GNNlayers.0.Transform.weight\n",
      "GNNlayers.0.Transform.bias\n",
      "GNNlayers.0.InterAct.weight\n",
      "GNNlayers.0.InterAct.bias\n",
      "GNNlayers.1.Transform.weight\n",
      "GNNlayers.1.Transform.bias\n",
      "GNNlayers.1.InterAct.weight\n",
      "GNNlayers.1.InterAct.bias\n",
      "GNNlayers.2.Transform.weight\n",
      "GNNlayers.2.Transform.bias\n",
      "GNNlayers.2.InterAct.weight\n",
      "GNNlayers.2.InterAct.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.9358, 2.9358, 2.9358, 2.9358, 2.9358, 2.9496, 2.9496, 2.9496, 2.9496,\n",
       "        2.9496, 2.9354, 2.9354, 2.9354, 2.9354, 2.9354, 2.9531, 2.9531, 2.9531,\n",
       "        2.9531, 2.9531], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #pass\n",
    "        \n",
    "model(torch.tensor(dat.input_dev[:20]['uid']).cuda(),torch.tensor(dat.input_dev[:20]['pos_iid']).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.mp = Message_Passing(inF,outF,useCuda)\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature in zip(u2e_pack,u2e_features):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(self.mp(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(self.mp(L_down,L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(self.mp(L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature in zip(i2e_pack,i2e_features):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(self.mp(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(self.mp(L_down,L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(self.mp(L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.mp(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return torch.sum(u_embeddings, dim=1),torch.sum(i_embeddings, dim=1),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3_share_proj(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3_share_proj,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].mp.Transform.weight,\n",
    "            self.NHGCFLayers[0].mp.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].mp.Transform.weight,\n",
    "            self.NHGCFLayers[1].mp.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].mp.Transform.weight,\n",
    "            self.NHGCFLayers[2].mp.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "class Message_Passing2(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing2,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing2(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(Message_Passing2(inF,outF,useCuda))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing2(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(Message_Passing2(inF,outF,useCuda))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        #u_embedding = u_feature.clone()\n",
    "        #i_embedding = i_feature.clone()\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embedding=temp[u_num:]\n",
    "        u_embedding=temp[:u_num]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embedding += u2e_Cell(L_upper,u_feature)\n",
    "            else:\n",
    "                u_embedding += u2e_Cell(L_upper,torch.cat([u_feature,u2e_feature],dim=0))\n",
    "                \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                pass\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell(L_down,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embedding += i2e_Cell(L_upper,i_feature)\n",
    "            else:\n",
    "                i_embedding += i2e_Cell(L_upper,torch.cat([i_feature,i2e_feature],dim=0))\n",
    "                \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                pass\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell(L_down,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "\n",
    "        return u_embedding,i_embedding,u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3_smooth(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3_smooth,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[2].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.u2eEmbds[1].weight,\n",
    "            self.u2eEmbds[2].weight,\n",
    "            self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
