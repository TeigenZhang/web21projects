{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import tqdm\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Module\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import BCELoss,BCEWithLogitsLoss\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam,Adadelta,RMSprop\n",
    "\n",
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda._initialized = True\n",
    "\n",
    "#from src.Dataset import ACM_Dataset,Amazon_Dataset,Movielens_Dataset\n",
    "from src.models import MF,NeuMF,GCF\n",
    "from src.Utils import BPRLoss,Wrap_Dataset,EarlyStopping\n",
    "#from src.Evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)]) if x<=top_k else sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    return len(truth_in_top_k) * 1.0 / (df_static['len'].sum())\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return full['ndcg'].sum() * 1.0 / df_eval['uid'].nunique()\n",
    "\n",
    "def evaluate(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio(df_eval,df_static,top_k),call_ndcg(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    stat = full[['uid','len','rating']].groupby('uid')['rating'].apply(sum).reset_index().rename(columns={'rating': 'recall_num'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    stat2['hr_perU'] = stat2.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    #stat['hr'] = stat.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    return stat2[['uid','len','recall_num','hr_perU']]\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    \n",
    "    stat = full[['uid','len','ndcg']].groupby('uid')['ndcg'].apply(sum).reset_index().rename(columns={'ndcg': 'ndcg_perU'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return stat2[['uid','len','ndcg_perU']]\n",
    "\n",
    "def evaluate2(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio2(df_eval,df_static,top_k),call_ndcg2(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_at = pd.read_csv('ACM/a2p.csv')\n",
    "interact_status = df_at.groupby('aid')['pid'].apply(set).reset_index().rename(columns={'pid': 'interacted_items'})\n",
    "interact_status['len'] = interact_status['interacted_items'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         aid interacted_items  len\n",
       " 0          0           {5521}    1\n",
       " 4          4            {893}    1\n",
       " 5          5           {5782}    1\n",
       " 11        11           {3817}    1\n",
       " 12        12           {1523}    1\n",
       " ...      ...              ...  ...\n",
       " 18374  18374           {6361}    1\n",
       " 18382  18382          {10602}    1\n",
       " 18383  18383            {614}    1\n",
       " 18384  18384           {2520}    1\n",
       " 18386  18386           {3539}    1\n",
       " \n",
       " [5586 rows x 3 columns],          aid interacted_items  len\n",
       " 0          0           {5521}    1\n",
       " 4          4            {893}    1\n",
       " 5          5           {5782}    1\n",
       " 7          7     {6297, 9615}    2\n",
       " 10        10     {8098, 2292}    2\n",
       " ...      ...              ...  ...\n",
       " 18382  18382          {10602}    1\n",
       " 18383  18383            {614}    1\n",
       " 18384  18384           {2520}    1\n",
       " 18386  18386           {3539}    1\n",
       " 18387  18387      {798, 9951}    2\n",
       " \n",
       " [8450 rows x 3 columns],          aid   interacted_items  len\n",
       " 0          0             {5521}    1\n",
       " 4          4              {893}    1\n",
       " 5          5             {5782}    1\n",
       " 7          7       {6297, 9615}    2\n",
       " 8          8  {5585, 298, 7326}    3\n",
       " ...      ...                ...  ...\n",
       " 18382  18382            {10602}    1\n",
       " 18383  18383              {614}    1\n",
       " 18384  18384             {2520}    1\n",
       " 18386  18386             {3539}    1\n",
       " 18387  18387        {798, 9951}    2\n",
       " \n",
       " [10447 rows x 3 columns],          aid          interacted_items  len\n",
       " 0          0                    {5521}    1\n",
       " 3          3  {6544, 9019, 210, 10587}    4\n",
       " 4          4                     {893}    1\n",
       " 5          5                    {5782}    1\n",
       " 6          6  {6544, 2874, 5331, 1030}    4\n",
       " ...      ...                       ...  ...\n",
       " 18382  18382                   {10602}    1\n",
       " 18383  18383                     {614}    1\n",
       " 18384  18384                    {2520}    1\n",
       " 18386  18386                    {3539}    1\n",
       " 18387  18387               {798, 9951}    2\n",
       " \n",
       " [12882 rows x 3 columns])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_status[interact_status['len']<=1],interact_status[interact_status['len']<=2],interact_status[interact_status['len']<=3],interact_status[interact_status['len']<=5],\n",
    "#interact_status[(interact_status['len']>5) & (interact_status['len']<=10)],interact_status[interact_status['len']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACM_Dataset(object):\n",
    "    def __init__(self,config_dat):\n",
    "        self.dataset_name = config_dat['dataset_name']\n",
    "        #self.model_name = model_name\n",
    "        self.Load_flag = config_dat['isLoad']\n",
    "        self.Store_flag =config_dat['store']\n",
    "        self.filepaths = config_dat['filepaths']\n",
    "        self.uNum,self.iNum = self.ACM_get_nums()\n",
    "        self.train,self.dev,self.test = self.data_split(config_dat['neg_num4train'])\n",
    "        #self.train = self.train.append([self.uNum-1,self.iNum-1,None])\n",
    "        self.train['rating'] = [1 for i in range(len(self.train))]\n",
    "        self.input_train = self.ACM_build_input_data(1)\n",
    "        self.input_dev = self.ACM_build_input_data(2)\n",
    "        self.input_test = self.ACM_build_input_data(3)\n",
    "        self.eval_dev,self.eval_test = self.ACM_build_eval_data()\n",
    "        \n",
    "        self.a2a,self.p2p = self.ACM_relation_process()\n",
    "        self.mp_graphs = self.ACM_create_mp_neighbor_graph()\n",
    "        \n",
    "        L_u2i,L_u2i_hat = self.ACM_buildLaplacianMat_u2i()\n",
    "        L_u2u,L_u2u_hat = self.ACM_buildLaplacianMat_u2u()\n",
    "        L_i2i,L_i2i_hat = self.ACM_buildLaplacianMat_i2i()\n",
    "        self.u2i = [(L_u2i,L_u2i_hat),[self.uNum,self.iNum]]\n",
    "        self.u2es = [[(L_u2u,L_u2u_hat,None),0,True]]\n",
    "        self.i2es = [[(L_i2i,L_i2i_hat,None),0,True]]\n",
    "        \n",
    "        self.full,self.full_hat = self.ACM_buildLaplacianMat_full()\n",
    "        self.num_list = [self.uNum,self.iNum]\n",
    "        \n",
    "    def ACM_get_nums(self):\n",
    "        df_a2p = pd.read_csv(self.filepaths[1])\n",
    "        return df_a2p['aid'].max()+1,df_a2p['pid'].max()+1\n",
    "    \n",
    "    def ACM_split(self,df_u2i):\n",
    "        \"\"\" \n",
    "        interact>20 ---> [n-20:10:10]\n",
    "        20>=interact>10 ---> [n-10:0:10]\n",
    "        10>=interact ---> [n:0:0]\n",
    "        \n",
    "        \"\"\"\n",
    "        rd_val = []\n",
    "        for i in range(len(df_u2i)):\n",
    "            rd_val.append(random.random())\n",
    "        df_u2i['random_val']=rd_val\n",
    "        df_u2i['rank'] = df_u2i.groupby(['aid'])['random_val'].rank(method='first', ascending=False)\n",
    "\n",
    "        grouped = df_u2i.groupby(['aid'])\n",
    "        test1 = pd.DataFrame([], columns=['aid', 'pid','negatives'])\n",
    "        dev1 = pd.DataFrame([], columns=['aid', 'pid','negatives'])\n",
    "        train1 = pd.DataFrame([], columns=['aid', 'pid','negatives'])\n",
    "        for name,group in tqdm.tqdm(grouped):\n",
    "            split_list = np.array_split(list(range(1,len(group)+1)),3)\n",
    "            train1 = train1.append(group[group['rank'].isin(split_list[0])])\n",
    "            test1 = test1.append(group[group['rank'].isin(split_list[1])])\n",
    "            dev1 = dev1.append(group[group['rank'].isin(split_list[2])])\n",
    "            \n",
    "        return train1[['aid', 'pid','negatives']],dev1[['aid', 'pid','negatives']], test1[['aid', 'pid','negatives']]\n",
    "    \n",
    "    def get_prob(self,neg_items,counter_dict):\n",
    "        \"\"\" get the prob of each neg_items\"\"\"\n",
    "        neg_occurance = [counter_dict[i] for i in neg_items] \n",
    "        neg_num = sum(neg_occurance)\n",
    "        neg_prob = [i/neg_num for i in neg_occurance]\n",
    "        return neg_prob\n",
    "    \n",
    "    def negative_sample(self,row_item,row_prob,row_len,neg_ratio,max_num):\n",
    "        if row_len * neg_ratio> max_num:\n",
    "            return np.random.choice(list(row_item),row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        else:\n",
    "            return np.random.choice(list(row_item),neg_ratio*row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        \n",
    "    def ACM_get_negative_items(self,df_u2i,neg_ratio):\n",
    "        paper_pool = set(df_u2i['pid'].unique())\n",
    "        #max_num = len(paper_pool)\n",
    "        counter_dict = Counter(df_u2i['pid'])\n",
    "        interact_status = df_u2i.groupby('aid')['pid'].apply(set).reset_index().rename(columns={'pid': 'interacted_items'})\n",
    "        interact_status['len'] = interact_status['interacted_items'].apply(lambda x:len(x))\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: paper_pool - x)\n",
    "        interact_status['negative_probs'] = interact_status['negative_items'].apply(lambda x:self.get_prob(x,counter_dict))\n",
    "        interact_status['len_neg'] = interact_status['negative_items'].apply(lambda x:len(x))\n",
    "        interact_status['negatives'] = interact_status.apply(lambda row:self.negative_sample(row['negative_items'],\n",
    "                                                                                            row['negative_probs'],\n",
    "                                                                                            row['len'],\n",
    "                                                                                            neg_ratio,\n",
    "                                                                                            row['len_neg']),axis=1)\n",
    "        return interact_status[['aid','interacted_items','negatives','len']]\n",
    "    \n",
    "    def ACM_negative_allocation(self,neg):\n",
    "        neg['pids'] = neg['interacted_items'].apply(list)\n",
    "        neg['split_negtives'] = neg.apply(lambda row: list(np.array_split(row['negatives'], row['len'])),axis=1)\n",
    "        uids,iids,neg_items = [],[],[]\n",
    "        for row in neg.itertuples():\n",
    "            for i,n in zip(row.pids,row.split_negtives):\n",
    "                uids.append(row.aid)\n",
    "                iids.append(i)\n",
    "                neg_items.append(n)\n",
    "        full = pd.DataFrame()\n",
    "        full['aid']=uids\n",
    "        full['pid']=iids\n",
    "        full['negatives']=neg_items\n",
    "\n",
    "        return full[['aid','pid','negatives']] \n",
    "    \n",
    "    def ACM_split_and_sample(self, neg_ratio):\n",
    "        df_u2i = pd.read_csv(self.filepaths[1]) \n",
    "        \n",
    "        neg = self.ACM_get_negative_items(df_u2i,neg_ratio)\n",
    "        full = self.ACM_negative_allocation(neg)\n",
    "        train,dev,test = self.ACM_split(full)\n",
    "        if self.Store_flag:\n",
    "            train.to_csv(self.filepaths[0]+'train.csv')\n",
    "            dev.to_csv(self.filepaths[0]+'dev.csv')\n",
    "            test.to_csv(self.filepaths[0]+'test.csv')\n",
    "        return train,dev,test\n",
    "    \n",
    "    def data_split(self, neg_ratio):\n",
    "        if self.Load_flag==True:\n",
    "            #raise Exception(\"Dataset has been loaded.\")\n",
    "            train = pd.read_csv(self.filepaths[0]+'train.csv')\n",
    "            dev = pd.read_csv(self.filepaths[0]+'dev.csv')\n",
    "            test = pd.read_csv(self.filepaths[0]+'test.csv')\n",
    "        else:\n",
    "            train,dev,test = self.ACM_split_and_sample(neg_ratio)\n",
    "        print('Dataset has been splited!')\n",
    "        return train,dev,test\n",
    "    ###############################################################################################################################\n",
    "    def ACM_build_input_data(self,dat_type):\n",
    "        authors, pos_papers, neg_papers = [], [], []\n",
    "        input_dat= pd.DataFrame()\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "        else:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        authors.append(int(row.aid))\n",
    "                        pos_papers.append(int(row.pid))\n",
    "                        neg_papers.append(int(i))\n",
    "                        \n",
    "        input_dat['uid']=authors\n",
    "        input_dat['pos_iid']=pos_papers\n",
    "        input_dat['neg_iid']=neg_papers\n",
    "        return input_dat\n",
    "    \n",
    "    def ACM_build_eval_data(self):\n",
    "        authors,papers,ratings = [],[],[]\n",
    "        eval_dev=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    authors.append(int(row.aid))\n",
    "                    papers.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                authors.append(int(row.aid))\n",
    "                papers.append(int(row.pid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    authors.append(int(row.aid))\n",
    "                    papers.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                authors.append(int(row.aid))\n",
    "                papers.append(int(row.pid))\n",
    "                ratings.append(float(1))\n",
    "        eval_dev['uid']=authors\n",
    "        eval_dev['iid']=papers\n",
    "        eval_dev['rating']=ratings\n",
    "        \n",
    "        authors,papers,ratings = [],[],[]\n",
    "        eval_test=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    authors.append(int(row.aid))\n",
    "                    papers.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                authors.append(int(row.aid))\n",
    "                papers.append(int(row.pid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    authors.append(int(row.aid))\n",
    "                    papers.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                authors.append(int(row.aid))\n",
    "                papers.append(int(row.pid))\n",
    "                ratings.append(float(1))\n",
    "        eval_test['uid']=authors\n",
    "        eval_test['iid']=papers\n",
    "        eval_test['rating']=ratings\n",
    "        \n",
    "        return eval_dev,eval_test\n",
    "    ###############################################################################################################################\n",
    "    \n",
    "    def ACM_relation_process(self):\n",
    "        \"\"\"\n",
    "        load relation data\n",
    "        if relation is self interaction ---> drop self link\n",
    "        \n",
    "        \"\"\"\n",
    "        # load data\n",
    "        df_a2a = pd.read_csv(self.filepaths[0]+'a2a.csv')\n",
    "        df_p2p = pd.read_csv(self.filepaths[0]+'p2p.csv')\n",
    "        \n",
    "        # self link drop\n",
    "        df_a2a = df_a2a[df_a2a['aid']!=df_a2a['aid_2']]\n",
    "        df_p2p = df_p2p[df_p2p['pid']!=df_p2p['pid_2']]\n",
    "        \n",
    "        # add link flag\n",
    "        df_a2a['link']=[1 for i in range(len(df_a2a))]\n",
    "        df_p2p['link']=[1 for i in range(len(df_p2p))]\n",
    "        return df_a2a,df_p2p\n",
    "    \n",
    "    ###############################################################################################################################\n",
    "    def ACM_sample_mp_neighbor(self,df):\n",
    "        sample_df = pd.DataFrame([],columns = ['aid','pid'])\n",
    "        grouped_df = df.groupby('aid')\n",
    "        for name,group in tqdm.tqdm(grouped_df):\n",
    "            if len(group)> 100:\n",
    "                    sample_df = sample_df.append(group.sample(n=100, replace=False))\n",
    "            if 100>=len(group)>10:\n",
    "                    sample_df = sample_df.append(group.sample(frac=0.1, replace=False))\n",
    "            if len(group)<=10:\n",
    "                    sample_df = sample_df.append(group)\n",
    "        return sample_df\n",
    "                    \n",
    "    def ACM_create_mp_neighbor_graph(self):\n",
    "        \"\"\"\n",
    "        creat metapath neighbor: APP, AAP\n",
    "        and transform to DGL Graph\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            df_app = pd.read_csv(self.filepaths[0]+'app.csv')\n",
    "            df_aap = pd.read_csv(self.filepaths[0]+'aap.csv')\n",
    "        else:\n",
    "            df_app = pd.merge(self.train, self.p2p, on=['pid'])\n",
    "            \n",
    "            df_aap = pd.merge(self.a2a, self.train, on=['aid'])\n",
    "\n",
    "            df_aap = df_aap[['aid','pid']].drop_duplicates().reset_index(drop=True)\n",
    "            df_app = df_app[['aid','pid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            #sample (sample standard? sample strategy?)\n",
    "            \n",
    "            if len(df_app)>200000:\n",
    "                print('length of app:',len(df_app),'start sampling...') \n",
    "                df_app = self.ACM_sample_mp_neighbor(df_app)\n",
    "\n",
    "            if len(df_aap)>200000:\n",
    "                print('length of aap:',len(df_aap),'start sampling...') \n",
    "                df_aap = self.ACM_sample_mp_neighbor(df_aap)\n",
    "                \n",
    "            if self.Store_flag==True:\n",
    "                df_app.to_csv('ACM/app.csv')\n",
    "                df_aap.to_csv('ACM/aap.csv')\n",
    "\n",
    "        df_app['n_pid'] = df_app['pid'].apply(lambda x: x+self.uNum)        \n",
    "        df_aap['n_pid'] = df_aap['pid'].apply(lambda x: x+self.uNum)\n",
    "        self.train['n_pid'] = self.train['pid'].apply(lambda x: x+self.uNum)\n",
    "        \n",
    "        g_ap = dgl.DGLGraph()\n",
    "        g_ap.add_nodes(self.uNum+self.iNum)\n",
    "        g_ap.add_edges(self.train['aid'].tolist(),self.train['n_pid'].tolist())\n",
    "        g_ap.add_edges(self.train['n_pid'].tolist(),self.train['aid'].tolist())\n",
    "\n",
    "        g_app = dgl.DGLGraph()\n",
    "        g_app.add_nodes(self.uNum+self.iNum)\n",
    "        g_app.add_edges(df_app['aid'].tolist(),df_app['n_pid'].tolist())\n",
    "        g_app.add_edges(df_app['n_pid'].tolist(),df_app['aid'].tolist())\n",
    "\n",
    "        g_aap = dgl.DGLGraph()\n",
    "        g_aap.add_nodes(self.uNum+self.iNum)\n",
    "        g_aap.add_edges(df_aap['aid'].tolist(),df_aap['n_pid'].tolist())\n",
    "        g_aap.add_edges(df_aap['n_pid'].tolist(),df_aap['aid'].tolist())\n",
    "        \n",
    "        return [g_ap,g_app,g_aap]\n",
    "    \n",
    "    ###############################################################################################################################\n",
    "    def getSparseEye(self,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(0,num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    \n",
    "    def ACM_buildLaplacianMat_u2i(self):\n",
    "\n",
    "        rt_item = self.train['pid'] + self.uNum\n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['aid'], self.train['pid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.train['rating'], (self.train['aid'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.iNum, self.uNum + self.iNum))\n",
    "        uiMat_upperPart.resize((self.uNum, self.uNum + self.iNum))\n",
    "        \n",
    "        #print(self.uNum + self.iNum,uiMat_upperPart.shape,uiMat.shape)\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.uNum+self.iNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        # item的最后一号恰好没有交互，所以这里要补全\n",
    "        row = np.append(row,self.uNum + self.iNum-1)\n",
    "        col = np.append(col,self.uNum + self.iNum-1)\n",
    "        data = np.append(data,0)\n",
    "        \n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    def ACM_buildLaplacianMat_u2u(self):\n",
    "        uuMat = coo_matrix((self.a2a['link'], (self.a2a['aid'], self.a2a['aid_2'])))\n",
    "\n",
    "        # item的最后一号恰好没有交互，所以这里要补全\n",
    "        #iiMat.resize((self.iNum, self.uNum + self.iNum))\n",
    "        \n",
    "        #uiMat_upperPart = coo_matrix((rt['rating'], (rt['aid'], rt_item)))\n",
    "        #uiMat = uiMat.transpose()\n",
    "        #uiMat.resize((self.itemNum, self.userNum + self.itemNum))\n",
    "        \n",
    "        A = uuMat\n",
    "        selfLoop = sparse.eye(self.uNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        # item的最后一号恰好没有交互，所以这里要补全\n",
    "        #row = np.append(row,self.uNum + self.iNum-1)\n",
    "        #col = np.append(col,self.uNum + self.iNum-1)\n",
    "        #data = np.append(data,0)\n",
    "        \n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    \n",
    "    def ACM_buildLaplacianMat_i2i(self):\n",
    "        iiMat = coo_matrix((self.p2p['link'], (self.p2p['pid'], self.p2p['pid_2'])))\n",
    "\n",
    "        # item的最后一号恰好没有交互，所以这里要补全\n",
    "        iiMat.resize((self.iNum, self.iNum))\n",
    "        \n",
    "        #uiMat_upperPart = coo_matrix((rt['rating'], (rt['aid'], rt_item)))\n",
    "        #uiMat = uiMat.transpose()\n",
    "        #uiMat.resize((self.itemNum, self.userNum + self.itemNum))\n",
    "        \n",
    "        A = iiMat\n",
    "        selfLoop = sparse.eye(self.iNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        # item的最后一号恰好没有交互，所以这里要补全\n",
    "        row = np.append(row,self.iNum-1)\n",
    "        col = np.append(col,self.iNum-1)\n",
    "        data = np.append(data,0)\n",
    "        \n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.iNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    def ACM_buildLaplacianMat_full(self):\n",
    "        \"\"\"  \n",
    "        u - i \n",
    "        \"\"\"\n",
    "        uuMat = coo_matrix((self.a2a['link'], (self.a2a['aid'], self.a2a['aid_2'])))\n",
    "        uuMat.resize((self.uNum,self.uNum))\n",
    "        \n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['aid'], self.train['pid'])))\n",
    "        uiMat.resize((self.uNum,self.iNum))\n",
    "        \n",
    "        uMat = sparse.hstack([uuMat,uiMat])\n",
    "        uMat.resize((self.uNum,self.uNum+self.iNum))\n",
    "\n",
    "        ###################################################    \n",
    "        iuMat = coo_matrix((self.train['rating'], (self.train['pid'], self.train['aid'])))\n",
    "        iuMat.resize(self.iNum,self.uNum)\n",
    "        \n",
    "        iiMat = coo_matrix((self.p2p['link'], (self.p2p['pid'], self.p2p['pid_2'])))\n",
    "        iiMat.resize(self.iNum,self.iNum)\n",
    "        \n",
    "        iMat = sparse.hstack([iuMat,iiMat])\n",
    "        iMat.resize((self.iNum,self.uNum+self.iNum))\n",
    "        \n",
    "        full = sparse.vstack([uMat,iMat])\n",
    "        A = full\n",
    "        #selfLoop = sparse.eye(self.uNum+self.iNum+self.aNum+self.oNum+self.gNumm)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row = np.append(row,self.uNum + self.iNum-1)\n",
    "        col = np.append(col,self.uNum + self.iNum-1)\n",
    "        data = np.append(data,0)\n",
    "\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum)\n",
    "\n",
    "        return SparseL, SparseL+SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,proj_dim,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        self.proj_dim = config['proj_dim']\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To,self.proj_dim, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[2].i_relation_attention.project[2].weight\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight,\n",
    "              ]\n",
    "        wts2 = [\n",
    "            #self.u2eEmbds[1].weight,\n",
    "            #self.u2eEmbds[2].weight,\n",
    "            #self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been splited!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:336: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:407: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:456: RuntimeWarning: divide by zero encountered in power\n"
     ]
    }
   ],
   "source": [
    "filepaths_ACM = [\n",
    "    'ACM/',\n",
    "    'ACM/a2p.csv',\n",
    "    'ACM/p2p.csv',\n",
    "    'ACM/a2a.csv'\n",
    "]\n",
    "\n",
    "filepaths_Movielens = [\n",
    "    'Movielens/',\n",
    "    'Movielens/u2i.csv',\n",
    "    'Movielens/i2g.csv',\n",
    "    'Movielens/i2i.csv',\n",
    "    'Movielens/u2g.csv',\n",
    "    'Movielens/u2o.csv',\n",
    "    'Movielens/u2u.csv'\n",
    "]\n",
    "\n",
    "filepaths_Amazon = [\n",
    "    'Amazon/',\n",
    "    'Amazon/u2i.csv',\n",
    "    'Amazon/i2b.csv',\n",
    "    'Amazon/i2c.csv',\n",
    "    'Amazon/i2v.csv'\n",
    "]\n",
    "\n",
    "config_dat = {\n",
    "    'filepaths':filepaths_ACM,\n",
    "    'dataset_name':'ACM',\n",
    "    'isLoad':True,\n",
    "    'store':False,\n",
    "    'neg_num4train':5,\n",
    "    'neg_num4eval':5\n",
    "}\n",
    "\n",
    "dat = ACM_Dataset(config_dat)\n",
    "\n",
    "userNum = dat.uNum\n",
    "itemNum = dat.iNum\n",
    "\n",
    "para = {\n",
    "    'dropout':0,\n",
    "    'num_heads':[4],\n",
    "    'num_meta_paths':3,\n",
    "    'epoch_strat':0,\n",
    "    'continue':False,\n",
    "    'is_load':True,\n",
    "    'device_id':1,\n",
    "    'num_users':userNum,\n",
    "    'num_items':itemNum,\n",
    "    #'layers':[128,32,16,8],\n",
    "    'layers':[64,64,64],\n",
    "    'proj_dim':32,\n",
    "    'embed_dim':64,\n",
    "    'hidden_dim':32,\n",
    "    'latent_dim_mf':16,\n",
    "    'latent_dim_mlp':64,\n",
    "    'cuda':True,\n",
    "    'epoch':500,\n",
    "    'loss_type':'BPR',\n",
    "    'lr':5e-3,\n",
    "    'weight_decay':0.0001,\n",
    "    'batch_size':128,\n",
    "    'train':0.8,\n",
    "    'patience':10 # 当验证集损失在连续20次训练周期中都没有得到降低时，停止模型训练，以防止模型过拟合\n",
    "}\n",
    "\n",
    "input_train = Wrap_Dataset(user_tensor=torch.LongTensor(dat.input_train['uid']),\n",
    "                            pos_item_tensor=torch.LongTensor(dat.input_train['pos_iid']),\n",
    "                            neg_item_tensor=torch.LongTensor(dat.input_train['neg_iid']))\n",
    "input_train_loader = DataLoader(input_train, batch_size=para['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Train_Loss 19.5216 | Val_Loss 48984.3281 | Val_HR@5 0.5538 | Val_NDCG@5 0.8298\n",
      "Validation metric Increased (inf --> -0.827520).  Saving model ...\n",
      "Epoch 00001 | Time(s) nan | Train_Loss 3.6970 | Val_Loss 50130.0117 | Val_HR@5 0.5540 | Val_NDCG@5 0.8275\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 00002 | Time(s) nan | Train_Loss 1.6146 | Val_Loss 51662.6875 | Val_HR@5 0.5550 | Val_NDCG@5 0.8239\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 00003 | Time(s) 168.1522 | Train_Loss 1.5077 | Val_Loss 52897.5625 | Val_HR@5 0.5534 | Val_NDCG@5 0.8209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0e7f4a30fe29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpara\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBPR_lossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBPR_lossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\src\\Utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, u, pos, neg)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mxui\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mxuj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxui\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxuj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-7fe43e56f040>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, userIdx, itemIdx)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mi_finalEmbd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgnn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGNNlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mu_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mu_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakyRelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mi_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakyRelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-7fe43e56f040>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, L, L_hat, features)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0museCuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mL_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0minter_part1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0minter_part2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterAct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "model = NHGCF_norelation(para,dat.full,dat.full_hat,dat.num_list)\n",
    "\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#model.module.weight_init()\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "    \n",
    "if para['continue'] == True:\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "BCE_lossfunc = BCEWithLogitsLoss()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "patience = para['patience'] \n",
    "early_stopping = EarlyStopping(patience, verbose=True) \n",
    "dur = []\n",
    "loss_record=[]\n",
    "hr_record=[]\n",
    "ndcg_record=[]\n",
    "for epoch in range(para['epoch']):\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    loss_log = []\n",
    "    model.train() # 设置模型为训练模式\n",
    "    for _id,batch in enumerate(input_train_loader):\n",
    "        optim.zero_grad()\n",
    "        if para['cuda']:\n",
    "            train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "        else:\n",
    "            train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "        #print(train_loss)\n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "        loss_log.append(train_loss.item())\n",
    "        \n",
    "    val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    \n",
    "    loss_record.append(np.mean(loss_log))\n",
    "    hr_record.append(hr)\n",
    "    ndcg_record.append(ndcg)\n",
    "    \n",
    "    if epoch > para['epoch_strat']:\n",
    "        early_stopping(ndcg*(-1), model)   \n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break # 结束模型训练   \n",
    "        \n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "    \n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "            \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "                                             hr, ndcg))\n",
    "x=list(range(epoch+1))   \n",
    "#plt.plot(x,loss_record,label=\"loss\")\n",
    "plt.plot(x,hr_record,label=\"HR@5\")\n",
    "plt.plot(x,ndcg_record,label=\"NDCG@5\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric Increased (inf --> -0.706390).  Saving model ...\n",
      "Validation metric Increased (-0.706390 --> -0.713784).  Saving model ...\n",
      "Validation metric Increased (-0.713784 --> -0.714769).  Saving model ...\n",
      "Validation metric Increased (-0.714769 --> -0.722733).  Saving model ...\n",
      "Validation metric Increased (-0.722733 --> -0.730768).  Saving model ...\n",
      "Validation metric Increased (-0.730768 --> -0.735693).  Saving model ...\n",
      "Validation metric Increased (-0.735693 --> -0.742124).  Saving model ...\n",
      "Validation metric Increased (-0.742124 --> -0.744270).  Saving model ...\n",
      "Validation metric Increased (-0.744270 --> -0.749287).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.749287 --> -0.750300).  Saving model ...\n",
      "Validation metric Increased (-0.750300 --> -0.752027).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.752027 --> -0.753514).  Saving model ...\n",
      "Validation metric Increased (-0.753514 --> -0.757648).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.757648 --> -0.758533).  Saving model ...\n",
      "Validation metric Increased (-0.758533 --> -0.760381).  Saving model ...\n",
      "Validation metric Increased (-0.760381 --> -0.761500).  Saving model ...\n",
      "Validation metric Increased (-0.761500 --> -0.761500).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.761500 --> -0.762097).  Saving model ...\n",
      "Validation metric Increased (-0.762097 --> -0.762596).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.762596 --> -0.763449).  Saving model ...\n",
      "Validation metric Increased (-0.763449 --> -0.763886).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.763886 --> -0.764861).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.764861 --> -0.766881).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 8 hr: 0.5689808351313619 ndcg: 0.725783662452367\n",
      "Validation metric Increased (inf --> -0.706211).  Saving model ...\n",
      "Validation metric Increased (-0.706211 --> -0.715969).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.715969 --> -0.723729).  Saving model ...\n",
      "Validation metric Increased (-0.723729 --> -0.734147).  Saving model ...\n",
      "Validation metric Increased (-0.734147 --> -0.738591).  Saving model ...\n",
      "Validation metric Increased (-0.738591 --> -0.742481).  Saving model ...\n",
      "Validation metric Increased (-0.742481 --> -0.745897).  Saving model ...\n",
      "Validation metric Increased (-0.745897 --> -0.746402).  Saving model ...\n",
      "Validation metric Increased (-0.746402 --> -0.749478).  Saving model ...\n",
      "Validation metric Increased (-0.749478 --> -0.751822).  Saving model ...\n",
      "Validation metric Increased (-0.751822 --> -0.752527).  Saving model ...\n",
      "Validation metric Increased (-0.752527 --> -0.755311).  Saving model ...\n",
      "Validation metric Increased (-0.755311 --> -0.761923).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.761923 --> -0.761968).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.761968 --> -0.765603).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.765603 --> -0.767482).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.767482 --> -0.767626).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.767626 --> -0.769719).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Validation metric Increased (-0.769719 --> -0.770149).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 16 hr: 0.5714684604645259 ndcg: 0.7307409713168691\n",
      "Validation metric Increased (inf --> -0.706752).  Saving model ...\n",
      "Validation metric Increased (-0.706752 --> -0.717670).  Saving model ...\n",
      "Validation metric Increased (-0.717670 --> -0.720066).  Saving model ...\n",
      "Validation metric Increased (-0.720066 --> -0.725756).  Saving model ...\n",
      "Validation metric Increased (-0.725756 --> -0.729288).  Saving model ...\n",
      "Validation metric Increased (-0.729288 --> -0.735872).  Saving model ...\n",
      "Validation metric Increased (-0.735872 --> -0.742060).  Saving model ...\n",
      "Validation metric Increased (-0.742060 --> -0.746475).  Saving model ...\n",
      "Validation metric Increased (-0.746475 --> -0.750044).  Saving model ...\n",
      "Validation metric Increased (-0.750044 --> -0.754393).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.754393 --> -0.756365).  Saving model ...\n",
      "Validation metric Increased (-0.756365 --> -0.757882).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.757882 --> -0.758110).  Saving model ...\n",
      "Validation metric Increased (-0.758110 --> -0.759779).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.759779 --> -0.761084).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.761084 --> -0.762549).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.762549 --> -0.765029).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.765029 --> -0.765391).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Validation metric Increased (-0.765391 --> -0.768561).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 64 hr: 0.5672039598933875 ndcg: 0.7229051703928463\n",
      "Validation metric Increased (inf --> -0.700459).  Saving model ...\n",
      "Validation metric Increased (-0.700459 --> -0.711521).  Saving model ...\n",
      "Validation metric Increased (-0.711521 --> -0.716589).  Saving model ...\n",
      "Validation metric Increased (-0.716589 --> -0.723546).  Saving model ...\n",
      "Validation metric Increased (-0.723546 --> -0.727510).  Saving model ...\n",
      "Validation metric Increased (-0.727510 --> -0.735481).  Saving model ...\n",
      "Validation metric Increased (-0.735481 --> -0.740562).  Saving model ...\n",
      "Validation metric Increased (-0.740562 --> -0.740986).  Saving model ...\n",
      "Validation metric Increased (-0.740986 --> -0.746068).  Saving model ...\n",
      "Validation metric Increased (-0.746068 --> -0.750358).  Saving model ...\n",
      "Validation metric Increased (-0.750358 --> -0.750713).  Saving model ...\n",
      "Validation metric Increased (-0.750713 --> -0.752611).  Saving model ...\n",
      "Validation metric Increased (-0.752611 --> -0.753141).  Saving model ...\n",
      "Validation metric Increased (-0.753141 --> -0.755982).  Saving model ...\n",
      "Validation metric Increased (-0.755982 --> -0.760098).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.760098 --> -0.762724).  Saving model ...\n",
      "Validation metric Increased (-0.762724 --> -0.764406).  Saving model ...\n",
      "Validation metric Increased (-0.764406 --> -0.764930).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.764930 --> -0.765010).  Saving model ...\n",
      "Validation metric Increased (-0.765010 --> -0.766523).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f82b8987d54b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;31m#print(train_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mloss_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "para['proj_dim'] = 32\n",
    "\n",
    "for dim in []:\n",
    "    para['embed_dim'] = dim\n",
    "    para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('embed dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)\n",
    "\n",
    "    \n",
    "para['embed_dim'] = 64\n",
    "para['layers'] = [64,64,64,64]    \n",
    "\n",
    "for dim in [8,16,64,128]:\n",
    "    para['proj_dim'] = dim\n",
    "    #para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('proj dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69969.65625, 0.5673562634852138, 0.7271187365635885)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65026.953125, 0.5816220332529509, 0.7404878650622022)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80704.9296875, 0.5436730549562128, 0.6915377582474793)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57725.07421875, 0.5841604264500572, 0.83247718417327)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67998.46875, 0.5714176926005838, 0.729466304479471)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70794.5625, 0.5621271734991751, 0.7108450764295248)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71228.421875, 0.5692092905191014, 0.734327269445404)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68724.5703125, 0.5715953801243813, 0.7304625923405739)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68580.46875, 0.5700215763421754, 0.730021614027897)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78656.9296875, 0.5538773956085797, 0.7097259750872211)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155217.328125, 0.47559334940982356, 0.6268068002293901)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100155.328125, 0.5480644751872065, 0.7039032461787891)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84312.6953125, 0.5423023226297754, 0.7136611829728107)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置切分区域\n",
    "listBins = [0, 1, 3, 10, 120]\n",
    "#设置切分后对应标签\n",
    "listLabels = ['1','2 - 3','4 - 10','>10']\n",
    "df_at = dat.test\n",
    "df_test = df_at.groupby('aid')['pid'].apply(set).reset_index().rename(columns={'pid': 'interacted_items'})\n",
    "df_test['len'] = df_test['interacted_items'].apply(lambda x:len(x))\n",
    "df_test = df_test[['aid','len']]\n",
    "df_test = df_test.rename(columns={'aid': 'uid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('HAN323.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "df_HAN = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_HAN['num'] = num_list\n",
    "\n",
    "df_HAN['fenzu'] = pd.cut(df_HAN['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_HAN_stat = df_HAN.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_HAN.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_HAN_stat['num'] = num_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('MF323.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "df_MF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_MF['num'] = num_list\n",
    "\n",
    "df_MF['fenzu'] = pd.cut(df_MF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_MF_stat = df_MF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_MF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_MF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['layers']=[64,64,64,64]\n",
    "\n",
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NGCF323.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "df_NGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NGCF['num'] = num_list\n",
    "\n",
    "df_NGCF['fenzu'] = pd.cut(df_NGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NGCF_stat = df_NGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NGCF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['layers']=[64,64,64]\n",
    "\n",
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "#model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NHGCF330-l2.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "df_NHGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NHGCF['num'] = num_list\n",
    "\n",
    "df_NHGCF['fenzu'] = pd.cut(df_NHGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NHGCF_stat = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NHGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NHGCF_stat['num'] = num_list\n",
    "#df_NHGCF_stat['num'] = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691163</td>\n",
       "      <td>6288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2 - 3</td>\n",
       "      <td>0.730410</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4 - 10</td>\n",
       "      <td>0.690592</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;10</td>\n",
       "      <td>0.796662</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fenzu  ave_ndcg   num\n",
       "0       1  0.691163  6288\n",
       "1   2 - 3  0.730410  3821\n",
       "2  4 - 10  0.690592  2102\n",
       "3     >10  0.796662   591"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HAN_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722810</td>\n",
       "      <td>6288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2 - 3</td>\n",
       "      <td>0.710532</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4 - 10</td>\n",
       "      <td>0.682087</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;10</td>\n",
       "      <td>0.825063</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fenzu  ave_ndcg   num\n",
       "0       1  0.722810  6288\n",
       "1   2 - 3  0.710532  3821\n",
       "2  4 - 10  0.682087  2102\n",
       "3     >10  0.825063   591"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0_5</td>\n",
       "      <td>0.722855</td>\n",
       "      <td>10728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6_10</td>\n",
       "      <td>0.714261</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11_20</td>\n",
       "      <td>0.742006</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.808735</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fenzu  ave_ndcg    num\n",
       "0    0_5  0.722855  10728\n",
       "1   6_10  0.714261    877\n",
       "2  11_20  0.742006    408\n",
       "3    >20  0.808735    180"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HAN_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0_5</td>\n",
       "      <td>0.713243</td>\n",
       "      <td>10914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6_10</td>\n",
       "      <td>0.703765</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11_20</td>\n",
       "      <td>0.762002</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.837932</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fenzu  ave_ndcg    num\n",
       "0    0_5  0.713243  10914\n",
       "1   6_10  0.703765    880\n",
       "2  11_20  0.762002    411\n",
       "3    >20  0.837932    180"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0_5</td>\n",
       "      <td>0.740843</td>\n",
       "      <td>10596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6_10</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11_20</td>\n",
       "      <td>0.772395</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fenzu  ave_ndcg    num\n",
       "0    0_5  0.740843  10596\n",
       "1   6_10  0.734829    885\n",
       "2  11_20  0.772395    407\n",
       "3    >20  0.862730    178"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0_5</td>\n",
       "      <td>0.769889</td>\n",
       "      <td>10585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6_10</td>\n",
       "      <td>0.786156</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11_20</td>\n",
       "      <td>0.823136</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>0.862642</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fenzu  ave_ndcg    num\n",
       "0    0_5  0.769889  10585\n",
       "1   6_10  0.786156    889\n",
       "2  11_20  0.823136    411\n",
       "3    >20  0.862642    180"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NHGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12802"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.test['aid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11857"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ndcg['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12385"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ndcg['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12066"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ndcg['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(dpi=500)\n",
    "#plt.figure(figsize=(10,5))\n",
    "fig, ax1 = plt.subplots(figsize = (6, 5))\n",
    "\n",
    "width = 0.5\n",
    "#index = np.arange(len(listLabels))\n",
    "#tick_label = listLabels\n",
    "#ax1.bar(index,df_MF_stat['num'],width =width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width,df_HAN_stat['num'],width =width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width,df_NGCF_stat['num'],width =width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width+width,df_NHGCF_stat['num'],width =width,color='lightgray',label=\"NHGCF_recall\",align=\"center\")\n",
    "#ax1.set_ylabel('Recall Num')\n",
    "#ax1.set_xticks(index+width*1.5, tick_label)\n",
    "#ax1.legend(loc='upper center')\n",
    "\n",
    "ax1.bar(listLabels,df_MF_stat['num'],width = width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NGCF_stat['num'],width = width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_HAN_stat['num'],width = width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NHGCF_stat['num'],width = width,color='lightgray',label=\"Ours_recall\",align=\"center\")\n",
    "ax1.set_ylabel('Recall Num',fontsize=12)\n",
    "ax1.set_xlabel('User Group\\n(divided by interaction num)',fontsize=15)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(listLabels,df_MF_stat['ave_ndcg'],label=\"MF\",marker='o')\n",
    "ax2.plot(listLabels,df_NGCF_stat['ave_ndcg'],label=\"NGCF\",marker='v')\n",
    "ax2.plot(listLabels,df_HAN_stat['ave_ndcg'],label=\"HAN\",marker='*')\n",
    "ax2.plot(listLabels,df_NHGCF_stat['ave_ndcg'],label=\"Ours\",marker='s')\n",
    "#ax2.hlines(0.70, -1, 8, linestyles = \"dashed\")\n",
    "#ax2.plot(listLabels,df_NeuMF_stat['ave_ndcg'],label=\"NeuMF\",marker='o')\n",
    "ax2.set_ylim(.65,.90)\n",
    "ax2.set_ylabel('NDCG@5',fontsize=12)\n",
    "ax2.yaxis.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)\n",
    "\n",
    "#ax1.legend(loc='lower left')\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121566"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat.train)+len(dat.dev)+len(dat.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10669, 18388)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.iNum,dat.uNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84812.609375, 0.5400685366163218, 0.7123638791956942)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308767.65625, 0.5089732199517706, 0.6558992985871475)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127691.9375, 0.4995303972585354, 0.6507849408939337)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79835.609375, 0.5477344840715827, 0.6976571486640007)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85136.234375, 0.539332402589161, 0.7106110944536702)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100203.734375, 0.5515420738672421, 0.7097259954360793)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79070.4921875, 0.5571011549689047, 0.7147190219567287)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,v_hr,v_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'ACM'\n",
    "model_name = 'NHGCF'\n",
    "hr_record=[]\n",
    "ndcg_record=[]\n",
    "for i in range(5):\n",
    "    #model = MF(para)\n",
    "    #model = NeuMF(para)\n",
    "    #model = GCF(para,dat.u2i[0][0])\n",
    "    #model = HAN(para,dat.mp_graphs)\n",
    "    model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    \n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        \n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "                \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "                                                 hr, ndcg))\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print(v_,v_hr,v_ndcg)\n",
    "    hr_record.append(v_hr)\n",
    "    ndcg_record.append(v_ndcg)\n",
    "    \n",
    "print(np.mean(hr_record),np.mean(ndcg_record))\n",
    "df_result = pd.DataFrame()\n",
    "df_result['hr'] = hr_record\n",
    "df_result['ndcg']=ndcg_record\n",
    "df_result.to_csv('result/'+data_name+'_'+model_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=128):\n",
    "        super(SemanticAttention, self).__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "\n",
    "        return (beta * z).sum(1)\n",
    "\n",
    "class HANLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    HAN layer.\n",
    "    Arguments\n",
    "    ---------\n",
    "    num_meta_paths : number of homogeneous graphs generated from the metapaths.\n",
    "    in_size : input feature dimension\n",
    "    out_size : output feature dimension\n",
    "    layer_num_heads : number of attention heads\n",
    "    dropout : Dropout probability\n",
    "    Inputs\n",
    "    ------\n",
    "    g : list[DGLGraph]\n",
    "        List of graphs\n",
    "    h : tensor\n",
    "        Input features\n",
    "    Outputs\n",
    "    -------\n",
    "    tensor\n",
    "        The output feature\n",
    "    \"\"\"\n",
    "    def __init__(self, num_meta_paths, in_size, out_size, layer_num_heads, dropout):\n",
    "        super(HANLayer, self).__init__()\n",
    "\n",
    "        # One GAT layer for each meta path based adjacency matrix\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        for i in range(num_meta_paths):\n",
    "            self.gat_layers.append(GATConv(in_size, out_size, layer_num_heads,\n",
    "                                           dropout, dropout, activation=F.elu))\n",
    "        self.semantic_attention = SemanticAttention(in_size=out_size * layer_num_heads)\n",
    "        self.num_meta_paths = num_meta_paths\n",
    "\n",
    "    def forward(self, gs, h):\n",
    "        semantic_embeddings = []\n",
    "\n",
    "        for i, g in enumerate(gs):\n",
    "            semantic_embeddings.append(self.gat_layers[i](g, h).flatten(1))\n",
    "        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)                  # (N, M, D * K)\n",
    "\n",
    "        return self.semantic_attention(semantic_embeddings)                            # (N, D * K)\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self,config, gs):\n",
    "        super(HAN, self).__init__()\n",
    "        self.gs = gs\n",
    "        self.usecuda = config['cuda']\n",
    "        self.dropout = config['dropout']\n",
    "        self.num_heads = config['num_heads']\n",
    "        self.num_meta_paths = len(gs)\n",
    "        self.userNum = config['num_users']\n",
    "        self.itemNum = config['num_items']\n",
    "        self.uEmbd = nn.Embedding(config['num_users'],config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(config['num_items'],config['embed_dim'])\n",
    "        self.in_size = config['embed_dim']\n",
    "        self.hidden_size = config['hidden_dim']\n",
    "        #self.h = torch.cat((self.uEmbd,self.iEmbd),dim=0)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(HANLayer(self.num_meta_paths, self.in_size, self.hidden_size, self.num_heads[0], self.dropout))\n",
    "        for l in range(1, len(self.num_heads)):\n",
    "            self.layers.append(HANLayer(self.num_meta_paths, self.hidden_size * self.num_heads[l-1],\n",
    "                                        self.hidden_size,  self.num_heads[l],  self.dropout))\n",
    "        #self.predict = nn.Linear(hidden_size * num_heads[-1], 1)\n",
    "    \n",
    "    def weight_init(self):\n",
    "        wts = [\n",
    "            self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.layers[0].gat_layers[0].fc.weight,\n",
    "            self.layers[0].gat_layers[1].fc.weight,\n",
    "            self.layers[0].gat_layers[2].fc.weight,\n",
    "           # self.layers[0].gat_layers[3].fc.weight,\n",
    "            #self.layers[0].gat_layers[4].fc.weight,\n",
    "            #self.layers[0].gat_layers[5].fc.weight,\n",
    "            self.layers[0].semantic_attention.project[0].weight,\n",
    "            self.layers[0].semantic_attention.project[2].weight\n",
    "            #self.layers[1].gat_layers[0].fc.weight,\n",
    "            #self.layers[1].gat_layers[1].fc.weight,\n",
    "            #self.layers[1].gat_layers[2].fc.weight,\n",
    "            #self.layers[1].semantic_attention.project[0].weight,\n",
    "            #self.layers[1].semantic_attention.project[2].weight\n",
    "            #self.layers[2].gat_layers[0].fc.weight,\n",
    "            #self.layers[2].gat_layers[1].fc.weight,\n",
    "            #self.layers[2].gat_layers[2].fc.weight,\n",
    "            #self.layers[2].semantic_attention.project[0].weight,\n",
    "            #self.layers[2].semantic_attention.project[2].weight\n",
    "        ]\n",
    "        \n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)  \n",
    "    \n",
    "    def getFeatureMat(self):\n",
    "        uidx = torch.LongTensor([i for i in range(self.userNum)])\n",
    "        iidx = torch.LongTensor([i for i in range(self.itemNum)])\n",
    "        if self.usecuda  == True:\n",
    "            uidx = uidx.cuda()\n",
    "            iidx = iidx.cuda()\n",
    "        #print(type(uidx))\n",
    "        userEmbd = self.uEmbd(uidx)\n",
    "        itemEmbd = self.iEmbd(iidx)\n",
    "\n",
    "        features = torch.cat([userEmbd,itemEmbd],dim=0)\n",
    "        return features\n",
    "    \n",
    "    def forward(self, userIdx,itemIdx):\n",
    "        itemIdx = itemIdx + self.userNum\n",
    "        features = self.getFeatureMat()\n",
    "        #finalEmbd = features.clone()\n",
    "        for gnn in self.layers:\n",
    "            features = gnn(self.gs, features)\n",
    "            features = normalize(features, 2, 1) # L2 Norm\n",
    "          \n",
    "        userEmbd = features[userIdx]\n",
    "        itemEmbd = features[itemIdx]    \n",
    "        #print(userEmbd.size()) \n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return torch.sum(u_embeddings, dim=1),torch.sum(i_embeddings, dim=1),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF_noattn(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF_noattn,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight,\n",
    "              ]\n",
    "        wts2 = [\n",
    "            #self.u2eEmbds[1].weight,\n",
    "            #self.u2eEmbds[2].weight,\n",
    "            #self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,num_list,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        \n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "\n",
    "        \n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        full =  inter_part1+inter_part2\n",
    "        u_feature = full[:self.uNum]\n",
    "        i_feature = full[self.uNum:]\n",
    "        return u_feature,i_feature\n",
    "\n",
    "class NHGCF_norelation(Module):\n",
    "\n",
    "    def __init__(self,config,L,L_hat,num_list):\n",
    "\n",
    "        super(NHGCF_norelation,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.uNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.iNum,config['embed_dim'])\n",
    "        \n",
    "        self.layers = config['layers']\n",
    "        self.GNNlayers = torch.nn.ModuleList()\n",
    "        self.L = L # sparse format\n",
    "        self.L_hat = L_hat\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "        \n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.GNNlayers.append(Message_Passing(From,To,num_list,self.useCuda))\n",
    "    \n",
    "     # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "              self.iEmbd.weight,     \n",
    "              self.GNNlayers[0].Transform.weight,\n",
    "              self.GNNlayers[0].InterAct.weight,\n",
    "              self.GNNlayers[1].Transform.weight,\n",
    "              self.GNNlayers[1].InterAct.weight,\n",
    "              self.GNNlayers[2].Transform.weight,\n",
    "              self.GNNlayers[2].InterAct.weight\n",
    "              #self.transForm1.weight,\n",
    "              #self.transForm2.weight,\n",
    "              #self.transForm3.weight,\n",
    "              ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)      \n",
    "\n",
    "\n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "        \n",
    "        u_feature = self.getFeatureMat(self.uNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.iNum,self.iEmbd)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.GNNlayers:\n",
    "            u_feature,i_feature = gnn(self.L,self.L_hat,torch.cat([u_feature,i_feature]))\n",
    "            u_feature = normalize(self.leakyRelu(u_feature), 2, 1)\n",
    "            i_feature = normalize(self.leakyRelu(i_feature), 2, 1)\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "            \n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,proj_dim,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF_share_proj(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        self.proj_dim = config['proj_dim']\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To,self.proj_dim, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[2].i_relation_attention.project[2].weight\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight,\n",
    "              ]\n",
    "        wts2 = [\n",
    "            #self.u2eEmbds[1].weight,\n",
    "            #self.u2eEmbds[2].weight,\n",
    "            #self.i2eEmbds[1].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
