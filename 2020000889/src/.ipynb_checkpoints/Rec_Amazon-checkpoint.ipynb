{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import tqdm\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Module\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import BCELoss,BCEWithLogitsLoss\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam,Adadelta,RMSprop\n",
    "\n",
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda._initialized = True\n",
    "\n",
    "#from src.Dataset import ACM_Dataset,Amazon_Dataset,Movielens_Dataset\n",
    "from src.models import MF,NeuMF,GCF\n",
    "from src.Utils import BPRLoss,Wrap_Dataset,EarlyStopping\n",
    "#from src.Evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    return len(truth_in_top_k) * 1.0 / (df_static['len'].sum())\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return full['ndcg'].sum() * 1.0 / df_eval['uid'].nunique()\n",
    "\n",
    "def evaluate(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio(df_eval,df_static,top_k),call_ndcg(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hit_ratio2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    stat = full[['uid','len','rating']].groupby('uid')['rating'].apply(sum).reset_index().rename(columns={'rating': 'recall_num'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    stat2['hr_perU'] = stat2.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    #stat['hr'] = stat.apply(lambda row:row['recall_num']/row['len'],axis=1)\n",
    "    return stat2[['uid','len','recall_num','hr_perU']]\n",
    "\n",
    "def jud(x):\n",
    "    #print(x)\n",
    "    if x<=5:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,x+1)])\n",
    "    else:\n",
    "        return sum([ math.log(2) / math.log(1 + i) for i in range(1,6)])\n",
    "\n",
    "def call_ndcg2(df_eval,df_static,top_k):\n",
    "    top_k = df_eval[df_eval['rank']<=top_k]\n",
    "    truth_in_top_k  = top_k[top_k['rating']==1]\n",
    "    full = pd.merge(truth_in_top_k, df_static, on=['uid'],how='left')\n",
    "    #print(full['len'].max(),full['len'].min())\n",
    "    full['dcg'] = full['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\n",
    "    full['idcg'] = full['len'].apply(lambda x: jud(x)) \n",
    "    full['ndcg'] = full.apply(lambda row:row['dcg']/row['idcg'],axis=1)\n",
    "    \n",
    "    stat = full[['uid','len','ndcg']].groupby('uid')['ndcg'].apply(sum).reset_index().rename(columns={'ndcg': 'ndcg_perU'})\n",
    "    stat2 = pd.merge(stat, df_static, on=['uid'],how='left')\n",
    "    #return truth_in_top_k['ndcg'].sum() * 1.0 / (df_eval['uid'].nunique()*sum([ math.log(2) / math.log(1 + i) for i in range(1,6)]))\n",
    "    return stat2[['uid','len','ndcg_perU']]\n",
    "\n",
    "def evaluate2(evaluate_data,input_data, model,loss_func,top_k,use_cuda=True):\n",
    "    \"\"\"\n",
    "    input_data --> 计算验证损失\n",
    "    evaluate_data --> 计算指标\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cuda()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cuda()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cuda()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cuda()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cuda()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cuda()\n",
    "        else:\n",
    "            eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "            eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "            eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "            \n",
    "            eval_user_input = torch.LongTensor(input_data['uid']).cpu()\n",
    "            eval_pos = torch.LongTensor(input_data['pos_iid']).cpu()\n",
    "            eval_neg = torch.LongTensor(input_data['neg_iid']).cpu()\n",
    "            \n",
    "        #print(eval_user.shape,eval_item.shape)    \n",
    "        scores = model(eval_user, eval_item)\n",
    "        val_loss = loss_func(eval_user_input,eval_pos,eval_neg)\n",
    "            \n",
    "            \n",
    "        #把数据转存到cpu,从而使用pandas\n",
    "        eval_user = torch.LongTensor(evaluate_data['uid']).cpu()\n",
    "        eval_item = torch.LongTensor(evaluate_data['iid']).cpu()\n",
    "        eval_rating = torch.FloatTensor(evaluate_data['rating']).cpu()\n",
    "        scores = scores.cpu()\n",
    "        \n",
    "        df_eval = pd.DataFrame([], columns=['uid', 'iid','rating', 'score'])\n",
    "        df_eval['uid'] = eval_user.data.view(-1).tolist()\n",
    "        df_eval['iid'] = eval_item.data.view(-1).tolist()\n",
    "        df_eval['rating'] = eval_rating.data.view(-1).tolist()\n",
    "        df_eval['score'] = scores.data.view(-1).tolist()\n",
    "        \n",
    "        df_eval['rank'] = df_eval.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "        \n",
    "        df_static = df_eval[df_eval['rating']==1].groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "        df_static.sort_values(by='uid', inplace=True)\n",
    "        df_eval.sort_values(['uid', 'rank'], inplace=True)\n",
    "        \n",
    "        return val_loss.item(),call_hit_ratio2(df_eval,df_static,top_k),call_ndcg2(df_eval,df_static,top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amazon_Dataset(object):\n",
    "    def __init__(self,config_dat):\n",
    "        self.dataset_name = config_dat['dataset_name']\n",
    "        #self.model_name = model_name\n",
    "        self.Load_flag = config_dat['isLoad']\n",
    "        self.Store_flag =config_dat['store']\n",
    "        self.filepaths = config_dat['filepaths']\n",
    "        self.uNum,self.iNum = self.Amazon_get_nums()\n",
    "        self.train,self.dev,self.test = self.data_split(config_dat['neg_num4train'])\n",
    "        self.train['rating'] = [1 for i in range(len(self.train))]\n",
    "        \n",
    "        self.input_train = self.Amazon_build_input_data(1)\n",
    "        self.input_dev = self.Amazon_build_input_data(2)\n",
    "        self.input_test = self.Amazon_build_input_data(3)\n",
    "        self.eval_dev,self.eval_test = self.Amazon_build_eval_data()\n",
    "        \n",
    "        self.i2b = pd.read_csv(self.filepaths[0]+'i2b.csv')\n",
    "        self.i2v = pd.read_csv(self.filepaths[0]+'i2v.csv')\n",
    "        self.i2c = pd.read_csv(self.filepaths[0]+'i2c.csv')\n",
    "        self.i2b['link'] = [1 for _ in range(len(self.i2b))]\n",
    "        self.i2v['link'] = [1 for _ in range(len(self.i2v))]\n",
    "        self.i2c['link'] = [1 for _ in range(len(self.i2c))]\n",
    "        self.bNum = self.i2b['bid'].max()+1\n",
    "        self.vNum = self.i2v['vid'].max()+1\n",
    "        self.cNum = self.i2c['cid'].max()+1\n",
    "        #self.a2a,self.p2p = self.ACM_relation_process()\n",
    "        self.mp_graphs = self.Amazon_create_mp_neighbor_graph()\n",
    "        \n",
    "        L_u2i,L_u2i_hat = self.Amazon_buildLaplacianMat_u2i()\n",
    "        self.u2i = [(L_u2i,L_u2i_hat),[self.uNum,self.iNum]]\n",
    "    \n",
    "        self.u2es = []\n",
    "        self.u2es2 = []\n",
    "        \n",
    "        L_i2b_i,L_i2b_i_hat,L_i2b_b,L_i2b_b_hat = self.Amazon_buildLaplacianMat_i2b()\n",
    "        L_i2v_i,L_i2v_i_hat,L_i2v_v,L_i2v_v_hat = self.Amazon_buildLaplacianMat_i2v()\n",
    "        L_i2c_i,L_i2c_i_hat,L_i2c_c,L_i2c_c_hat = self.Amazon_buildLaplacianMat_i2c()\n",
    "        self.i2es = [\n",
    "            [(L_i2b_i,L_i2b_i_hat,L_i2b_b_hat),self.bNum,False],\n",
    "            [(L_i2v_i,L_i2v_i_hat,L_i2v_v_hat),self.vNum,False],\n",
    "            [(L_i2c_i,L_i2c_i_hat,L_i2c_c_hat),self.cNum,False]\n",
    "        ]\n",
    "        self.i2es2 = [\n",
    "            [(L_i2b_i,L_i2b_i_hat,L_i2b_b,L_i2b_b_hat),self.bNum,False],\n",
    "            [(L_i2v_i,L_i2v_i_hat,L_i2v_v,L_i2v_v_hat),self.vNum,False],\n",
    "            [(L_i2c_i,L_i2c_i_hat,L_i2c_c,L_i2c_c_hat),self.cNum,False]\n",
    "        ]\n",
    "        self.full,self.full_hat = self.Amazon_buildLaplacianMat_full()\n",
    "        self.num_list = [self.uNum,self.iNum,self.bNum,self.vNum,self.cNum]\n",
    "    def Amazon_get_nums(self):\n",
    "        df_u2i = pd.read_csv(self.filepaths[1])\n",
    "        return df_u2i['uid'].max()+1,df_u2i['iid'].max()+1\n",
    "    \n",
    "    def Amazon_split(self,df_u2i):\n",
    "        \"\"\" \n",
    "        interact>20 ---> [n-20:10:10]\n",
    "        20>=interact>10 ---> [n-10:0:10]\n",
    "        10>=interact ---> [n:0:0]\n",
    "        \n",
    "        \"\"\"\n",
    "        rd_val = []\n",
    "        for i in range(len(df_u2i)):\n",
    "            rd_val.append(random.random())\n",
    "        df_u2i['random_val']=rd_val\n",
    "        df_u2i['rank'] = df_u2i.groupby(['uid'])['random_val'].rank(method='first', ascending=False)\n",
    "\n",
    "        grouped = df_u2i.groupby(['uid'])\n",
    "        test1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        dev1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        train1 = pd.DataFrame([], columns=['uid', 'iid','negatives'])\n",
    "        for name,group in tqdm.tqdm(grouped):\n",
    "            split_list = np.array_split(list(range(1,len(group)+1)),3)\n",
    "            train1 = train1.append(group[group['rank'].isin(split_list[0])])\n",
    "            test1 = test1.append(group[group['rank'].isin(split_list[1])])\n",
    "            dev1 = dev1.append(group[group['rank'].isin(split_list[2])])\n",
    "            \n",
    "        return train1[['uid', 'iid','negatives']],dev1[['uid', 'iid','negatives']], test1[['uid', 'iid','negatives']]\n",
    "    \n",
    "    def get_prob(self,neg_items,counter_dict):\n",
    "        \"\"\" get the prob of each neg_items\"\"\"\n",
    "        neg_occurance = [counter_dict[i] for i in neg_items] \n",
    "        neg_num = sum(neg_occurance)\n",
    "        neg_prob = [i/neg_num for i in neg_occurance]\n",
    "        return neg_prob\n",
    "    \n",
    "    def negative_sample(self,row_item,row_prob,row_len,neg_ratio,max_num):\n",
    "        if row_len * neg_ratio> max_num:\n",
    "            return np.random.choice(list(row_item),row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        else:\n",
    "            return np.random.choice(list(row_item),neg_ratio*row_len,replace=False,\n",
    "                                                                  p = row_prob)\n",
    "        \n",
    "    def Amazon_get_negative_items(self,df_u2i,neg_ratio):\n",
    "        paper_pool = set(df_u2i['iid'].unique())\n",
    "        #max_num = len(paper_pool)\n",
    "        counter_dict = Counter(df_u2i['iid'])\n",
    "        interact_status = df_u2i.groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "        interact_status['len'] = interact_status['interacted_items'].apply(lambda x:len(x))\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: paper_pool - x)\n",
    "        interact_status['negative_probs'] = interact_status['negative_items'].apply(lambda x:self.get_prob(x,counter_dict))\n",
    "        interact_status['len_neg'] = interact_status['negative_items'].apply(lambda x:len(x))\n",
    "        interact_status['negatives'] = interact_status.apply(lambda row:self.negative_sample(row['negative_items'],\n",
    "                                                                                            row['negative_probs'],\n",
    "                                                                                            row['len'],\n",
    "                                                                                            neg_ratio,\n",
    "                                                                                            row['len_neg']),axis=1)\n",
    "        return interact_status[['uid','interacted_items','negatives','len']]\n",
    "    \n",
    "    def Amazon_negative_allocation(self,neg):\n",
    "        neg['iids'] = neg['interacted_items'].apply(list)\n",
    "        neg['split_negtives'] = neg.apply(lambda row: list(np.array_split(row['negatives'], row['len'])),axis=1)\n",
    "        uids,iids,neg_items = [],[],[]\n",
    "        for row in neg.itertuples():\n",
    "            for i,n in zip(row.iids,row.split_negtives):\n",
    "                uids.append(row.uid)\n",
    "                iids.append(i)\n",
    "                neg_items.append(n)\n",
    "        full = pd.DataFrame()\n",
    "        full['uid']=uids\n",
    "        full['iid']=iids\n",
    "        full['negatives']=neg_items\n",
    "\n",
    "        return full[['uid','iid','negatives']] \n",
    "    \n",
    "    def Amazon_split_and_sample(self, neg_ratio):\n",
    "        df_u2i = pd.read_csv(self.filepaths[1]) \n",
    "        \n",
    "        neg = self.Amazon_get_negative_items(df_u2i,neg_ratio)\n",
    "        full = self.Amazon_negative_allocation(neg)\n",
    "        train,dev,test = self.Amazon_split(full)\n",
    "        if self.Store_flag:\n",
    "            train.to_csv(self.filepaths[0]+'train.csv')\n",
    "            dev.to_csv(self.filepaths[0]+'dev.csv')\n",
    "            test.to_csv(self.filepaths[0]+'test.csv')\n",
    "        return train,dev,test\n",
    "    \n",
    "    def data_split(self, neg_ratio):\n",
    "        if self.Load_flag==True:\n",
    "            #raise Exception(\"Dataset has been loaded.\")\n",
    "            train = pd.read_csv(self.filepaths[0]+'train.csv')\n",
    "            dev = pd.read_csv(self.filepaths[0]+'dev.csv')\n",
    "            test = pd.read_csv(self.filepaths[0]+'test.csv')\n",
    "        else:\n",
    "            train,dev,test = self.Amazon_split_and_sample(neg_ratio)\n",
    "        print('Dataset has been splited!')\n",
    "        return train,dev,test\n",
    "    ###############################################################################################################################\n",
    "    \n",
    "    def Amazon_build_input_data(self,dat_type):\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        input_dat= pd.DataFrame()\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives[1:-2].split():\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "        else:\n",
    "            if dat_type==1:\n",
    "                for row in self.train.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==2:\n",
    "                for row in self.dev.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "            if dat_type==3:\n",
    "                for row in self.test.itertuples():\n",
    "                    for i in row.negatives:\n",
    "                        users.append(int(row.uid))\n",
    "                        pos_items.append(int(row.iid))\n",
    "                        neg_items.append(int(i))\n",
    "                        \n",
    "        input_dat['uid']=users\n",
    "        input_dat['pos_iid']=pos_items\n",
    "        input_dat['neg_iid']=neg_items\n",
    "        return input_dat\n",
    "    \n",
    "    def Amazon_build_eval_data(self):\n",
    "        users,items,ratings = [],[],[]\n",
    "        eval_dev=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.dev.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        eval_dev['uid']=users\n",
    "        eval_dev['iid']=items\n",
    "        eval_dev['rating']=ratings\n",
    "        \n",
    "        users,items,ratings = [],[],[]\n",
    "        eval_test=pd.DataFrame()\n",
    "        if self.Load_flag==True:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives[1:-2].split():\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        else:\n",
    "            for row in self.test.itertuples():\n",
    "                for i in row.negatives:\n",
    "                    users.append(int(row.uid))\n",
    "                    items.append(int(i))\n",
    "                    ratings.append(float(0))  # negative samples get 0 rating\n",
    "                users.append(int(row.uid))\n",
    "                items.append(int(row.iid))\n",
    "                ratings.append(float(1))\n",
    "        eval_test['uid']=users\n",
    "        eval_test['iid']=items\n",
    "        eval_test['rating']=ratings\n",
    "        \n",
    "        return eval_dev,eval_test\n",
    "    ###############################################################################################################################\n",
    "    \n",
    "    def Amazon_sample_mp_neighbor(self,df):\n",
    "        sample_df = pd.DataFrame([],columns = ['uid','iid'])\n",
    "        grouped_df = df.groupby('uid')\n",
    "        for name,group in tqdm.tqdm(grouped_df):\n",
    "            if len(group)> 50:\n",
    "                    sample_df = sample_df.append(group.sample(n=50, replace=False))\n",
    "            if 50>=len(group)>10:\n",
    "                    sample_df = sample_df.append(group.sample(frac=0.2, replace=False))\n",
    "            if len(group)<=10:\n",
    "                    sample_df = sample_df.append(group)\n",
    "        return sample_df\n",
    "                    \n",
    "    def Amazon_create_mp_neighbor_graph(self):\n",
    "        \"\"\"\n",
    "        creat metapath neighbor: UI, UIBI,UIVI,UICI\n",
    "        and transform to DGL Graph\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.Load_flag==True:\n",
    "            df_uibi = pd.read_csv(self.filepaths[0]+'uibi.csv')\n",
    "            df_uivi = pd.read_csv(self.filepaths[0]+'uivi.csv')\n",
    "            df_uici = pd.read_csv(self.filepaths[0]+'uici.csv')\n",
    "        else:\n",
    "            temp = pd.merge(self.train[['uid','iid']], self.i2b[['iid','bid']], on=['iid'])\n",
    "            temp = temp.drop(columns=['iid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uibi = pd.merge(temp,self.i2b[['iid','bid']],on=['bid'])\n",
    "            \n",
    "            temp = pd.merge(self.train[['uid','iid']], self.i2v[['iid','vid']], on=['iid'])\n",
    "            temp = temp.drop(columns=['iid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uivi = pd.merge(temp,self.i2v[['iid','vid']],on=['vid'])\n",
    "            \n",
    "            temp = pd.merge(self.train[['uid','iid']], self.i2c[['iid','cid']], on=['iid'])\n",
    "            temp = temp.drop(columns=['iid']).drop_duplicates().reset_index(drop=True)\n",
    "            df_uici = pd.merge(temp,self.i2c[['iid','cid']],on=['cid'])\n",
    "        \n",
    "            df_uibi = df_uibi[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            df_uivi = df_uivi[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "            df_uici = df_uici[['uid','iid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            #sample (sample standard? sample strategy?)\n",
    "            \n",
    "            if len(df_uibi)>200000:\n",
    "                print('length of df_uibi:',len(df_uibi),'start sampling...') \n",
    "                df_uibi = self.Amazon_sample_mp_neighbor(df_uibi)\n",
    "\n",
    "            if len(df_uivi)>240000:\n",
    "                print('length of df_uivi:',len(df_uivi),'start sampling...') \n",
    "                df_uivi = self.Amazon_sample_mp_neighbor(df_uivi)\n",
    "                \n",
    "            if len(df_uici)>200000:\n",
    "                print('length of df_uici:',len(df_uici),'start sampling...') \n",
    "                df_uici = self.Amazon_sample_mp_neighbor(df_uici)\n",
    "                \n",
    "            if self.Store_flag==True:\n",
    "                df_uibi.to_csv('Amazon/uibi.csv')\n",
    "                df_uivi.to_csv('Amazon/uivi.csv')\n",
    "                df_uici.to_csv('Amazon/uici.csv')\n",
    "\n",
    "        df_uibi['n_iid'] = df_uibi['iid'].apply(lambda x: x+self.uNum)        \n",
    "        df_uivi['n_iid'] = df_uivi['iid'].apply(lambda x: x+self.uNum)\n",
    "        df_uici['n_iid'] = df_uici['iid'].apply(lambda x: x+self.uNum)\n",
    "        self.train['n_iid'] = self.train['iid'].apply(lambda x: x+self.uNum)\n",
    "        \n",
    "        g_ui = dgl.DGLGraph()\n",
    "        g_ui.add_nodes(self.uNum+self.iNum)\n",
    "        g_ui.add_edges(self.train['uid'].tolist(),self.train['n_iid'].tolist())\n",
    "        g_ui.add_edges(self.train['n_iid'].tolist(),self.train['uid'].tolist())\n",
    "        \n",
    "        g_uibi = dgl.DGLGraph()\n",
    "        g_uibi.add_nodes(self.uNum+self.iNum)\n",
    "        g_uibi.add_edges(df_uibi['uid'].tolist(),df_uibi['n_iid'].tolist())\n",
    "        g_uibi.add_edges(df_uibi['n_iid'].tolist(),df_uibi['uid'].tolist())\n",
    "        \n",
    "        g_uivi = dgl.DGLGraph()\n",
    "        g_uivi.add_nodes(self.uNum+self.iNum)\n",
    "        g_uivi.add_edges(df_uivi['uid'].tolist(),df_uivi['n_iid'].tolist())\n",
    "        g_uivi.add_edges(df_uivi['n_iid'].tolist(),df_uivi['uid'].tolist())\n",
    "        \n",
    "        g_uici = dgl.DGLGraph()\n",
    "        g_uici.add_nodes(self.uNum+self.iNum)\n",
    "        g_uici.add_edges(df_uici['uid'].tolist(),df_uici['n_iid'].tolist())\n",
    "        g_uici.add_edges(df_uici['n_iid'].tolist(),df_uici['uid'].tolist())\n",
    "\n",
    "        return [g_ui,g_uibi,g_uivi,g_uici]\n",
    "    \n",
    "    ###############################################################################################################################\n",
    "    def getSparseEye(self,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(0,num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    def getSparseEye_down(self,num_span,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(num_span,num_span+num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    def getSparseEye_upper(self,num_span,num):\n",
    "        row = [k for k in range(0,num_span)]\n",
    "        row.append(num_span-1)\n",
    "        col = [j for j in range(0,num_span)]\n",
    "        col.append(num_span+num-1)\n",
    "        i = torch.LongTensor([row,col])\n",
    "        val = torch.FloatTensor([1]*num_span)\n",
    "        val = torch.cat([val,torch.FloatTensor([0])])\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "    \n",
    "    def Amazon_buildLaplacianMat_u2i(self):\n",
    "        rt_item = self.train['iid'] + self.uNum\n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['uid'], self.train['iid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.train['rating'], (self.train['uid'], rt_item)))\n",
    "        uiMat_upperPart.resize((self.uNum, self.uNum + self.iNum))\n",
    "        \n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.iNum, self.uNum + self.iNum))\n",
    "        #print(uiMat_upperPart.shape,uiMat.shape)\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.uNum+self.iNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        #print(L.shape)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row =np.append(row,self.uNum + self.iNum-1)\n",
    "        col =np.append(col,self.uNum + self.iNum-1)\n",
    "        data =np.append(data,0)\n",
    "        \n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum)\n",
    "        \n",
    "        return SparseL, SparseL+SL\n",
    "    \n",
    "    def Amazon_buildLaplacianMat_i2b(self):\n",
    "        rt_item = self.i2b['bid'] + self.iNum\n",
    "        uiMat = coo_matrix((self.i2b['link'], (self.i2b['iid'], self.i2b['bid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.i2b['link'], (self.i2b['iid'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.bNum, self.iNum + self.bNum))\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.iNum + self.bNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.iNum)\n",
    "        row_index_down = np.where(row>=self.iNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.iNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.iNum+self.bNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.iNum,self.bNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.iNum),self.bNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.iNum+self.bNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.iNum,self.bNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Amazon_buildLaplacianMat_i2v(self):\n",
    "        rt_item = self.i2v['vid'] + self.iNum\n",
    "        uiMat = coo_matrix((self.i2v['link'], (self.i2v['iid'], self.i2v['vid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.i2v['link'], (self.i2v['iid'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.vNum, self.iNum + self.vNum))\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.iNum + self.vNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.iNum)\n",
    "        row_index_down = np.where(row>=self.iNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.iNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.iNum+self.vNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.iNum,self.vNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.iNum),self.vNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.iNum+self.vNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.iNum,self.vNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Amazon_buildLaplacianMat_i2c(self):\n",
    "        rt_item = self.i2c['cid'] + self.iNum\n",
    "        uiMat = coo_matrix((self.i2c['link'], (self.i2c['iid'], self.i2c['cid'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((self.i2c['link'], (self.i2c['iid'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.cNum, self.iNum + self.cNum))\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.iNum + self.cNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "        \n",
    "        row_index_upper = np.where(row<self.iNum)\n",
    "        row_index_down = np.where(row>=self.iNum)\n",
    "        \n",
    "        row_upper = np.append(row[row_index_upper],self.iNum-1)\n",
    "        col_upper = np.append(col[row_index_upper],self.iNum+self.cNum-1)\n",
    "        i = torch.LongTensor([row_upper,col_upper])\n",
    "        data_upper = np.append(data[row_index_upper],0)\n",
    "        data_upper = torch.FloatTensor(data_upper)\n",
    "        L_upper = torch.sparse.FloatTensor(i,data_upper)\n",
    "        upper_SL = self.getSparseEye_upper(self.iNum,self.cNum)\n",
    "        L_upper_hat = L_upper+ upper_SL\n",
    "        \n",
    "        row_down = np.append((row[row_index_down]-self.iNum),self.cNum-1)\n",
    "        col_down = np.append(col[row_index_down],self.iNum+self.cNum-1)\n",
    "        i = torch.LongTensor([row_down,col_down])\n",
    "        data_down = np.append(data[row_index_down],0)\n",
    "        data_down = torch.FloatTensor(data_down)\n",
    "        L_down = torch.sparse.FloatTensor(i,data_down)\n",
    "        down_SL = self.getSparseEye_down(self.iNum,self.cNum)\n",
    "        L_down_hat = L_down+ down_SL\n",
    "        \n",
    "        return L_upper,L_upper_hat,L_down,L_down_hat\n",
    "    \n",
    "    def Amazon_buildLaplacianMat_full(self):\n",
    "        \"\"\"  \n",
    "        u - i - b - v - c\n",
    "        \"\"\"\n",
    "        uiMat = coo_matrix((self.train['rating'], (self.train['uid'], self.train['iid']+self.uNum)))\n",
    "        uiMat.resize((self.uNum,self.uNum+self.iNum+self.bNum+self.vNum+self.cNum))\n",
    "\n",
    "        ###################################################    \n",
    "        iuMat = coo_matrix((self.train['rating'], (self.train['iid'], self.train['uid'])))\n",
    "        iuMat.resize(self.iNum,self.uNum+self.iNum)\n",
    "        \n",
    "        ibMat = coo_matrix((self.i2b['link'], (self.i2b['iid'], self.i2b['bid'])))\n",
    "        ibMat.resize(self.iNum,self.bNum)\n",
    "\n",
    "        ivMat = coo_matrix((self.i2v['link'], (self.i2v['iid'], self.i2v['vid'])))\n",
    "        ivMat.resize((self.iNum,self.vNum))\n",
    "        \n",
    "        icMat = coo_matrix((self.i2c['link'], (self.i2c['iid'], self.i2c['cid'])))\n",
    "        icMat.resize((self.iNum,self.cNum))\n",
    "\n",
    "        iMat = sparse.hstack([iuMat,ibMat,ivMat,icMat])\n",
    "        ###################################################   \n",
    "        biMat = coo_matrix((self.i2b['link'], (self.i2b['bid'], self.i2b['iid']+self.uNum)))\n",
    "        biMat.resize((self.bNum,self.uNum+self.iNum+self.bNum+self.vNum+self.cNum))\n",
    "        \n",
    "        viMat = coo_matrix((self.i2v['link'], (self.i2v['vid'], self.i2v['iid']+self.uNum)))\n",
    "        viMat.resize((self.vNum,self.uNum+self.iNum+self.bNum+self.vNum+self.cNum))\n",
    "\n",
    "        ciMat = coo_matrix((self.i2c['link'], (self.i2c['cid'], self.i2c['iid']+self.uNum)))\n",
    "        ciMat.resize((self.cNum,self.uNum+self.iNum+self.bNum+self.vNum+self.cNum))\n",
    "\n",
    "        full = sparse.vstack([uiMat,iMat,biMat,viMat,ciMat])\n",
    "        A = full\n",
    "        #selfLoop = sparse.eye(self.uNum+self.iNum+self.aNum+self.oNum+self.gNumm)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        diag[np.isinf(diag)] = 0\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        data = L.data\n",
    "\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        SL = self.getSparseEye(self.uNum+self.iNum+self.bNum+self.vNum+self.cNum)\n",
    "\n",
    "        return SparseL, SparseL+SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been splited!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:370: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:447: RuntimeWarning: divide by zero encountered in power\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:559: RuntimeWarning: divide by zero encountered in power\n"
     ]
    }
   ],
   "source": [
    "filepaths_ACM = [\n",
    "    'ACM/',\n",
    "    'ACM/a2p.csv',\n",
    "    'ACM/p2p.csv',\n",
    "    'ACM/a2a.csv'\n",
    "]\n",
    "\n",
    "filepaths_Movielens = [\n",
    "    'Movielens/',\n",
    "    'Movielens/u2i.csv',\n",
    "    'Movielens/i2g.csv',\n",
    "    'Movielens/i2i.csv',\n",
    "    'Movielens/u2g.csv',\n",
    "    'Movielens/u2o.csv',\n",
    "    'Movielens/u2u.csv'\n",
    "]\n",
    "\n",
    "filepaths_Amazon = [\n",
    "    'Amazon/',\n",
    "    'Amazon/u2i.csv',\n",
    "    'Amazon/i2b.csv',\n",
    "    'Amazon/i2c.csv',\n",
    "    'Amazon/i2v.csv'\n",
    "]\n",
    "\n",
    "config_dat = {\n",
    "    'filepaths':filepaths_Amazon,\n",
    "    'dataset_name':'ACM',\n",
    "    'isLoad':True,\n",
    "    'store':False,\n",
    "    'neg_num4train':5,\n",
    "    'neg_num4eval':5\n",
    "}\n",
    "\n",
    "dat = Amazon_Dataset(config_dat)\n",
    "\n",
    "userNum = dat.uNum\n",
    "itemNum = dat.iNum\n",
    "\n",
    "para = {\n",
    "    'dropout':0,\n",
    "    'num_heads':[4],\n",
    "    'num_meta_paths':3,\n",
    "    'epoch_strat':0,\n",
    "    'continue':False,\n",
    "    'is_load':True,\n",
    "    'device_id':1,\n",
    "    'num_users':userNum,\n",
    "    'num_items':itemNum,\n",
    "    #'layers':[128,32,16,8],\n",
    "    'layers':[64,64,64,64],\n",
    "    'embed_dim':64,\n",
    "    'proj_dim':32,\n",
    "    'hidden_dim':32,\n",
    "    'latent_dim_mf':16,\n",
    "    'latent_dim_mlp':64,\n",
    "    'cuda':True,\n",
    "    'epoch':500,\n",
    "    'loss_type':'BPR',\n",
    "    'lr':1e-3,\n",
    "    'weight_decay':0.01,\n",
    "    'batch_size':128,\n",
    "    'train':0.8,\n",
    "    'patience':10 # 当验证集损失在连续20次训练周期中都没有得到降低时，停止模型训练，以防止模型过拟合\n",
    "}\n",
    "\n",
    "input_train = Wrap_Dataset(user_tensor=torch.LongTensor(dat.input_train['uid']),\n",
    "                            pos_item_tensor=torch.LongTensor(dat.input_train['pos_iid']),\n",
    "                            neg_item_tensor=torch.LongTensor(dat.input_train['neg_iid']))\n",
    "input_train_loader = DataLoader(input_train, batch_size=para['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置切分区域\n",
    "listBins = [0, 5, 10, 50, 100, 210]\n",
    "#设置切分后对应标签\n",
    "listLabels = ['0 - 5','6 - 10','11 - 50','51 - 100','>100']\n",
    "\n",
    "df_static = dat.test.groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "df_static['len'] = df_static['interacted_items'].apply(lambda x:len(x))\n",
    "df_static['fenzu'] = pd.cut(df_static['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "\n",
    "df_stat = df_static.groupby('fenzu').apply(len).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Z\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Train_Loss 54.9587 | Val_Loss 130974.9141 | Val_HR@5 0.2228 | Val_NDCG@5 0.4318\n",
      "Validation metric Increased (inf --> -0.448254).  Saving model ...\n",
      "Epoch 00001 | Time(s) nan | Train_Loss 45.5512 | Val_Loss 128869.6719 | Val_HR@5 0.2312 | Val_NDCG@5 0.4483\n",
      "Validation metric Increased (-0.448254 --> -0.455211).  Saving model ...\n",
      "Epoch 00002 | Time(s) nan | Train_Loss 43.2900 | Val_Loss 127694.1406 | Val_HR@5 0.2343 | Val_NDCG@5 0.4552\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-c36f41aaff80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#print(train_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mloss_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF2(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "#model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "#model = NHGCF3_noattn(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "#model = NHGCF_norelation(para,dat.full,dat.full_hat,dat.num_list)\n",
    "#model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#model.module.weight_init()\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "    \n",
    "if para['continue'] == True:\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "BCE_lossfunc = BCEWithLogitsLoss()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "patience = para['patience'] \n",
    "early_stopping = EarlyStopping(patience, verbose=True) \n",
    "dur = []\n",
    "loss_record=[]\n",
    "hr_record=[]\n",
    "ndcg_record=[]\n",
    "for epoch in range(para['epoch']):\n",
    "    \n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    loss_log = []\n",
    "    model.train() # 设置模型为训练模式\n",
    "    for _id,batch in enumerate(input_train_loader):\n",
    "        optim.zero_grad()\n",
    "        if para['cuda']:\n",
    "            train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "        else:\n",
    "            train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "        #print(train_loss)\n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "        loss_log.append(train_loss.item())\n",
    "        \n",
    "    val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    \n",
    "    loss_record.append(np.mean(loss_log))\n",
    "    hr_record.append(hr)\n",
    "    ndcg_record.append(ndcg)\n",
    "    \n",
    "    if epoch > para['epoch_strat']:\n",
    "        early_stopping(ndcg*(-1), model)   \n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break # 结束模型训练   \n",
    "        \n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "    \n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "            \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "                                             hr, ndcg))\n",
    "x=list(range(epoch+1))   \n",
    "#plt.plot(x,loss_record,label=\"loss\")\n",
    "plt.plot(x,hr_record,label=\"HR@5\")\n",
    "plt.plot(x,ndcg_record,label=\"NDCG@5\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "print(' ')\n",
    "print('hr:',v_hr,'ndcg:',v_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric Increased (inf --> -0.311121).  Saving model ...\n",
      "Validation metric Increased (-0.311121 --> -0.325993).  Saving model ...\n",
      "Validation metric Increased (-0.325993 --> -0.339907).  Saving model ...\n",
      "Validation metric Increased (-0.339907 --> -0.348520).  Saving model ...\n",
      "Validation metric Increased (-0.348520 --> -0.355574).  Saving model ...\n",
      "Validation metric Increased (-0.355574 --> -0.360148).  Saving model ...\n",
      "Validation metric Increased (-0.360148 --> -0.362571).  Saving model ...\n",
      "Validation metric Increased (-0.362571 --> -0.364869).  Saving model ...\n",
      "Validation metric Increased (-0.364869 --> -0.365337).  Saving model ...\n",
      "Validation metric Increased (-0.365337 --> -0.365378).  Saving model ...\n",
      "Validation metric Increased (-0.365378 --> -0.368546).  Saving model ...\n",
      "Validation metric Increased (-0.368546 --> -0.368584).  Saving model ...\n",
      "Validation metric Increased (-0.368584 --> -0.369474).  Saving model ...\n",
      "Validation metric Increased (-0.369474 --> -0.369976).  Saving model ...\n",
      "Validation metric Increased (-0.369976 --> -0.371184).  Saving model ...\n",
      "Validation metric Increased (-0.371184 --> -0.371364).  Saving model ...\n",
      "Validation metric Increased (-0.371364 --> -0.372319).  Saving model ...\n",
      "Validation metric Increased (-0.372319 --> -0.373316).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.373316 --> -0.373520).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.373520 --> -0.373816).  Saving model ...\n",
      "Validation metric Increased (-0.373816 --> -0.374989).  Saving model ...\n",
      "Validation metric Increased (-0.374989 --> -0.375432).  Saving model ...\n",
      "Validation metric Increased (-0.375432 --> -0.376274).  Saving model ...\n",
      "Validation metric Increased (-0.376274 --> -0.376335).  Saving model ...\n",
      "Validation metric Increased (-0.376335 --> -0.379030).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.379030 --> -0.380180).  Saving model ...\n",
      "Validation metric Increased (-0.380180 --> -0.381129).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.381129 --> -0.382003).  Saving model ...\n",
      "Validation metric Increased (-0.382003 --> -0.383442).  Saving model ...\n",
      "Validation metric Increased (-0.383442 --> -0.383514).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.383514 --> -0.383927).  Saving model ...\n",
      "Validation metric Increased (-0.383927 --> -0.384623).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.384623 --> -0.385117).  Saving model ...\n",
      "Validation metric Increased (-0.385117 --> -0.385557).  Saving model ...\n",
      "Validation metric Increased (-0.385557 --> -0.386583).  Saving model ...\n",
      "Validation metric Increased (-0.386583 --> -0.387416).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.387416 --> -0.387622).  Saving model ...\n",
      "Validation metric Increased (-0.387622 --> -0.388636).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.388636 --> -0.389774).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Validation metric Increased (-0.389774 --> -0.389975).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.389975 --> -0.390992).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.390992 --> -0.391863).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.391863 --> -0.393597).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.393597 --> -0.394559).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 8 hr: 0.19856949624953887 ndcg: 0.3790636279132033\n",
      "Validation metric Increased (inf --> -0.358437).  Saving model ...\n",
      "Validation metric Increased (-0.358437 --> -0.375823).  Saving model ...\n",
      "Validation metric Increased (-0.375823 --> -0.387421).  Saving model ...\n",
      "Validation metric Increased (-0.387421 --> -0.394510).  Saving model ...\n",
      "Validation metric Increased (-0.394510 --> -0.400608).  Saving model ...\n",
      "Validation metric Increased (-0.400608 --> -0.402545).  Saving model ...\n",
      "Validation metric Increased (-0.402545 --> -0.404891).  Saving model ...\n",
      "Validation metric Increased (-0.404891 --> -0.407070).  Saving model ...\n",
      "Validation metric Increased (-0.407070 --> -0.410455).  Saving model ...\n",
      "Validation metric Increased (-0.410455 --> -0.412057).  Saving model ...\n",
      "Validation metric Increased (-0.412057 --> -0.413034).  Saving model ...\n",
      "Validation metric Increased (-0.413034 --> -0.414726).  Saving model ...\n",
      "Validation metric Increased (-0.414726 --> -0.416858).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.416858 --> -0.417604).  Saving model ...\n",
      "Validation metric Increased (-0.417604 --> -0.419033).  Saving model ...\n",
      "Validation metric Increased (-0.419033 --> -0.420177).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.420177 --> -0.421193).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.421193 --> -0.422530).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.422530 --> -0.423176).  Saving model ...\n",
      "Validation metric Increased (-0.423176 --> -0.423908).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.423908 --> -0.424587).  Saving model ...\n",
      "Validation metric Increased (-0.424587 --> -0.425126).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.425126 --> -0.425619).  Saving model ...\n",
      "Validation metric Increased (-0.425619 --> -0.426412).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Validation metric Increased (-0.426412 --> -0.426549).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 16 hr: 0.21488297741525597 ndcg: 0.4130613127130086\n",
      "Validation metric Increased (inf --> -0.388790).  Saving model ...\n",
      "Validation metric Increased (-0.388790 --> -0.410435).  Saving model ...\n",
      "Validation metric Increased (-0.410435 --> -0.418318).  Saving model ...\n",
      "Validation metric Increased (-0.418318 --> -0.423026).  Saving model ...\n",
      "Validation metric Increased (-0.423026 --> -0.425789).  Saving model ...\n",
      "Validation metric Increased (-0.425789 --> -0.429156).  Saving model ...\n",
      "Validation metric Increased (-0.429156 --> -0.431401).  Saving model ...\n",
      "Validation metric Increased (-0.431401 --> -0.433347).  Saving model ...\n",
      "Validation metric Increased (-0.433347 --> -0.434995).  Saving model ...\n",
      "Validation metric Increased (-0.434995 --> -0.437157).  Saving model ...\n",
      "Validation metric Increased (-0.437157 --> -0.439995).  Saving model ...\n",
      "Validation metric Increased (-0.439995 --> -0.440310).  Saving model ...\n",
      "Validation metric Increased (-0.440310 --> -0.442915).  Saving model ...\n",
      "Validation metric Increased (-0.442915 --> -0.444432).  Saving model ...\n",
      "Validation metric Increased (-0.444432 --> -0.445325).  Saving model ...\n",
      "Validation metric Increased (-0.445325 --> -0.446309).  Saving model ...\n",
      "Validation metric Increased (-0.446309 --> -0.446329).  Saving model ...\n",
      "Validation metric Increased (-0.446329 --> -0.447057).  Saving model ...\n",
      "Validation metric Increased (-0.447057 --> -0.450595).  Saving model ...\n",
      "Validation metric Increased (-0.450595 --> -0.451010).  Saving model ...\n",
      "Validation metric Increased (-0.451010 --> -0.452018).  Saving model ...\n",
      "Validation metric Increased (-0.452018 --> -0.452106).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.452106 --> -0.453328).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.453328 --> -0.454454).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.454454 --> -0.456285).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Validation metric Increased (-0.456285 --> -0.456401).  Saving model ...\n",
      "Validation metric Increased (-0.456401 --> -0.457288).  Saving model ...\n",
      "Validation metric Increased (-0.457288 --> -0.458426).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 32 hr: 0.22883961142763454 ndcg: 0.4410357692551088\n",
      "Validation metric Increased (inf --> -0.440288).  Saving model ...\n",
      "Validation metric Increased (-0.440288 --> -0.450821).  Saving model ...\n",
      "Validation metric Increased (-0.450821 --> -0.456403).  Saving model ...\n",
      "Validation metric Increased (-0.456403 --> -0.461320).  Saving model ...\n",
      "Validation metric Increased (-0.461320 --> -0.464261).  Saving model ...\n",
      "Validation metric Increased (-0.464261 --> -0.466366).  Saving model ...\n",
      "Validation metric Increased (-0.466366 --> -0.468271).  Saving model ...\n",
      "Validation metric Increased (-0.468271 --> -0.471103).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.471103 --> -0.471576).  Saving model ...\n",
      "Validation metric Increased (-0.471576 --> -0.474035).  Saving model ...\n",
      "Validation metric Increased (-0.474035 --> -0.475397).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.475397 --> -0.477568).  Saving model ...\n",
      "Validation metric Increased (-0.477568 --> -0.477693).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Validation metric Increased (-0.477693 --> -0.478231).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "embed dim: 128 hr: 0.24152559740951757 ndcg: 0.46935828310867844\n",
      "Validation metric Increased (inf --> -0.416056).  Saving model ...\n",
      "Validation metric Increased (-0.416056 --> -0.433157).  Saving model ...\n",
      "Validation metric Increased (-0.433157 --> -0.436023).  Saving model ...\n",
      "Validation metric Increased (-0.436023 --> -0.440615).  Saving model ...\n",
      "Validation metric Increased (-0.440615 --> -0.442094).  Saving model ...\n",
      "Validation metric Increased (-0.442094 --> -0.442638).  Saving model ...\n",
      "Validation metric Increased (-0.442638 --> -0.445199).  Saving model ...\n",
      "Validation metric Increased (-0.445199 --> -0.446195).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.446195 --> -0.449009).  Saving model ...\n",
      "Validation metric Increased (-0.449009 --> -0.451444).  Saving model ...\n",
      "Validation metric Increased (-0.451444 --> -0.452697).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.452697 --> -0.454385).  Saving model ...\n",
      "Validation metric Increased (-0.454385 --> -0.454907).  Saving model ...\n",
      "Validation metric Increased (-0.454907 --> -0.455629).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.455629 --> -0.456559).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.456559 --> -0.458836).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.458836 --> -0.459488).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation metric Increased (-0.459488 --> -0.459878).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Validation metric Increased (-0.459878 --> -0.461213).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.461213 --> -0.461251).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 8 hr: 0.23084805508874043 ndcg: 0.4473480000038172\n",
      "Validation metric Increased (inf --> -0.415474).  Saving model ...\n",
      "Validation metric Increased (-0.415474 --> -0.427518).  Saving model ...\n",
      "Validation metric Increased (-0.427518 --> -0.433975).  Saving model ...\n",
      "Validation metric Increased (-0.433975 --> -0.440916).  Saving model ...\n",
      "Validation metric Increased (-0.440916 --> -0.443764).  Saving model ...\n",
      "Validation metric Increased (-0.443764 --> -0.446467).  Saving model ...\n",
      "Validation metric Increased (-0.446467 --> -0.448406).  Saving model ...\n",
      "Validation metric Increased (-0.448406 --> -0.449986).  Saving model ...\n",
      "Validation metric Increased (-0.449986 --> -0.453866).  Saving model ...\n",
      "Validation metric Increased (-0.453866 --> -0.455128).  Saving model ...\n",
      "Validation metric Increased (-0.455128 --> -0.455203).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.455203 --> -0.456374).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.456374 --> -0.456488).  Saving model ...\n",
      "Validation metric Increased (-0.456488 --> -0.457354).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.457354 --> -0.458077).  Saving model ...\n",
      "Validation metric Increased (-0.458077 --> -0.458427).  Saving model ...\n",
      "Validation metric Increased (-0.458427 --> -0.459297).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.459297 --> -0.459835).  Saving model ...\n",
      "Validation metric Increased (-0.459835 --> -0.460907).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 16 hr: 0.2319547485346559 ndcg: 0.4492095032909467\n",
      "Validation metric Increased (inf --> -0.423787).  Saving model ...\n",
      "Validation metric Increased (-0.423787 --> -0.434396).  Saving model ...\n",
      "Validation metric Increased (-0.434396 --> -0.439730).  Saving model ...\n",
      "Validation metric Increased (-0.439730 --> -0.443248).  Saving model ...\n",
      "Validation metric Increased (-0.443248 --> -0.446782).  Saving model ...\n",
      "Validation metric Increased (-0.446782 --> -0.449623).  Saving model ...\n",
      "Validation metric Increased (-0.449623 --> -0.449682).  Saving model ...\n",
      "Validation metric Increased (-0.449682 --> -0.452941).  Saving model ...\n",
      "Validation metric Increased (-0.452941 --> -0.454527).  Saving model ...\n",
      "Validation metric Increased (-0.454527 --> -0.457731).  Saving model ...\n",
      "Validation metric Increased (-0.457731 --> -0.459187).  Saving model ...\n",
      "Validation metric Increased (-0.459187 --> -0.460640).  Saving model ...\n",
      "Validation metric Increased (-0.460640 --> -0.460901).  Saving model ...\n",
      "Validation metric Increased (-0.460901 --> -0.461850).  Saving model ...\n",
      "Validation metric Increased (-0.461850 --> -0.463031).  Saving model ...\n",
      "Validation metric Increased (-0.463031 --> -0.464343).  Saving model ...\n",
      "Validation metric Increased (-0.464343 --> -0.464461).  Saving model ...\n",
      "Validation metric Increased (-0.464461 --> -0.464792).  Saving model ...\n",
      "Validation metric Increased (-0.464792 --> -0.465008).  Saving model ...\n",
      "Validation metric Increased (-0.465008 --> -0.465361).  Saving model ...\n",
      "Validation metric Increased (-0.465361 --> -0.466436).  Saving model ...\n",
      "Validation metric Increased (-0.466436 --> -0.466876).  Saving model ...\n",
      "Validation metric Increased (-0.466876 --> -0.466898).  Saving model ...\n",
      "Validation metric Increased (-0.466898 --> -0.469314).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "proj dim: 64 hr: 0.23273353281141124 ndcg: 0.452177299763796\n",
      "Validation metric Increased (inf --> -0.419904).  Saving model ...\n",
      "Validation metric Increased (-0.419904 --> -0.427149).  Saving model ...\n",
      "Validation metric Increased (-0.427149 --> -0.433088).  Saving model ...\n",
      "Validation metric Increased (-0.433088 --> -0.438568).  Saving model ...\n",
      "Validation metric Increased (-0.438568 --> -0.442808).  Saving model ...\n",
      "Validation metric Increased (-0.442808 --> -0.446930).  Saving model ...\n",
      "Validation metric Increased (-0.446930 --> -0.447923).  Saving model ...\n",
      "Validation metric Increased (-0.447923 --> -0.449838).  Saving model ...\n",
      "Validation metric Increased (-0.449838 --> -0.451162).  Saving model ...\n",
      "Validation metric Increased (-0.451162 --> -0.451998).  Saving model ...\n",
      "Validation metric Increased (-0.451998 --> -0.454079).  Saving model ...\n",
      "Validation metric Increased (-0.454079 --> -0.455156).  Saving model ...\n",
      "Validation metric Increased (-0.455156 --> -0.455974).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.455974 --> -0.456819).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.456819 --> -0.458549).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.458549 --> -0.458848).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation metric Increased (-0.458848 --> -0.459264).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Validation metric Increased (-0.459264 --> -0.459270).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation metric Increased (-0.459270 --> -0.460667).  Saving model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4d8ac93fb28c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpara\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBPR_lossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBPR_lossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\src\\Utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, u, pos, neg)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mxui\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mxuj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxui\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxuj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-30523325fdd5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, userIdx, itemIdx)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgnn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNHGCFLayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n\u001b[1;32m--> 263\u001b[1;33m                                                                    u_feature, i_feature, u2e_features, i2e_features)\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[0mu_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakyRelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[0mi_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakyRelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-30523325fdd5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mi_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi2e_Cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_upper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL_upper_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi2e_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu2i_Cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu2i_pack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu2i_pack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mi_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mu_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mu_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-30523325fdd5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, L, L_hat, features)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mL_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0minter_part1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0minter_part2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterAct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minter_part1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0minter_part2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\sparse\\__init__.py\u001b[0m in \u001b[0;36mmm\u001b[1;34m(mat1, mat2)\u001b[0m\n\u001b[0;32m     66\u001b[0m                size=(2, 3), nnz=6, layout=torch.sparse_coo)\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "para['proj_dim'] = 32\n",
    "\n",
    "for dim in [8,16,32,128]:\n",
    "    para['embed_dim'] = dim\n",
    "    para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('embed dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)\n",
    "\n",
    "    \n",
    "para['embed_dim'] = 64\n",
    "para['layers'] = [64,64,64,64]    \n",
    "\n",
    "for dim in [8,16,64,128]:\n",
    "    para['proj_dim'] = dim\n",
    "    #para['layers'] = [dim,dim,dim,dim]\n",
    "    \n",
    "    model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "    #model = NHGCF4(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #model.module.weight_init()\n",
    "    model.weight_init()\n",
    "    if para['cuda'] == True:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if para['continue'] == True:\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=para['weight_decay'])\n",
    "    BCE_lossfunc = BCEWithLogitsLoss()\n",
    "    BPR_lossfunc = BPRLoss(model)\n",
    "    patience = para['patience'] \n",
    "    early_stopping = EarlyStopping(patience, verbose=True) \n",
    "    dur = []\n",
    "    loss_record=[]\n",
    "    hr_record=[]\n",
    "    ndcg_record=[]\n",
    "    for epoch in range(para['epoch']):\n",
    "\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        loss_log = []\n",
    "        model.train() # 设置模型为训练模式\n",
    "        for _id,batch in enumerate(input_train_loader):\n",
    "            optim.zero_grad()\n",
    "            if para['cuda']:\n",
    "                train_loss = BPR_lossfunc(batch[0].cuda(), batch[1].cuda(),batch[2].cuda())\n",
    "            else:\n",
    "                train_loss = BPR_lossfunc(batch[0], batch[1],batch[2])\n",
    "            #print(train_loss)\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            loss_log.append(train_loss.item())\n",
    "\n",
    "        val_loss,hr,ndcg = evaluate(dat.eval_dev, dat.input_dev, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "        loss_record.append(np.mean(loss_log))\n",
    "        hr_record.append(hr)\n",
    "        ndcg_record.append(ndcg)\n",
    "\n",
    "        if epoch > para['epoch_strat']:\n",
    "            early_stopping(ndcg*(-1), model)   \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break # 结束模型训练   \n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        #print(\"Epoch {:05d} | Time(s) {:.4f} | Train_Loss {:.4f} | Val_Loss {:.4f} | Val_HR@5 {:.4f} | \"\n",
    "        #        \"Val_NDCG@5 {:.4f}\". format(epoch, np.mean(dur), np.mean(loss_log),val_loss,\n",
    "        #                                         hr, ndcg))\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "    print('proj dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj dim: 128 hr: 0.22888060007377956 ndcg: 0.44319751979879424\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "v_,v_hr,v_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "print('proj dim:',dim,'hr:',v_hr,'ndcg:',v_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133988.59375, 0.227568963397139, 0.4369339623016982)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138814.1875, 0.2358896585645776, 0.4545629072811069)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133350.75, 0.23486494241095215, 0.4536278347976662)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133210.328125, 0.232200680411526, 0.4495075940709393)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133498.09375, 0.2307660777964504, 0.4429809215353184)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302886.4375, 0.1696520063942288, 0.32763245929548057)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138765.953125, 0.24066483584047219, 0.46533590503712613)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133671.1875, 0.22363405336721728, 0.4328781951300936)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131959.375, 0.22902406033528713, 0.44493711033337224)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133211.484375, 0.22904455465835963, 0.44340749400545826)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132524.90625, 0.23320490224207893, 0.4520617542981086)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133215.65625, 0.23482395376480714, 0.45604335502543947)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133803.515625, 0.2291880149198672, 0.442175005028406)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133673.640625, 0.22967987867360742, 0.44329494940748104)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133564.765625, 0.23062261753494281, 0.4458172134869379)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133404.671875, 0.23388121490347175, 0.4536076251446351)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132943.21875, 0.23295897036520885, 0.4503694155236273)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133803.15625, 0.22904455465835963, 0.4445469654272905)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132873.109375, 0.2360741074722302, 0.45568983530138735)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138631.546875, 0.2416075747018076, 0.46625599905326626)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133163.125, 0.23111448128868303, 0.4444053764710178)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133294.25, 0.23162683936549575, 0.4480569217904472)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133355.609375, 0.2353773004877649, 0.453670818286913)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138590.125, 0.23136041316555314, 0.4470011708945964)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143317.0, 0.21617411976882403, 0.4152909702756047)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_,df_hr,df_ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置切分区域\n",
    "listBins = [0, 5, 10, 50,210]\n",
    "#设置切分后对应标签\n",
    "listLabels = ['0 - 5','6 - 10','11 - 50','>50']\n",
    "df_at = dat.test\n",
    "df_test = df_at.groupby('uid')['iid'].apply(set).reset_index().rename(columns={'iid': 'interacted_items'})\n",
    "df_test['len'] = df_test['interacted_items'].apply(lambda x:len(x))\n",
    "df_test = df_test[['uid','len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('MF326.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_MF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_MF['num'] = num_list\n",
    "\n",
    "df_MF['fenzu'] = pd.cut(df_MF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_MF_stat = df_MF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_MF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_MF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NGCF330.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_NGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NGCF['num'] = num_list\n",
    "\n",
    "df_NGCF['fenzu'] = pd.cut(df_NGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NGCF_stat = df_NGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NGCF_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "model = HAN(para,dat.mp_graphs)\n",
    "#model = NHGCF(para,dat.u2i,dat.u2es,dat.i2es)\n",
    "\n",
    "#model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('HAN326.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_HAN = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_HAN['num'] = num_list\n",
    "\n",
    "df_HAN['fenzu'] = pd.cut(df_HAN['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_HAN_stat = df_HAN.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_HAN.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_HAN_stat['num'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MF(para)\n",
    "#model = NeuMF(para)\n",
    "#model = GCF(para,dat.u2i[0][0])\n",
    "#model = HAN(para,dat.mp_graphs)\n",
    "model = NHGCF3(para,dat.u2i,dat.u2es2,dat.i2es2)\n",
    "\n",
    "#model.weight_init()\n",
    "if para['cuda'] == True:\n",
    "    model = model.cuda()\n",
    "BPR_lossfunc = BPRLoss(model)\n",
    "model.load_state_dict(torch.load('NHGCF328.pt'))\n",
    "v_,df_hr,df_ndcg = evaluate2(dat.eval_test, dat.input_test, model, BPR_lossfunc, 5, para['cuda'])\n",
    "\n",
    "df_result = pd.merge(df_test,df_ndcg,on='uid',how='left')\n",
    "df_result = df_result.fillna(0)\n",
    "df_result = df_result.rename(columns={'len_x': 'len'})\n",
    "df_result = df_result[['uid','len','ndcg_perU']]\n",
    "df_ndcg = df_result\n",
    "\n",
    "\n",
    "df_NHGCF = df_ndcg.groupby('len')['ndcg_perU'].apply(np.mean).reset_index().rename(columns={'ndcg_perU': 'ave_ndcg'})\n",
    "num_list = df_ndcg.groupby('len').apply(len).to_list()\n",
    "df_NHGCF['num'] = num_list\n",
    "\n",
    "df_NHGCF['fenzu'] = pd.cut(df_NHGCF['len'], bins=listBins, labels=listLabels, include_lowest=True)\n",
    "df_NHGCF_stat = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()\n",
    "num_list = df_NHGCF.groupby('fenzu')['num'].apply(sum).to_list()\n",
    "df_NHGCF_stat['num'] = num_list\n",
    "#df_NHGCF_stat['num'] = df_NHGCF.groupby('fenzu')['ave_ndcg'].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.463151</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 50</td>\n",
       "      <td>0.389025</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>0.396809</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg   num\n",
       "0    0 - 5  0.463151  3018\n",
       "1   6 - 10  0.367370  1158\n",
       "2  11 - 50  0.389025   787\n",
       "3      >50  0.396809    64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.548686</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 50</td>\n",
       "      <td>0.540341</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>0.578085</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg   num\n",
       "0    0 - 5  0.548686  3269\n",
       "1   6 - 10  0.473430  1291\n",
       "2  11 - 50  0.540341   891\n",
       "3      >50  0.578085    76"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.556807</td>\n",
       "      <td>3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.482348</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 50</td>\n",
       "      <td>0.547235</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>0.539097</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg   num\n",
       "0    0 - 5  0.556807  3358\n",
       "1   6 - 10  0.482348  1295\n",
       "2  11 - 50  0.547235   881\n",
       "3      >50  0.539097    71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HAN_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.552892</td>\n",
       "      <td>3304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 50</td>\n",
       "      <td>0.530407</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>0.544161</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg   num\n",
       "0    0 - 5  0.552892  3304\n",
       "1   6 - 10  0.473100  1296\n",
       "2  11 - 50  0.530407   883\n",
       "3      >50  0.544161    76"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NHGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fenzu</th>\n",
       "      <th>ave_ndcg</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0 - 5</td>\n",
       "      <td>0.541916</td>\n",
       "      <td>3315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6 - 10</td>\n",
       "      <td>0.476763</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11 - 50</td>\n",
       "      <td>0.534516</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>0.546276</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fenzu  ave_ndcg   num\n",
       "0    0 - 5  0.541916  3315\n",
       "1   6 - 10  0.476763  1310\n",
       "2  11 - 50  0.534516   887\n",
       "3      >50  0.546276    75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NHGCF_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=500)\n",
    "#plt.figure(figsize=(10,5))\n",
    "fig, ax1 = plt.subplots(figsize = (6, 5))\n",
    "\n",
    "width = 0.5\n",
    "#index = np.arange(len(listLabels))\n",
    "#tick_label = listLabels\n",
    "#ax1.bar(index,df_MF_stat['num'],width =width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width,df_HAN_stat['num'],width =width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width,df_NGCF_stat['num'],width =width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "#ax1.bar(index+width+width+width,df_NHGCF_stat['num'],width =width,color='lightgray',label=\"NHGCF_recall\",align=\"center\")\n",
    "#ax1.set_ylabel('Recall Num')\n",
    "#ax1.set_xticks(index+width*1.5, tick_label)\n",
    "#ax1.legend(loc='upper center')\n",
    "\n",
    "ax1.bar(listLabels,df_MF_stat['num'],width = width,color='lightsteelblue',label=\"MF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NGCF_stat['num'],width = width,color='lightseagreen',label=\"NGCF_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_HAN_stat['num'],width = width,color='lightskyblue',label=\"HAN_recall\",align=\"center\")\n",
    "ax1.bar(listLabels,df_NHGCF_stat['num'],width = width,color='lightgray',label=\"Ours_recall\",align=\"center\")\n",
    "ax1.set_ylabel('Num',fontsize=12)\n",
    "ax1.set_xlabel('User Group\\n(divided by interaction num)',fontsize=15)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(listLabels,df_MF_stat['ave_ndcg'],label=\"MF\",marker='o')\n",
    "ax2.plot(listLabels,df_NGCF_stat['ave_ndcg'],label=\"NGCF\",marker='v')\n",
    "ax2.plot(listLabels,df_HAN_stat['ave_ndcg'],label=\"HAN\",marker='*')\n",
    "ax2.plot(listLabels,df_NHGCF_stat['ave_ndcg'],label=\"Ours\",marker='s')\n",
    "#ax2.hlines(0.70, -1, 8, linestyles = \"dashed\")\n",
    "#ax2.plot(listLabels,df_NeuMF_stat['ave_ndcg'],label=\"NeuMF\",marker='o')\n",
    "#ax2.set_ylim(.65,.90)\n",
    "ax2.set_ylabel('NDCG@5',fontsize=12)\n",
    "ax2.yaxis.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)\n",
    "\n",
    "#ax1.legend(loc='lower left')\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=32):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(inF,outF,useCuda),Message_Storage(useCuda)]))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[1][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[2][0].Transform.weight,\n",
    "            #self.NHGCFLayers[0].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[0].i2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[0].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[1][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[2][0].Transform.weight,\n",
    "            #self.NHGCFLayers[1].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[1].i2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[1].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[1][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[2][0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].u2e_Cells[2][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2][0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2][0].InterAct.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[1][0].Transform.weight,\n",
    "            #self.NHGCFLayers[2].i2e_Cells[1][0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.i2eEmbds[0].weight,\n",
    "            self.i2eEmbds[1].weight,\n",
    "            self.i2eEmbds[2].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            #nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NHGCF2(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF2,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        \n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "        \n",
    "        \n",
    "        self.u_relation_attention = RelationAttention(in_size=config['embed_dim'])\n",
    "        self.i_relation_attention = RelationAttention(in_size=config['embed_dim'])\n",
    "        self.u2i_Cell = Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self.self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(torch.nn.ModuleList([Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda),\n",
    "                                                           Message_Storage(self.useCuda)]))\n",
    "        \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self.self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(torch.nn.ModuleList([Message_Passing(config['embed_dim'],config['embed_dim'],self.useCuda),\n",
    "                                                           Message_Storage(self.useCuda)]))\n",
    "        \n",
    "        self.layers = config['layers']\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    " \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.u_relation_attention.project[0].weight,\n",
    "            self.u_relation_attention.project[2].weight,\n",
    "            self.i_relation_attention.project[0].weight,\n",
    "            self.i_relation_attention.project[2].weight,\n",
    "            self.u2i_Cell.Transform.weight,\n",
    "            self.u2i_Cell.InterAct.weight,\n",
    "            self.i2e_Cells[0][0].Transform.weight,\n",
    "            self.i2e_Cells[0][0].InterAct.weight,\n",
    "            self.i2e_Cells[1][0].Transform.weight,\n",
    "            self.i2e_Cells[1][0].InterAct.weight,\n",
    "            self.i2e_Cells[2][0].Transform.weight,\n",
    "            self.i2e_Cells[2][0].InterAct.weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.i2eEmbds[0].weight,\n",
    "            self.i2eEmbds[1].weight,\n",
    "            self.i2eEmbds[2].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            nn.init.constant_(wt, 0.0)\n",
    "            #nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        \n",
    "        for _ in self.layers[:-1]:\n",
    "            u_embeddings = []\n",
    "            i_embeddings = []\n",
    "            u2e_embeddings =[]\n",
    "            i2e_embeddings =[]\n",
    "            for ((L_upper,L_upper_hat,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(self.u2e_pack,u2e_features,self.u2e_Cells):\n",
    "                if self_tag is True:\n",
    "                    # self interact\n",
    "                    u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "                else:\n",
    "                    u2e_embeddings.append(u2e_Cell[1](L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                    u_embeddings.append(u2e_Cell[0](L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "            for ((L_upper,L_upper_hat,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(self.i2e_pack,i2e_features,self.i2e_Cells):\n",
    "                if self_tag is True:\n",
    "                    # self interact\n",
    "                    i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "                else:\n",
    "                    i2e_embeddings.append(i2e_Cell[1](L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                    i_embeddings.append(i2e_Cell[0](L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "            temp = self.u2i_Cell(self.u2i_pack[0][0],self.u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "            i_embeddings.append(temp[self.userNum:]) \n",
    "            u_embeddings.append(temp[:self.userNum])\n",
    "\n",
    "            i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "            u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "            \n",
    "            u_feature = self.leakyRelu(self.u_relation_attention(u_embeddings))\n",
    "            i_feature = self.leakyRelu(self.i_relation_attention(i_embeddings))\n",
    "            \n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_embeddings]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_embeddings]\n",
    "            #u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            #i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size=128):\n",
    "        super(SemanticAttention, self).__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "\n",
    "        return (beta * z).sum(1)\n",
    "\n",
    "class HANLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    HAN layer.\n",
    "    Arguments\n",
    "    ---------\n",
    "    num_meta_paths : number of homogeneous graphs generated from the metapaths.\n",
    "    in_size : input feature dimension\n",
    "    out_size : output feature dimension\n",
    "    layer_num_heads : number of attention heads\n",
    "    dropout : Dropout probability\n",
    "    Inputs\n",
    "    ------\n",
    "    g : list[DGLGraph]\n",
    "        List of graphs\n",
    "    h : tensor\n",
    "        Input features\n",
    "    Outputs\n",
    "    -------\n",
    "    tensor\n",
    "        The output feature\n",
    "    \"\"\"\n",
    "    def __init__(self, num_meta_paths, in_size, out_size, layer_num_heads, dropout):\n",
    "        super(HANLayer, self).__init__()\n",
    "\n",
    "        # One GAT layer for each meta path based adjacency matrix\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        for i in range(num_meta_paths):\n",
    "            self.gat_layers.append(GATConv(in_size, out_size, layer_num_heads,\n",
    "                                           dropout, dropout, activation=F.elu))\n",
    "        self.semantic_attention = SemanticAttention(in_size=out_size * layer_num_heads)\n",
    "        self.num_meta_paths = num_meta_paths\n",
    "\n",
    "    def forward(self, gs, h):\n",
    "        semantic_embeddings = []\n",
    "\n",
    "        for i, g in enumerate(gs):\n",
    "            semantic_embeddings.append(self.gat_layers[i](g, h).flatten(1))\n",
    "        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)                  # (N, M, D * K)\n",
    "\n",
    "        return self.semantic_attention(semantic_embeddings)                            # (N, D * K)\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self,config, gs):\n",
    "        super(HAN, self).__init__()\n",
    "        self.gs = gs\n",
    "        self.usecuda = config['cuda']\n",
    "        self.dropout = config['dropout']\n",
    "        self.num_heads = config['num_heads']\n",
    "        self.num_meta_paths = len(gs)\n",
    "        self.userNum = config['num_users']\n",
    "        self.itemNum = config['num_items']\n",
    "        self.uEmbd = nn.Embedding(config['num_users'],config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(config['num_items'],config['embed_dim'])\n",
    "        self.in_size = config['embed_dim']\n",
    "        self.hidden_size = config['hidden_dim']\n",
    "        #self.h = torch.cat((self.uEmbd,self.iEmbd),dim=0)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(HANLayer(self.num_meta_paths, self.in_size, self.hidden_size, self.num_heads[0], self.dropout))\n",
    "        for l in range(1, len(self.num_heads)):\n",
    "            self.layers.append(HANLayer(self.num_meta_paths, self.hidden_size * self.num_heads[l-1],\n",
    "                                        self.hidden_size,  self.num_heads[l],  self.dropout))\n",
    "        #self.predict = nn.Linear(hidden_size * num_heads[-1], 1)\n",
    "    \n",
    "    def weight_init(self):\n",
    "        wts = [\n",
    "            self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.layers[0].gat_layers[0].fc.weight,\n",
    "            self.layers[0].gat_layers[1].fc.weight,\n",
    "            self.layers[0].gat_layers[2].fc.weight,\n",
    "            self.layers[0].gat_layers[3].fc.weight,\n",
    "           # self.layers[0].gat_layers[3].fc.weight,\n",
    "            #self.layers[0].gat_layers[4].fc.weight,\n",
    "            #self.layers[0].gat_layers[5].fc.weight,\n",
    "            self.layers[0].semantic_attention.project[0].weight,\n",
    "            self.layers[0].semantic_attention.project[2].weight\n",
    "            #self.layers[1].gat_layers[0].fc.weight,\n",
    "            #self.layers[1].gat_layers[1].fc.weight,\n",
    "            #self.layers[1].gat_layers[2].fc.weight,\n",
    "            #self.layers[1].semantic_attention.project[0].weight,\n",
    "            #self.layers[1].semantic_attention.project[2].weight\n",
    "            #self.layers[2].gat_layers[0].fc.weight,\n",
    "            #self.layers[2].gat_layers[1].fc.weight,\n",
    "            #self.layers[2].gat_layers[2].fc.weight,\n",
    "            #self.layers[2].semantic_attention.project[0].weight,\n",
    "            #self.layers[2].semantic_attention.project[2].weight\n",
    "        ]\n",
    "        \n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)  \n",
    "    \n",
    "    def getFeatureMat(self):\n",
    "        uidx = torch.LongTensor([i for i in range(self.userNum)])\n",
    "        iidx = torch.LongTensor([i for i in range(self.itemNum)])\n",
    "        if self.usecuda  == True:\n",
    "            uidx = uidx.cuda()\n",
    "            iidx = iidx.cuda()\n",
    "        #print(type(uidx))\n",
    "        userEmbd = self.uEmbd(uidx)\n",
    "        itemEmbd = self.iEmbd(iidx)\n",
    "\n",
    "        features = torch.cat([userEmbd,itemEmbd],dim=0)\n",
    "        return features\n",
    "    \n",
    "    def forward(self, userIdx,itemIdx):\n",
    "        itemIdx = itemIdx + self.userNum\n",
    "        features = self.getFeatureMat()\n",
    "        #finalEmbd = features.clone()\n",
    "        for gnn in self.layers:\n",
    "            features = gnn(self.gs, features)\n",
    "            features = normalize(features, 2, 1) # L2 Norm\n",
    "          \n",
    "        userEmbd = features[userIdx]\n",
    "        itemEmbd = features[itemIdx]    \n",
    "        #print(userEmbd.size()) \n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,proj_dim,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell(L_down,L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell(L_down,L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return self.u_relation_attention(u_embeddings),self.i_relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        self.proj_dim = config['proj_dim']\n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To,self.proj_dim, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            #self.NHGCFLayers[3].u2i_Cell.Transform.weight,\n",
    "            #self.NHGCFLayers[3].u2i_Cell.InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[0].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[1].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[2].Transform.weight,\n",
    "            #self.NHGCFLayers[3].i2e_Cells[2].InterAct.weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].u_relation_attention.project[2].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[0].weight,\n",
    "            #self.NHGCFLayers[3].i_relation_attention.project[2].weight\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.i2eEmbds[0].weight,\n",
    "            self.i2eEmbds[1].weight,\n",
    "            self.i2eEmbds[2].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationAttention(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size):\n",
    "        super(RelationAttention, self).__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(in_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1, bias=False))\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)\n",
    "        beta = torch.softmax(w, dim=1)\n",
    "        return (beta * z).sum(1)\n",
    "    \n",
    "    \n",
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "    \n",
    "class Message_Storage(Module):\n",
    "    def __init__(self,useCuda):\n",
    "        super(Message_Storage,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "    def forward(self, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L_hat = L_hat.cuda()\n",
    "        return torch.sparse.mm(L_hat,features) \n",
    "    \n",
    "    \n",
    "class NHGCFLayer(Module):\n",
    "    def __init__(self,inF,outF,proj_dim,useCuda,self_tag_u2es, self_tag_i2es):\n",
    "        super(NHGCFLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "\n",
    "        self.u2i_Cell = Message_Passing(inF,outF,useCuda)\n",
    "        \n",
    "        self.u2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_u2es:\n",
    "            if i==True:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.u2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "                \n",
    "        self.i2e_Cells = torch.nn.ModuleList()\n",
    "        for i in self_tag_i2es:\n",
    "            if i==True:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "            else:\n",
    "                self.i2e_Cells.append(Message_Passing(inF,outF,useCuda))\n",
    "         \n",
    "        self.u_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        self.i_relation_attention = RelationAttention(in_size=self.inF,hidden_size=proj_dim)\n",
    "        #self.relation_attention = RelationAttention(in_size=self.inF)\n",
    "        \n",
    "    def forward(self, u2i_pack, u2e_pack, i2e_pack, u_feature, i_feature, u2e_features, i2e_features):\n",
    "        u_embeddings = []\n",
    "        i_embeddings = []\n",
    "        u2e_embeddings =[]\n",
    "        i2e_embeddings =[]\n",
    "        u_num = u2i_pack[1][0]\n",
    "        #i_num = u2i_pack[2][1]\n",
    "        \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),u2e_feature,u2e_Cell in zip(u2e_pack,u2e_features,self.u2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,u_feature))\n",
    "            else:\n",
    "                u2e_embeddings.append(u2e_Cell(L_down,L_down_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "                u_embeddings.append(u2e_Cell(L_upper,L_upper_hat,torch.cat([u_feature,u2e_feature],dim=0)))\n",
    "            \n",
    "            \n",
    "        for ((L_upper,L_upper_hat,L_down,L_down_hat),self_tag),i2e_feature,i2e_Cell in zip(i2e_pack,i2e_features,self.i2e_Cells):\n",
    "            if self_tag is True:\n",
    "                # self interact\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,i_feature))\n",
    "            else:\n",
    "                i2e_embeddings.append(i2e_Cell(L_down,L_down_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                i_embeddings.append(i2e_Cell(L_upper,L_upper_hat,torch.cat([i_feature,i2e_feature],dim=0)))\n",
    "                \n",
    "        temp = self.u2i_Cell(u2i_pack[0][0],u2i_pack[0][1],torch.cat([u_feature,i_feature],dim=0))\n",
    "        i_embeddings.append(temp[u_num:]) \n",
    "        u_embeddings.append(temp[:u_num])\n",
    "        \n",
    "        i_embeddings = torch.stack(i_embeddings, dim=1)\n",
    "        u_embeddings = torch.stack(u_embeddings, dim=1)\n",
    "        return torch.sum(u_embeddings, dim=1),torch.sum(i_embeddings, dim=1),u2e_embeddings,i2e_embeddings\n",
    "        #return self.relation_attention(u_embeddings),self.relation_attention(i_embeddings),u2e_embeddings,i2e_embeddings\n",
    "    \n",
    "    \n",
    "\n",
    "class NHGCF3_noattn(Module):\n",
    "    def __init__(self,config,u2i,u2es,i2es):\n",
    "        \"\"\"\n",
    "        u2es[x][0]: laplacian\n",
    "        u2es[x][1]: node num\n",
    "        u2es[x][2]: self intercat tag\n",
    "        \"\"\"\n",
    "        super(NHGCF3_noattn,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        self.proj_dim = config['proj_dim']\n",
    "        self.userNum = u2i[1][0]\n",
    "        self.itemNum = u2i[1][1]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.userNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.itemNum,config['embed_dim'])\n",
    "        self.u2i_pack = (u2i[0],[self.userNum,self.itemNum])\n",
    "        \n",
    "        self.u2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_u2es = []\n",
    "        self.self_tag_u2es = []\n",
    "        self.u2eNums =[]\n",
    "        for u2e in u2es:\n",
    "            self.L_u2es.append(u2e[0])\n",
    "            self.u2eNums.append(u2e[1])\n",
    "            if u2e[2]==False:\n",
    "                self.u2eEmbds.append(nn.Embedding(u2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.u2eEmbds.append(None)\n",
    "            self.self_tag_u2es.append(u2e[2])\n",
    "        self.u2e_pack = zip(self.L_u2es,self.self_tag_u2es)\n",
    "            \n",
    "        self.i2eEmbds=torch.nn.ModuleList()\n",
    "        self.L_i2es = []\n",
    "        self.self_tag_i2es = []\n",
    "        self.i2eNums =[]\n",
    "        for i2e in i2es:\n",
    "            self.L_i2es.append(i2e[0])\n",
    "            self.i2eNums.append(i2e[1])\n",
    "            if i2e[2]==False:\n",
    "                self.i2eEmbds.append(nn.Embedding(i2e[1],config['embed_dim']))\n",
    "            else:\n",
    "                self.i2eEmbds.append(None)\n",
    "            self.self_tag_i2es.append(i2e[2])\n",
    "        self.i2e_pack = zip(self.L_i2es,self.self_tag_i2es)    \n",
    "    \n",
    "        self.layers = config['layers']\n",
    "        self.NHGCFLayers = torch.nn.ModuleList()\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "\n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.NHGCFLayers.append(NHGCFLayer(From, To,self.proj_dim, self.useCuda, self.self_tag_u2es, self.self_tag_i2es))  \n",
    "    # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "            self.iEmbd.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[0].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[0].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[0].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[1].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[1].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[1].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[1].i_relation_attention.project[2].weight,\n",
    "              \n",
    "            self.NHGCFLayers[2].u2i_Cell.Transform.weight,\n",
    "            self.NHGCFLayers[2].u2i_Cell.InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[0].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[1].InterAct.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2].Transform.weight,\n",
    "            self.NHGCFLayers[2].i2e_Cells[2].InterAct.weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].u_relation_attention.project[2].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[0].weight,\n",
    "            self.NHGCFLayers[2].i_relation_attention.project[2].weight\n",
    "\n",
    "              ]\n",
    "        wts2 = [\n",
    "            self.i2eEmbds[0].weight,\n",
    "            self.i2eEmbds[1].weight,\n",
    "            self.i2eEmbds[2].weight\n",
    "        ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "        for wt in wts2:\n",
    "            #nn.init.constant_(wt, 0.0)\n",
    "            nn.init.xavier_normal_(wt, gain=1) \n",
    "            \n",
    "    \n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        #itemIdx = itemIdx + self.userNum\n",
    "        u_feature = self.getFeatureMat(self.userNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.itemNum,self.iEmbd)\n",
    "        \n",
    "        u2e_features = []\n",
    "        for num,embd in zip(self.u2eNums,self.u2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "            \n",
    "        i2e_features = []\n",
    "        for num,embd in zip(self.i2eNums,self.i2eEmbds):\n",
    "            if embd is not None:\n",
    "                u2e_features.append(self.getFeatureMat(num,embd))\n",
    "            else:\n",
    "                # self interact\n",
    "                u2e_features.append(None)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.NHGCFLayers:\n",
    "            u_feature, i_feature, u2e_features, i2e_features = gnn(self.u2i_pack, self.u2e_pack, self.i2e_pack, \n",
    "                                                                   u_feature, i_feature, u2e_features, i2e_features)\n",
    "            u_feature = self.leakyRelu(u_feature)\n",
    "            i_feature = self.leakyRelu(i_feature)\n",
    "            u_feature = normalize(u_feature, 2, 1) # L2 Norm\n",
    "            i_feature = normalize(i_feature, 2, 1) # L2 Norm\n",
    "            \n",
    "            u2e_features = [self.leakyRelu(f) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [self.leakyRelu(f) if (f is not None) else None for f in i2e_features]\n",
    "            u2e_features = [normalize(f,2,1) if (f is not None) else None for f in u2e_features]\n",
    "            i2e_features = [normalize(f,2,1) if (f is not None) else None for f in i2e_features]\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "\n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passing(Module):\n",
    "    def __init__(self,inF,outF,num_list,useCuda):\n",
    "        super(Message_Passing,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.useCuda = useCuda\n",
    "        \n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "        self.bNum = num_list[2]\n",
    "        self.vNum = num_list[3]\n",
    "        self.cNum = num_list[4]\n",
    "        \n",
    "        self.Transform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.InterAct = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, L, L_hat,features):\n",
    "        if self.useCuda:\n",
    "            L=L.cuda()\n",
    "            L_hat = L_hat.cuda()\n",
    "        inter_part1 = torch.sparse.mm(L_hat,self.Transform(features))     \n",
    "        inter_part2 = torch.sparse.mm(L,self.InterAct(torch.mul(features,features)))\n",
    "        full =  inter_part1+inter_part2\n",
    "        u_feature = full[:self.uNum]\n",
    "        i_feature = full[self.uNum:self.iNum+self.uNum]\n",
    "        b_feature = full[self.iNum+self.uNum:self.iNum+self.uNum+self.bNum]\n",
    "        v_feature = full[self.iNum+self.uNum+self.bNum:self.iNum+self.uNum+self.bNum+self.vNum]\n",
    "        c_feature = full[self.iNum+self.uNum+self.bNum+self.vNum:]\n",
    "        return u_feature,i_feature,b_feature,v_feature,c_feature\n",
    "\n",
    "class NHGCF_norelation(Module):\n",
    "\n",
    "    def __init__(self,config,L,L_hat,num_list):\n",
    "\n",
    "        super(NHGCF_norelation,self).__init__()\n",
    "        self.useCuda = config['cuda']\n",
    "        self.uNum = num_list[0]\n",
    "        self.iNum = num_list[1]\n",
    "        self.bNum = num_list[2]\n",
    "        self.vNum = num_list[3]\n",
    "        self.cNum = num_list[4]\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(self.uNum,config['embed_dim'])\n",
    "        self.iEmbd = nn.Embedding(self.iNum,config['embed_dim'])\n",
    "        self.bEmbd = nn.Embedding(self.bNum,config['embed_dim'])\n",
    "        self.vEmbd = nn.Embedding(self.vNum,config['embed_dim'])\n",
    "        self.cEmbd = nn.Embedding(self.cNum,config['embed_dim'])\n",
    "        \n",
    "        self.layers = config['layers']\n",
    "        self.GNNlayers = torch.nn.ModuleList()\n",
    "        self.L = L # sparse format\n",
    "        self.L_hat = L_hat\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "        \n",
    "        for From,To in zip(self.layers[:-1],self.layers[1:]):\n",
    "            self.GNNlayers.append(Message_Passing(From,To,num_list,self.useCuda))\n",
    "    \n",
    "     # 参数初始化\n",
    "    def weight_init(self):\n",
    "        wts= [self.uEmbd.weight,\n",
    "              self.iEmbd.weight,\n",
    "              self.bEmbd.weight,\n",
    "              self.vEmbd.weight,\n",
    "              self.cEmbd.weight,        \n",
    "              self.GNNlayers[0].Transform.weight,\n",
    "              self.GNNlayers[0].InterAct.weight,\n",
    "              self.GNNlayers[1].Transform.weight,\n",
    "              self.GNNlayers[1].InterAct.weight,\n",
    "              self.GNNlayers[2].Transform.weight,\n",
    "              self.GNNlayers[2].InterAct.weight\n",
    "              #self.transForm1.weight,\n",
    "              #self.transForm2.weight,\n",
    "              #self.transForm3.weight,\n",
    "              ]\n",
    "        for wt in wts:\n",
    "            nn.init.xavier_normal_(wt, gain=1)      \n",
    "\n",
    "\n",
    "    def getFeatureMat(self,num,embd):\n",
    "        idx = torch.LongTensor([i for i in range(num)])\n",
    "        if self.useCuda == True:\n",
    "            idx = idx.cuda()\n",
    "        fullEmbd = embd(idx)\n",
    "        return fullEmbd\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "        \n",
    "        u_feature = self.getFeatureMat(self.uNum,self.uEmbd)\n",
    "        i_feature = self.getFeatureMat(self.iNum,self.iEmbd)\n",
    "        b_feature = self.getFeatureMat(self.bNum,self.bEmbd)\n",
    "        v_feature = self.getFeatureMat(self.vNum,self.vEmbd)\n",
    "        c_feature = self.getFeatureMat(self.cNum,self.cEmbd)\n",
    "        \n",
    "        u_finalEmbd = u_feature.clone()\n",
    "        i_finalEmbd = i_feature.clone()\n",
    "        for gnn in self.GNNlayers:\n",
    "            u_feature,i_feature,b_feature,v_feature,c_feature = gnn(self.L,self.L_hat,torch.cat([u_feature,i_feature,\n",
    "                                                                                                 b_feature,v_feature,c_feature]))\n",
    "            u_feature = normalize(self.leakyRelu(u_feature), 2, 1)\n",
    "            i_feature = normalize(self.leakyRelu(i_feature), 2, 1)\n",
    "            b_feature = normalize(self.leakyRelu(b_feature), 2, 1)\n",
    "            v_feature = normalize(self.leakyRelu(v_feature), 2, 1)\n",
    "            c_feature = normalize(self.leakyRelu(c_feature), 2, 1)\n",
    "            \n",
    "            u_finalEmbd = torch.cat([u_finalEmbd,u_feature.clone()],dim=1)\n",
    "            i_finalEmbd = torch.cat([i_finalEmbd,i_feature.clone()],dim=1)\n",
    "            \n",
    "        userEmbd = u_finalEmbd[userIdx]\n",
    "        itemEmbd = i_finalEmbd[itemIdx]\n",
    "\n",
    "        add  = torch.mul(userEmbd,itemEmbd)\n",
    "        logits = torch.sum(add,dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
